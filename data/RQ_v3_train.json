{"id": 106, "date": "2011-10-13", "title": "Spreadsheets on the Move: An Evaluation of Mobile Spreadsheets", "url": "", "keywords": [], "abstract": "he power of mobile devices has increased dramatically in the last few years. these devices are becoming more sophisticated allowing users to accomplish a wide variety of tasks while on the move. the increasingly mobile nature of business has meant that more users will need access to spreadsheets while away from their desktop and laptop computers. existing mobile applications suffer from a number of usability issues that make using spreadsheets in this way more difficult. this work represents the first evaluation of mobile spreadsheet applications. through a pilot survey the needs and experiences of experienced spreadsheet users was examined. the range of spreadsheet apps available for the ios platform was also evaluated in light of these users' needs.", "rq": ["rq 2: to what extent is access to spreadsheets used while away from traditional computing devices?", "rq 3: what issues affect the usability of mobile spreadsheet applications?"], "relatedWork": ": the rapid progression of technology has led to an increase in the number of mobile applications available. although these applications offer a number of advantages in terms of portability and convenience they do so at the cost of usability. zhang and adipat (2005) have highlighted a number of issues that affect the usability of mobile applications: \u2022 mobile context: when considering mobile applications the user is not tied to a single location. this will also include interaction with nearby people, objects and environmental elements which may distract a user's attention. \u2022 connectivity: with mobile devices connectivity is often slow and unreliable and therefore will impact the performance of mobile applications which utilise these features. \u2022 small screen size & different display resolution: in order to provide portability mobile devices contain very limited screen size meaning that the amount of information that can be displayed is drastically reduced. \u2022 limited processing capability and power: in order to provide portability, mobile devices often contain less processing capability and power. this has the effect of limiting the types of applications that are suitable for mobile devices. \u2022 data entry methods: the input methods available for mobile devices are difficult and require a certain level of proficiency. this problem increases the likelihood of erroneous input and decreases the rate of data entry. the above limitations of mobile devices further aggravate existing usability issues in the spreadsheet application. the limited screen size on mobile devices requires the user to perform considerably more navigation when looking at large spreadsheets. this may cause users to find it difficult to conceptualise the overall spreadsheet and to see how the section on-screen fits with this overall picture. flood et al. (2008), have identified navigation as an issue that affects the performance of people debugging spreadsheets through voice recognition technology. by addressing this issue it was found that the performance of users debugging spreadsheets could be increased. it was also found that participants audited more cells with the improved navigation system, which is an important aspect of the debugging process. mobile devices generally do not contain a traditional keyboard as the size required would be too large to enable portability. some devices incorporate a physical keyboard which utilises small keys while other devices use touch screen technology to present a keyboard to the user on screen. these keyboards also require the physical keys to be smaller than traditional keyboards to fit all keys on screen. the ios platform addresses this issue by providing users with three separate keyboards; one containing letters, one containing numbers and some special characters and a third containing additional special characters. chen et al. (2010) conducted an evaluation of users entering text on a small size qwerty keyboard. this evaluation required 15 participants to enter a passage of text using the small sized keyboard. on average participants used 540 keystrokes to enter the passage of text. the most prevalent type of error made by these participants during the task was a key ambiguity error, which occurred when a user entered a character other than the target character. it was found that on average, participants made about 9 key errors on the first typing task. it is also worth noting that all participants made at least one error of this type during the study. errors of this type, when made on a spreadsheet, may result in a misspelled word or in an incorrect reference in a cell formula, which could alter the bottom line value of a spreadsheet substantially. it has been shown repeatedly that even on desktop computers errors like this persist. two independent studies (panko 1998;powell, baker et al. 2009) have found that over 85% of the evaluated spreadsheets contained errors. the limited processing power of portable devices has meant that existing spreadsheet applications may not function correctly when run on these devices. in an attempt to address this issue a number of developers have created spreadsheet apps which scale down the level of functionality to enable users to view and use spreadsheets in a mobile context. most of these applications however, are limited in terms of functions available and spreadsheet size.", "conclusion": "<title>conclusions</title> this research has shown that there is a need for mobile spreadsheet apps. a large proportion of participants surveyed, 78%, have said that they have needed access to spreadsheets while away from traditional computing devices. the primary needs of these users are to view or change existing spreadsheets with only 21% of participants saying they would need to create a spreadsheet on a mobile device. along with examining the need for mobile spreadsheet applications, this work also examined the extent to which existing applications are used. it was found that approximately half of the participants that required access to spreadsheets while away from traditional computing devices have used mobile spreadsheet applications. of these participants only 33% could accomplish their desired task, with a further 50% stating that they could partially complete their task. to better understand why this was the case, the usability of these applications was examined. it was found that existing apps suffer from a number of issues, most predominantly due to the small screen size of most mobile devices. participants' most common complaint of these devices was that the screen size was too small. one participant also remarked that a lack of a global view was a problem. despite these issues, it was found that participants were not dissatisfied with mobile applications. the convenience afforded by the ability to view spreadsheets on a mobile device outweighs the usability issues associated with mobile spreadsheet applications."}
{"id": 207, "date": "2013-10-13", "title": "\"Narco\" Emotions: Affect and Desensitization in Social Media during the Mexican Drug War", "url": "", "keywords": ["affect", "desensitization", "social media", "crisis informatics H5.3. Group and Organization Interfaces", "Asynchronous interaction", "Web-based interaction"], "abstract": "social media platforms have emerged as prominent information sharing ecosystems in the context of a variety of recent crises, ranging from mass emergencies, to wars and political conflicts. we study affective responses in social media and how they might indicate desensitization to violence experienced in communities embroiled in an armed conflict. specifically, we examine three established affect measures: negative affect, activation, and dominance as observed on twitter in relation to a number of statistics on protracted violence in four major cities afflicted by the mexican drug war. during a two year period (aug 2010-dec 2012), while violence was on the rise in these regions, our findings show a decline in negative emotional expression as well as a rise in emotional arousal and dominance in twitter posts: aspects known to be psychological markers of desensitization. we discuss the implications of our work for behavioral health, facilitating rehabilitation efforts in communities enmeshed in an acute and persistent urban warfare, and the impact on civic engagement.", "rq": ["rq 1: how does the expression of na in social media change over time, subject to prolonged violence?", "rq 2: how does the expression of activation in social media change over time, subject to prolonged violence exposure?", "rq 3: how does the expression of dominance in social media change over time, subject to prolonged violence exposure?", "rq 4: how does the level of social media use change over time, subject to prolonged violence exposure?"], "relatedWork": ": there has been an increased interest in hci research in understanding how citizens use social technologies to respond to crises: from natural ones: earthquakes and floods, to manmade ones: wars and terrorist attacks . as social media becomes a prominent communication channel, the motivation to study the use of these platforms during crises, comes in part, from a desire to understand how society copes with those events. our work builds on this prior literature in crisis informatics by investigating how social media can be used to gauge the well-being of a society experiencing prolonged violence. there is limited research in this area e.g., that investigate citizens' affective responses to crisis, even specifically to the mexican drug war , albeit focused on a us border town. however, to our knowledge, the crisis informatics literature, despite studying a wide range of crises (e.g., ), has not examined emotional expression of citizens experiencing urban warfare. our study will investigate emotional responses manifested in social media during a crisis and has implications for public health officials, as social media could potentially be used as a barometer of negative psychological impact on citizens. however, although not related to crisis informatics, recent research on social media use has demonstrated that it can reveal a variety of behavioral and affective trends. kramer utilized posts made on facebook to determine a measure of societal happiness; whereas golder and macy found that positive and negative affect expressed on twitter can replicate known diurnal and seasonal behavioral patterns across cultures. affect and behavior mined from facebook and twitter posts has also been known to be reflective of behavioral and public health concerns . another thread of research relevant to our work comes from psychology, where the impact of trauma and crisis in the society on the affective responses of people has been widely investigated . a critical consequence of a crisis experience is affective desensitization, a well-studied topic in behavioral health domains. researchers have studied how individuals chronically exposed to violence might experience a decrease in affective and even physical reactions . this phenomenon, affective desensitization, is characterized by the numbing of (negative) emotional reactions to events that typically would elicit a strong response, as well as by an increase in aggressive behavior . additionally, research has shown that even brief exposure to violence both in the physical world and through the media (from television, to video games, and the internet), can result in affective desensitization . the rich body of studies on affect due to trauma, and associated desensitization has all been done in laboratory settings, or with surveys, with homogeneous samples. to our knowledge, they have never been investigated with social media. social media provides an opportunity to study whether desensitization to violence can be detected on a macro scale by studying the affective responses of people as a consequence of trauma. due to its archival record, reactions to societal violence can be tracked longitudinally. weaving together these observations from prior work, along with the known unique context of social media use in mexico as a mechanism of expression during the ongoing armed conflict provides us an opportunity to study the affective responses of people enmeshed in the chronic violence, and the possible manifestation of desensitization on twitter.", "conclusion": "<title>conclusion</title> through a large-scale quantitative study around the mexican drug war, we have demonstrated the nature of affective changes in social media posts by people exposed to this protracted violence. first, we used official homicide statistics as well as unofficial data (search interest, \"narco\" language use on twitter, activity on and visibility of a prominent \"narco\" blog) to establish factual evidence of ongoing violence in four major mexican cities in 2010-12. thereafter, we quantified the affective responses of people in their twitter posts through the measures negative affect, activation, dominance. while violence was on the rise in our regions of interest, our findings showed a decline in negative affect as well as a rise in emotional arousal and dominance in twitter posts: aspects that are known to be psychological correlates of desensitization. we discussed how our findings may augment mental health related rehabilitation efforts in crisis afflicted communities, and how civic media might need to adapt to address this psychological challenge."}
{"id": 248, "date": "2014-09-04", "title": "MoodBar: Increasing new user retention in Wikipedia through lightweight socialization", "url": "https://arxiv.org/abs/1409.1496v1[cs.SI]", "keywords": ["Wikipedia", "online community", "socialization", "user retention", "natural experiment H.5.3 [Information Interfaces]: Group and Organization Interfaces -Collaborative computing", "Computer-supported cooperative work", "Web-based interaction"], "abstract": "socialization in online communities allows existing members to welcome and recruit newcomers, introduce them to community norms and practices, and sustain their early participation. however, socializing newcomers does not come for free: in large communities, socialization can result in a significant workload for mentors and is hard to scale. in this study we present results from an experiment that measured the effect of a lightweight socialization tool on the activity and retention of newly registered users attempting to edit for the first time wikipedia. wikipedia is struggling with the retention of newcomers and our results indicate that a mechanism to elicit lightweight feedback and to provide early mentoring to newcomers improves their chances of becoming long-term contributors.", "rq": ["rq 2:. is reporting feedback associated with a higher productivity by newcomers in the short term?"], "relatedWork": ": besides individual incentives, previous studies also stressed the importance of the initial period of socialization in online groups. a successful early socialization experience is associated with, and sometimes even predicts, increased engagement in mailing lists , newsgroups , social networks , and wikipedia , to cite a few. however, the causal structure between socialization, motivation, and participation is still not entirely clear. strong motivational factors, perhaps in conjunction with individual-level skills , may be the cause for both a successful early socialization stage and a later long-term participation. to further establish a causal connection, controlled and field experiments on groups of limited size have been performed, with encouraging results: sharing in a digital information good is increased by social incentives , personal messages improve the retention of newcomers to wikipedia who had their edits rejected , and top contributors in a q&a community contributed more on the long term if they had received a personalized socialization experience .", "conclusion": "<title>conclusion and future directions</title> our findings provide evidence that early mentoring of newcomers in an open collaboration system through lightweight socialization tools such as moodbar improves their engagement and retention. we found that eliciting feedback via simple ui manipulations is an effective way to reach users who are at the earliest stages of their editing experience and might otherwise be unable to receive mentoring and support (rq 1). we also found that these feedback mechanisms tend to self-select users who have a higher natural propensity to become active contributors (rq 2). finally, we found evidence that early interaction with these feedback mechanisms has a significant, long-lasting effect on the retention of these users (rq 3). considering that experienced contributors perform a large amount of work on wikipedia, we submit that designing interfaces like moodbar could help mitigate the stagnation and newcomer retention problem wikipedia is currently facing. there are a number of limitations and possible research directions that this study did not explore and future research should address. despite the fact that a relative small number of experienced users in the \"response team\" successfully managed to work through a backlog of feedback messages to respond to, our results do not indicate how scalable this approach would be and at what point the ability to socialize a substantially larger number of newcomers would start to break down. we provided evidence that lightweight interaction, based on very short messages and responses, can go a long way in socializing new users but also indicated that the workload was manageable at the current scale. research indicating that canned, depersonalized messages can negatively impact newcomer retention suggests that any attempt to run the moodbar model at a larger scale would need to assess the risk of depersonalized communication . we did not perform any kind of qualitative analysis on the type of messages elicited by newcomers to try and understand how self-reported mood and the specific issues being discussed may be associated with engagement and retention. as a result, we do not know what socialization strategy is the most effective, and what aspect in the socialization process afforded by moodbar drives editor retention. qualitative analysis of messages exchanged in the context of this lightweight process should be compared with findings from previous studies where more in-depth socialization strategies were considered . finally, in this study we only considered newcomers on the english wikipedia. data from other wikipedia language edi-tions indicates that other communities have different retention rates for newcomers. as a result, our findings may not immediately generalize to other wikipedia communities governed by different norms or practices, or composed by a substantially different user demographics. at a broader level, however, our finding applies to any online community where users contribute content, such as ratings, reviews, or photos; wikis are just an example of open collaboration communities and any of these has its own set of norms about contribution. in fact, the problem of socializing a suddenly growing number of newcomers, or \"eternal september\", dates back to the early period of usenet groups. our results thus provide evidence that lightweight socialization tools could make newcomer socialization sustainable in other online communities too. while moodbar was retired as an experiment from the english wikipedia in 2013, it is still in use in other wikimedia projects, so the methodology used in this study could be replicated to other projects to provide an additional validation."}
{"id": 406, "date": "2015-10-13", "title": "Personality, Culture, and System Factors -Impact on Affective Response to Multimedia", "url": "https://arxiv.org/abs/1310.1531", "keywords": [], "abstract": "hilst affective responses to various forms and genres of multimedia content have been well researched, precious few studies have investigated the combined impact that multimedia system parameters and human factors have on affect. consequently, in this paper we explore the role that two primordial dimensions of human factors -personality and culture -in conjunction with system factors -frame rate, resolution, and bit rate -have on user affect and enjoyment of multimedia presentations. to this end, a two-site, cross-cultural study was undertaken, the results of which produced three predictve models. personality and culture traits were shown statistically to represent 5.6% of the variance in positive affect, 13.6% in negative affect and 9.3% in enjoyment. the correlation between affect and enjoyment, was significant. predictive modeling incorporating human factors showed about 8%, 7% and 9% improvement in predicting positive affect, negative affect and enjoyment respectively when compared to models trained only on system factors. results and analysis indicate the significant role played by human factors in influencing affect that users experience while watching multimedia.", "rq": ["rq 4:. how do predictive models perform on the task of automatic assessment of experience of affect and enjoyment of videos?"], "relatedWork": ". related work: there are several studies which aim to predict affective responses to multimedia (see , , for a thorough review). some focus on distilling the influence of specific cinematographic theories , types of segment and shot , the use of colour and connotative space . apart from the works mentioned above, there has been research focused on modeling the different audio-visual features to predict emotions , , , , , . the features used in this work are inspired by those used in the literature, along with certain content-based descriptors which have been shown to perform well in several content understanding tasks , . research on modeling emotional response in videos also often takes into account the facial expressions of viewers , , , , and a range of complementary sensors (e.g., heart rate, eeg) to help measure the evoked emotions , , . however, the extent to which physiological responses capture the subjective intensity of affect (which varies as a consequence of users' innate psychology) is unclear. a consequence of this is that such studies implicitly assume that, given a video, the affect experienced by different users will be more or less the same. this is equally the case with affective video datasets (as seen in table i). however prior research shows that individual differences can lead to varied experiences . to illustrate this, evidence reveals a complex relationship between affective video tagging and physiological signals , , . as such, it is important to consider the subjective nature of affective perception. however, it is to be noted that we do not aim at creating a large-scale video dataset for affective modeling, rather our aim is to understand the influence of users' individual traits on their perception of affect and consequently develop a dataset towards this goal. personality can be a good tool to explore the systematic differences in users' individual traits . one popular model is the five factor model (ffm) . certain traits are considerably influenced by the cultural background to which an individual belongs. shared conceptions and collective norms characterize a local environment, and thereby shape the perception and cognition of those who associate with it. differences in culture have been studied by hofstede et al . six cultural traits constitute the model -masculinity, individualism, uncertainty avoidance index, pragmatism, power distance, and indulgence. both human factors targeted in our study, namely personality and culture, are shown to reliably capture individual differences in multiple domains like language , intonation of voice while speaking , , kind of photos one likes , type of people one befriends , etc. (see for a thorough review). other examples include preference of genre for language learning in different cultures and the respective cultural acceptance of some movie content etc. due to the consistency shown between these human factors and user behaviors, we use them to study how they influence users' experience of affect and enjoyment in multimedia.", "conclusion": "<title>vi. conclusion</title> experience of affect and enjoyment in multimedia is influenced by an intricate interplay between characteristics of stimuli, individuals, and systems of perception. returning to the research questions posed at the outset of the paper, we can now state that: rq1 for positive affect, negative affect and enjoyment, personality and culture respectively represented 5.6%, 13.6% and 9.3% of variance. notwithstanding the fact that these constitute sizeable proportions, follow up studies need to explore other potential contributing factors, such as sensory impairnments/acuity, user cognitive style, and domain expertise . rq2 traits of extraversion, conscientiousness, masculinity and indulgence are significant predictors for positive affect, and agreeableness, neuroticism, conscientiousness and indulgence were important predictors for negative affect. conscientiousness, openness and uncertainity avoidance were significant predictors for enjoyment. rq3 the majority of the movie clips which were enjoyed were also rated high on positive affect, with a small exception of clips having high correlation between negative affect and enjoyment. such behavior is possibly due to the interchange that potentially takes place between human factors (e.g. neuroticism) and media content. rq4 predictive models trained with a mixture of human factors and content, emotion and emotion factors yielded the highest achievement for positive affect, negative affect and enjoyment respectively with an accuracy of 79%, 77% and 76% respectively. it is important to know the impact of human factors on user enjoyment, as this allows one to optimise this latter parameter especially in conditions in which other more traditional forms of adaptation (such as layered adaptation) are difficult/impractical to perform. as highlighted above, results obtained in our study showcase the important part that human factors have on two impartant aspects of user qoe, namely affect and enjoyment. thus, integration of human factors in the optimistic model was shown to have significantly improved modeling performance; however, extended models based on personality and culture did not have impacts of the same magnitude. this means that several other human factors, apart from those taken into consideration in this study such as user behavior in a particular domain of study (e.g. movies rated or images liked) or other psychological constructs like mood etc. , , can be explored. nonetheless, results show that human factors, namely personality and culture, exert an important influence in modeling the experience of affect and enjoyment, indicating that content production and delivery mechanisms should not just take into account multimedia system factors but also human factors, in order to achieve maximal user satisfaction."}
{"id": 561, "date": "2016-10-13", "title": "MODELLING THE INTRUSIVE FEELINGS OF ADVANCED DRIVER ASSISTANCE SYSTEMS BASED ON VEHICLE ACTIVITY LOG DATA: A CASE STUDY FOR THE LANE KEEPING ASSISTANCE SYSTEM", "url": "", "keywords": ["ADAS", "LKAS", "Vehicle activity log data", "Intrusive feeling", "Affective design"], "abstract": "bstract\uf02dalthough the automotive industry has been among the sectors that best-understands the importance of drivers' affect, the focus of design and research in the automotive field has long emphasized the visceral aspects of exterior and interior design. with the adoption of advanced driver assistance systems (adas), endowing 'semiautonomy' to the vehicles, however, the scope of affective design should be expanded to include the behavioural aspects of the vehicle. in such a 'shared-control' system wherein the vehicle can intervene in the human driver's operations, a certain degree of 'intrusive feelings' are unavoidable. for example, when the lane keeping assistance system (lkas), one of the most popular examples of adas, operates the steering wheel in a dangerous situation, the driver may feel interrupted or surprised because of the abrupt torque generated by lkas. this kind of unpleasant experience can lead to prolonged negative feelings such as irritation, anxiety, and distrust of the system. therefore, there are increasing needs of investigating the driver's affective responses towards the vehicle's dynamic behaviour. in this study, four types of intrusive feelings caused by lkas were identified to be proposed as a quantitative performance indicator in designing the affectively satisfactory behaviour of lkas. a metric as well as a statistical data analysis method to quantitatively measure the intrusive feelings through the vehicle sensor log data.", "rq": ["rq 1: what are the types of the intrusive feelings caused by lkas?", "rq 2: is it possible to derive variables, measuring the intrusive feelings objectively, from vehicle log data?", "rq 3: is it possible to quantitatively compare the measured feelings?"], "relatedWork": ": lane keeping assistance system (lkas), one of the adas, detects the lane marker with a front camera and keeps track of the relative position between the vehicle centre and the lane. then, lkas maintains the driving lane and reduces the risk of a lateral collision accident by means of automatic steering angle control using motordriven power steering (mdps) when unintended lane departure is expected (risack et al., 2000;rajamani, 2012;marino et al., 2012). to date, the evaluation of lkas has been based mostly on functional completeness such as lane recognition (mineta et al., 2003) and lane departure rate (hwang et al., 2008). in iso 11270 (2013), which contains performance test procedures, determines success if the outside of the tire does not deviate by more than offset (passenger car: 0.4 m, bus and truck: 1.1 m) from the lane boundary. on the other hand, there are evaluation guidelines that use lateral speed as a performance indicator. the maximum lateral velocity that does not deviate 0.5 m from the boundary of the outer lane is used as the performance index while raising the lateral velocity 0.5 m/s in the straight section (national highway traffic safety administration, 2013). there are also several studies that demonstrate the effectiveness of lkas such as human workload mitigation. tanaka et al. (2000) reported that lkas and adaptive cruise control (acc) were effective in reducing driver workload by measuring vital reaction. blaschke et al. (2009) argued that there be a benefit to the lane keeping assistance function is situations that cause the distraction during actual driving such as phone dialling task. the customer's expectation is now heading towards a holistic experience beyond the functional completeness and effectiveness of the technology. even if lkas is a safety-assisting function, providing the driver with an unfavourable experience may result in the driver turning the function off, which may ultimately render the supporting function useless. therefore, it is very important to design the assistance system considering drive experience, but there is little research on experience and emotion of lkas. eichelberger and mccartt (2016) collected experience on acc, front car warning (fcw), lane departure warning (ldw), and lane keeping assistance (lka), which are representative adas, through telephone interviews from drivers. they pointed out that the most annoying thing is the lka, but there was no further analysis that why they regard it as an annoy, and there was a limit only depending on the driver's memory. this study focuses on the intrusive feelings of lkas to identify factors that adversely influence the driver's affect.", "conclusion": "<title>conclusion & future work</title> designing a system that takes into account user affects is now a crucial issue in the automotive industry. in this paper, we describe the types of intrusive feelings that affect user emotion and build performance indicators to design driver-centric lkas. in addition, exploratory data analysis techniques were applied to real vehicle log data to reveal various patterns and features of intrusive feelings. based on this, we proposed a similarity-based quantitative comparison methodology to help minimise the intrusive feelings. our method is expected to complement the existing vehicle performance evaluation based on traditional survey method. moreover, our method can support designers' efficient for optimal performance because they can see how much performance has improved as they adjust the lkas parameters. our future research will focus on the development of analytics support software that can automatically perform the proposed quantitative analysis. because the vehicle log data is big and massive, automated analysis and evaluation will be highly utilized in the industry. in the near future, various types of intrusive feeling are expected to be found that inhibit the driver 's affect in the automobile industry due to the development of autonomous driving technology. research to identify this and create a better driving experience using massive log data should be conducted in both academia and industry."}
{"id": 582, "date": "2016-10-20", "title": "Information Overload in Group Communication From Conversation to Cacophony in the Twitch Chat", "url": "https://arxiv.org/abs/1610.06497v1[cs.SI]", "keywords": [], "abstract": "nline communication channels, especially social web platforms, are rapidly replacing traditional ones. online platforms allow users to overcome physical barriers, enabling worldwide participation. however, the power of online communication bears an important negative consequence -we are exposed to too much information to process. too many participants, for example, can turn online public spaces into noisy, overcrowded fora where no meaningful conversation can be held. here we analyze a large dataset of public chat logs from twitch, a popular video streaming platform, in order to examine how information overload affects online group communication. we measure structural and textual features of conversations such as user output, interaction, and information content per message across a wide range of information loads. our analysis reveals the existence of a transition from a conversational state to a cacophony -a state of overload with lower user participation, more copy-pasted messages, and less information per message. these results hold both on average and at the individual level for the majority of users. this study provides a quantitative basis for further studies of the social effects of information overload, and may guide the design of more resilient online communication systems.", "rq": ["rq 1:. are there two phases -conversation and overload -in the twitch data?", "rq 5:. can we quantify information overload at the individual level?"], "relatedWork": "elated work: in this section we give a brief survey of relevant literature on attention, information overload, and collective phenomena. because we test our research questions using data from twitch, and because part of the terminology used in the paper draws directly from the lexicon typically used within its community, we provide also a brief survey of research on twitch and video-sharing communities.", "conclusion": ""}
{"id": 676, "date": "2017-08-12", "title": "TraceDiff: Debugging Unexpected Code Behavior Using Trace Divergences", "url": "https://arxiv.org/abs/1708.03786v1[cs.HC]", "keywords": [], "abstract": "ecent advances in program synthesis offer means to automatically debug student submissions and generate personalized feedback in massive programming classrooms. when automatically generating feedback for programming assignments, a key challenge is designing pedagogically useful hints that are as effective as the manual feedback given by teachers. through an analysis of teachers' hint-giving practices in 132 online q&a posts, we establish three design guidelines that an effective feedback design should follow. based on these guidelines, we develop a feedback system that leverages both program synthesis and visualization techniques. our system compares the dynamic code execution of both incorrect and fixed code and highlights how the error leads to a difference in behavior and where the incorrect code trace diverges from the expected solution. results from our study suggest that our system enables students to detect and fix bugs that are not caught by students using another existing visual debugging tool.", "rq": ["rq 1: can tracediff help students identify and fix more bugs than when just using python tutor?", "rq 2: can tracediff help students fix bugs faster than when just using python tutor?"], "relatedWork": ". related work a. automated feedback for programming assignments: intelligent tutoring systems (itss) often supply a sequence of hints that descend from high-level pointers down to specific, bottom-out hints that spell out exactly how to generate the correct solution. for example, in the andes physics tutoring system, hints were delivered in a sequence: pointing, teaching, and bottom-out . itss have been historically expensive and time-consuming to build because they rely heavily on experts to construct hints. recently, researchers have demonstrated how program synthesis can generate some of the personalized and automatic feedback typically found in itss (e.g., , , , ). for example, autograder can identify and fix a bug in an incorrect code submission, and then automatically generate sequences of increasingly specific hints about where the bug is and what a student needs to change to fix it. high-level hints that point to relevant class materials or attempt to reteach a concept can be difficult to automatically generate because they require more context or the deep domain knowledge of a teacher. to leverage the teacher's highlevel feedback at scale, codeopticon provides a tutoring interface that helps teachers provide synchronous feedback for multiple students at once. recent work has also demonstrated how program analysis and synthesis can be used as an aid for a teacher to scale feedback grounded in their deep domain knowledge , . while scaling the return on teacher effort, these systems still require teachers to manually review and write hints for incorrect student work. in contrast to prior work on scaling up teacher-written feedback, this paper focuses on fully automated approaches to provide high-level hints, specifically for the context of writing code. d'antoni et al. have explored the similar design challenge of automatically generated hints for the domain of finite automata . taking inspiration from this work, we aim to generate high-level hints in the domain of introductory programming assignments.", "conclusion": ""}
{"id": 716, "date": "2017-10-13", "title": "Comparing Pedestrian Navigation Methods in Virtual Reality and Real Life", "url": "", "keywords": ["Virtual Reality", "Navigation", "Multi-Modal Interaction"], "abstract": "mobile navigation apps are among the most used mobile applications and are often used as a baseline to evaluate new mobile navigation technologies in field studies. as field studies often introduce external factors that are hard to control for, we investigate how pedestrian navigation methods can be evaluated in virtual reality (vr). we present a study comparing navigation methods in real life (rl) and vr to evaluate if vr environments are a viable alternative to rl environments when it comes to testing these. in a series of studies, participants navigated a real and a virtual environment using a paper map and a navigation app on a smartphone. we measured the differences in navigation performance, task load and spatial knowledge acquisition between rl and vr.", "rq": ["rq 1: how does the locomotion, the vr environment and the navigation method influence participants navigation performance?", "rq 2: how can we improve upon these factors and bring vr navigation and rl navigation closer together?"], "relatedWork": ": there is a large body of related work studying various aspects of pedestrian navigation. researchers are interested in navigation strategies and performance , task load or spatial knowledge acquisition during navigation . there is also a long tradition of building novel and multimodal navigation prototypes and comparing them to existing techniques such as turn-by-turn navigation on a mobile device or paper map, using field studies. but evaluating navigation tasks in laboratory settings is also becoming more common. virtual environments (ves) with different levels of immersion and locomotion techniques have been a widely used tool in those studies. cliburn for example used three large projection screens oriented at 120 degree angles to conduct an experiment exploring the use of dynamically placed landmarks as navigation aids. subjects used a gamepad to move and rotate through the ve and interact with the system. for pedestrian street crossing simulations, deb et al. and feldstein et al. conducted studies in vr using low cost hmds with real walking in a small tracking space. large screens, projections or hmds are ways to improve the visual immersion that before was restricted to regular computer screens. nevertheless there was already extensive research being conducted on navigation that used the benefit of a lab environment even with basic computer monitors.", "conclusion": "<title>discussion & conclusion</title> in our study we compare navigation performance, task load and spatial knowledge acquisition using a paper map and smartphone in rl and vr respectively. overall the results between vr and rl were significantly different in navigation performance, task load and landmark recognition. route recognition, however, was not significantly different in both rl and vr. still challenges and problems are to overcome until vr environments can fully replace rl for navigation in an experiment setting. the following discussion will therefore highlight how the locomotion, the vr environment and the navigation method influence participants navigation performance (rq1). we also present guidelines (see figure 5) on how we can improve upon these factors and bring vr navigation and rl navigation closer together (rq2). locomotion wip proved to be the most natural locomotion technique from the ones that were tested in our pre-study, but that doesn't mean that it doesn't come with drawbacks that need to be discussed. mcmahans framework for interaction fidelity analysis (fifa) rates wip slightly above mid-fidelity and found that mid-fidelity interactions mostly perform worse than high-as well as low-fidelity interaction . although their implementation differed slightly from ours we would rate our implementation similarly and see the following challenges for pedestrian navigation: the movement times in figure 3 suggest that participants were overall faster in the vr conditions compared to the rl conditions. this could be an artefact of the factor translating the up and down movement into forward motion while using our wip implementation. to better control this in future studies we suggest taking individual walking speed measure in the beginning of both the vr and rl condition. that way experimenters know how much the speed gets in-or decreased in vr on an individual basis. another thing we noted was, that participants sped up during the second vr condition as they got used to wip and tried to exploit the locomotion technique (e.g. jogging, walking through objects). this could be dealt with using the before measured walking speed as a reference and prohibit deviating too much from it."}
{"id": 764, "date": "2017-10-13", "title": "Map-Based Visualization of 2D/3D Spatial Data via Stylization and Tuning of Information Emphasis", "url": "", "keywords": ["\u2022 Information systems \u2192 Geographic information systems", "Search interfaces", "\u2022 Human-centered computing \u2192 Visualization", "Search Results Visualization", "2D/3D Geographical Maps", "Opacity Tuning", "Visual Information Filtering"], "abstract": "n geographical information search, map visualization can challenge the user because results can consist of a large set of heterogeneous items, increasing visual complexity. we propose a novel visualization model to address this issue. our model represents results as markers, or as geometric objects, on 2d/3d layers, using stylized and highly colored shapes to enhance their visibility. moreover, the model supports interactive information filtering in the map by enabling the user to focus on different data categories, using transparency sliders to tune the opacity, and thus the emphasis, of the corresponding data items. a test with users provided positive results concerning the efficacy of the model.", "rq": ["rq 2: can opacity tuning help the user focus on relevant information during the analysis of geographical search results, with respect to visualizing data with a fixed opacity, the same for every category?"], "relatedWork": "background and related work: in , hu et al. point out that \"empirical studies show that visualization technologies, such as 2d maps and 3d virtual environments, can facilitate participants' learning and understanding in decisionmaking, especially spatial decision-making, processes\"; e.g., see . 2d and 3d visualization were used in web collaborative gis; e.g., see ), and . in general, it is not clear whether 3d maps are superior to 2d ones in different application domains. reported that, in a tourist and navigation support service for mobile devices, 3d maps had advantages over 2d ones, but they might not provide much benefit for experienced 2d map users. concerning map readability and learnability, canham and hegarty advocate minimality in graphical interface design: \"graphics should not display more information than is required for the task at hand\". earlier, built on hegarty's prior work and reported that \"individual differences in the ability to learn from simple maps, figures, and diagrams are a product of both domain-specific knowledge and general visual spatial abilities\". moreover, the addition of perceptual detail in a navigation interface (route map) impacts on map learning, depending on the user's spatial abilities . recent work investigates the adaptation of information visualization to the user's characteristics . some works attempt to reduce the complexity of geographical maps through abstraction. e.g., proposes hierarchical route maps representing less or more detailed views. varies the width of linear geometries (runs of pistes) to highlight the most relevant results. other works exploit transparency to overlay different types of information on maps , to combine an attribute setting mechanism with the visualization of a background working area , to merge maps in an overlay model , or to provide translucent layers for map exploration . in comparison, we employ transparency to enable the user to focus maps on subsets of information. visual interfaces are adopted in information retrieval to provide overviews and help the comprehension of information; e.g., . some works attempt to improve the presentation of results by displaying them in 3d maps, explicitly representing geographical, temporal, semantic, or other types of relations; e.g., . other works reduce visual complexity through sketching , which seems to support user engagement. we employ 2d/3d maps to represent the geographic extension of information, using a symbolic, stylized representation of data categories, in the tradition of parish maps and community mapping . however, the shapes of our model do not recall handy sketching.", "conclusion": "<title>conclusions</title> we presented a visualization model for representing geographical information search results on 2d/3d maps. the model stylizes results, using their geometries, and represents them in vivid colors to enhance their discernibility. moreover, it introduces transparency sliders to modify the opacity of data in the map. a user test has shown that emphasizing search results through coloring, stylization and opacity tuning helps finding relevant information. furthermore, transparency sliders are an efficacious tool to focus maps on specific information needs. this work was funded by projects mimosa (\"progetto di ateneo torino_call2014_l2_157\", 2015-17), \"ricerca locale\" and \"ricerca autofinanziata\" of the university of torino."}
{"id": 912, "date": "2018-05-03", "title": "Does Journaling Encourage Healthier Choices? Analyzing Healthy Eating Behaviors of Food Journalers", "url": "https://arxiv.org/abs/1805.01129v1[cs.SI]", "keywords": ["Healthy Eating", "Eating Behaviors", "Food Journals", "Quantified Self"], "abstract": "past research has shown the benefits of food journaling in promoting mindful eating and healthier food choices. however, the links between journaling and healthy eating have not been thoroughly examined. beyond caloric restriction, do journalers consistently and sufficiently consume healthful diets? how different are their eating habits compared to those of average consumers who tend to be less conscious about health? in this study, we analyze the healthy eating behaviors of active food journalers using data from myfitnesspal. surprisingly, our findings show that food journalers do not eat as healthily as they should despite their proclivity to health eating and their food choices resemble those of the general populace. furthermore, we find that the journaling duration is only a marginal determinant of healthy eating outcomes and sociodemographic factors, such as gender and regions of residence, are much more predictive of healthy food choices.", "rq": ["rq 2: how do the eating behaviors of food journalers significantly differ across sociodemographic groups?", "rq 3: to what extent does the journaling practice influence the eating behaviors of food journalers?"], "relatedWork": "2.1 personal informatics and food journaling: much research in personal informatics has focused on characterizing the use of tools and technologies to track one's own personal data for self-discovery and behavior change in a variety of domains . in particular, a few researchers have explored the use of mobile food journals and other online tools for dietary self-tracking in recent years . cordeiro et al. identified several key challenges related to the journaling tools and practices, such as unreliable data and negative nudges . to overcome tracking burden and promote mindful eating, epstein et al. proposed a lightweight food journal . recently, chung et al. studied the practice of food tracking amongst instagram users and the role of social support on their healthy eating pursuit. our work is complementary to previous food journaling research . while many studies aimed to qualitatively characterize various aspects of the self-tracking practices, few studies have taken a computational approach to examine the broader impacts of journaling on the healthy eating behaviors of food journalers. in this study, we analyze more than 1 million food diary entries to quantitatively assess the behavioral impacts of journaling.", "conclusion": "<title>conclusion</title> in this study, we investigated the healthy eating behaviors of my-fitnesspal food journalers. despite the claim about the benefit of journaling in promoting healthier choices, we found that most food journalers did not eat more healthful diets than the general public. first, much of their dietary consumption did not meet the daily recommended intakes of healthy and unhealthy food sources. next, their dietary patterns were not as uniform as we initially expected and the distinct patterns mostly resembled those of the general populace who may be less health conscious. moreover, journaling duration, which was previously shown to be associated with improved weight loss outcomes, appeared to have a marginal influence on the healthy eating behaviors, whereas gender, lapsing frequency, and regions of residence are much more predictive of the healthy eating outcomes."}
{"id": 948, "date": "2018-07-16", "title": "Human Perception of Surprise: A User Study", "url": "https://arxiv.org/abs/1807.05906v1[cs.IR]", "keywords": ["Computational surprise, expectancy violation"], "abstract": "nderstanding how to engage users is a critical question in many applications. previous research has shown that unexpected or astonishing events can attract user attention, leading to positive outcomes such as engagement and learning. in this work, we investigate the similarity and differences in how people and algorithms rank the surprisingness of facts. our crowdsourcing study, involving 106 participants, shows that computational models of surprise can be used to artificially induce surprise in humans.", "rq": ["rq 1: can computational models of surprise match users' perceptions, when ranking facts by their surprisingness?", "rq 2: how does a participant's knowledge of a fact relate to its surprisingness?"], "relatedWork": ": although surprise has long been considered a subjective quantity primarily based on or influenced by personal feelings, tastes, or opinions , there is significant work on quantifying surprise as an objective measure. existing techniques can roughly be classified into the following two categories. shannon surprise: shannon surprise uses information content as a measure of surprise, based on the frequency with which words appear in a language model. uncommon words occurring together are more likely to be informative and induce higher levels of surprise. surprisingness s(w) associated with a single word w can be represented as the reciprocal of its probability of occurrence p(w), so that s(w) = 1/p(w). this formulation can be extended to a complete sentence by summing over the logarithms of the reciprocal probabilities of all words in the sentence. thus, surprisingness of a statement containing n words {w 1 , . . . , w n } with corresponding probabilities {p 1 , . . . , p n } can be computed as: s = \u2212 (p 1 log (p 1 ) + p 2 log (p 2 ) + . . . + p n log (p n )) this definition of surprise is similar to the calculation of entropy which gives a logarithmic measure of the number of states with significant probability of being occupied. therefore, according to shannon theory, unlikely events are more likely to be surprising. inspired by shannon's definition of surprise, lin et al. used the ratio of assertion frequency to object frequency to find distinguishing assertions. they defined assertion frequency as the total number of times an assertion occurs and object frequency as the number of times the object appears in a sample of ten million random textrunner assertions. exman et al. broadly defined interestingness as a composition of relevance (to a domain area) and unexpectedness. in a similar manner, tsurel et. al. defined surprisingness of an article as the inverse of the average similarity to other articles in a category . bayesian surprise: the problem with shannon surprise is that it uses 'unlikely' events as a proxy for 'unexpected' events. in real life, an event can be unlikely without being unexpected: for example, the possibility of seeing a black cat sitting on a white bench is unlikely but not unexpected, and hence not surprising. shannon surprise also does not account for prior beliefs of users and how people's baseline knowledge affects their perception of surprise. the bayesian model of surprise handles such limitations by measuring the differences between posterior and prior beliefs of people and describes how data affects natural or artificial observers. the bayesian definition of surprise gives a consistent formulation of computational surprise under minimal axiomatic assumptions. like shannon surprise, bayesian surprise also considers surprise as an information-theoretic concept which can be derived from first principles and formalized analytically across spatio-temporal scales, sensory modalities, and more generally, data types and data sources. the bayesian framework to quantify surprise uses probabilistic concepts to cope with uncertainty and considers prior and posterior distributions to capture subjective expectations. itti and baldi defined bayesian surprise as the kullback-leibler (kl) divergence between the prior \u03c0 0 (\u03b8 ) and the posterior \u03c0 (\u03b8 |x ) beliefs about the model parameters \u03b8 either in the form s bayes (x ; \u03c0 0 ) = d k l , or in the mirror form d k l . their previous work has explored the effect of bayesian surprise on attention , but little is known about how these computational models of surprise work with human users.", "conclusion": "<title>conclusions</title> in this paper, we report findings from a user study where participants are asked to rate and rank the surprisingness of facts, and compare their ranking of surprise against those generated by algorithms. results show that both algorithms we investigated perform well in terms of finding facts that are also perceived to be surprising by users. qualitative analysis reveal that surprise strongly depends on individual differences in prior knowledge and assumptions; at the same time, some facts can also be generally surprising or unsurprising to the crowd."}
{"id": 960, "date": "2018-08-01", "title": "How Does Tweet Difficulty Affect Labeling Performance of Annotators?", "url": "https://arxiv.org/abs/1808.00388v1[cs.HC]", "keywords": ["crowdsourcing", "tweet difficulty", "label reliability", "human factors", "sentiment analysis"], "abstract": "rowdsourcing is a popular means to obtain labeled data at moderate costs, for example for tweets, which can then be used in text mining tasks. to alleviate the problem of low-quality labels in this context, multiple human factors have been analyzed to identify and deal with workers who provide such labels. however, one aspect that has been rarely considered is the inherent difficulty of tweets to be labeled and how this affects the reliability of the labels that annotators assign to such tweets. therefore, we investigate in this preliminary study this connection using a hierarchical sentiment labeling task on twitter. we find that there is indeed a relationship between both factors, assuming that annotators have labeled some tweets before: labels assigned to easy tweets are more reliable than those assigned to difficult tweets. therefore, training predictors on easy tweets enhances the performance by up to 6% in our experiment. this implies potential improvements for active learning techniques and crowdsourcing.", "rq": ["rq 1: meaningful?", "rq 1:. how does document difficulty in the training set affect the performance of resulting predictors in the early phase and in the late phase?"], "relatedWork": "elated work: the most relevant literature for our work addresses how document difficulty, and in particular tweet difficulty, is modeled in crowdsourcing and similar environments. martinez et al. utilize a predictor's certainty to approximate the difficulty of a document . the underlying assumption is that a predictor is less certain about predicting labels for difficult documents. we employ the same idea in this work to derive tweet difficulty heuristically. label difficulty has also been acknowledged and researched in the context of active learning and crowdsourcing . however, gan et al. focus on modeling the difficulty of labeling tasks in crowdsourcing instead of single documents. paukkeri et al. propose a method to estimate a document's subjective difficulty for each user separately based on comparing a document's terms with the known vocabulary of an individual. sameki et al. model tweet difficulty in the context of crowdsourcing where they devise a system that minimizes the labeling costs for micro-tasks by allocating more budget to difficult tweets and less to easy ones. the authors argue that more sentiment makes a tweet more difficult to understand. hence, they formulate the problem of estimating tweet difficulty as a task of distinguishing sarcastic from non-sarcastic tweets. one of the factors that they utilize is annotator disagreement -if more individuals agree on a label, it is considered easier. an approach that is related to this idea in spirit exists for estimating the difficulty of queries : topic difficulty is approximated by analyzing the performances of existing systems -a lower performance indicates more difficult topics. in our work, we also harness annotator disagreement to approximate tweet difficulty -lower annotator disagreement is associated with easier tweets. while our work bears similarities with , the objectives dif-fer: we are explicitly interested in analyzing how tweet difficulty affects the reliability of tweets that annotators assign, while sameki et al. employ tweet difficulty as a feature to predict the number of annotators who should label the tweet. furthermore, we combine worker disagreement with two more factors to model tweet difficulty. another related approach is described in where the authors propose a probabilistic method that takes image difficulty and crowd worker expertise into account to derive a ground truth -the authors show that this idea is more accurate than majority voting. however, they do not consider that workers learn during a labeling task. in addition, we focus on analyzing how the performance of predictors is affected by tweet difficulty. although we are investigating tweet difficulty in crowdsourcing, we do not analyze any online crowdsourcing activity on tweets, because we first need to know how annotators behave in a fully controlled experiment, before we include the uncertainty associated with worker diversity/background knowledge and engagement/disinterest. similarly, in this work we do not discuss human factors, e.g. how worker expertise affects label reliability because we performed an experiment in a controlled environment with volunteers which we consider faithful. likewise, the annotators share a similar background in that they are computer science students. despite tweets being text documents, we do not use any of the proposed methods, e.g. , to model difficulty. this is because tweets are too short to extract meaningful grammatical features and sometimes they even do not contain any well-formed sentences at all. therefore, we model tweet difficulty using the abovementioned heuristics from the crowdsourcing context which correlate intuitively with tweet difficulty.", "conclusion": "<title>conclusion</title> in this preliminary study we examined how tweet difficulty affects the reliability of labels that annotators assign. the experiment we designed to investigate this hypothesis was performed independently in two locations and we obtained consistent empirical results. they suggest that the labels assigned to easy tweets are more reliable, but only if the annotators are familiar with the labeling task, i.e. they had labeled a certain number of tweets before. this observation implies that the performance of predictors could be theoretically enhanced by devising a predictor that can estimate the difficulty of tweets in advance. due to its benefits for crowdsourcing and active learning, we plan to develop a method that employs such a tweet difficulty predictor at its core in the future . another subject for future investigation is the question of diversity in easy tweets: do the easy tweets in a labeling task always suffice to train meaningful predictors?"}
{"id": 962, "date": "2018-08-01", "title": "Studying Preferences and Concerns about Information Disclosure in Email Notifications", "url": "https://arxiv.org/abs/1808.00356v1[cs.HC]", "keywords": ["Notifications", "information disclosure", "privacy", "virtual assistants"], "abstract": "he proliferation of network-connected devices and applications has resulted in people receiving dozens, or hundreds, of notifications per day. when people are in the presence of others, each notification poses some risk of accidental information disclosure; onlookers may see notifications appear above the lock screen of a mobile phone, on the periphery of a desktop or laptop display, or projected onscreen during a presentation. in this paper, we quantify the prevalence of these accidental disclosures in the context of email notifications, and we study people's relevant preferences and concerns. our results are compiled from an exploratory retrospective survey of 131 respondents, and a separate contextual-labeling study in which 169 participants labeled 1,040 meeting-email pairs. we find that, for 53% of people, at least 1 in 10 email notifications poses an information disclosure risk. we also find that the real or perceived severity of these risks depend both on user characteristics and attributes of the meeting or email (e.g. the number of recipients or attendees). we conclude by exploring machine learning algorithms to predict people's comfort levels given an email notification and a context, then we present implications for the design of future contextually-relevant notification systems.", "rq": ["rq 1: how often do email notifications pose an information disclosure risk?"], "relatedWork": "productivity cost in notifications: previous works in notifications mainly focused on the negative impact of interruptions on productivity by quantifying the cost of interruptions and identifying low-cost interruptible moments to send notifications. previous studies show that the cognitive load of current tasks , activity transitions , physical activities and user interactions on devices , and other context such as time and location can be used to identify interruptible moments for notifications. in desktop office settings, fogarty et al. show how sensor-based statistical models can be used to predict one's interruptibility by leveraging features such as: phone use, ambient noise (e.g., to detect in-person conversations), mouse movement, and keyboard keystrokes. likewise, coordinate uses computer activity, calendar information, audio and video signals, and indoor and outdoor location data to predict users' availability. notification policies then use inferred levels of availability and interruptibility to determine the right time to deliver notifications to users. while these systems demonstrate how systems can avoid interrupting users at inopportune times, research has also recognized that there can be costs associated with delaying notifications. as such, notification policies should trade-off the cost of interruption with the cost of delays . our work is distinguished in that we study the privacy cost associated with notifications that disclose some information in social settings, as opposed to most of the previous works focusing on the loss of productivity (e.g. interrupting an important conversation or tasks). the sensitive nature of the problem we study has implications for our methodology for data collection, in which we have taken careful steps to respect respondents' privacy in both study 1 and 2.", "conclusion": "<title>conclusion</title> in this paper, we report results from an exploratory retrospective survey and a larger contextual labeling study. our research necessitated that we ask users to discuss sensitive scenarios. specifically, we asked user to describe sensitive emails, and to discuss why they would feel uncomfortable receiving notifications for those messages when in the presence of others. to this end, we designed our studies to carefully respect participant privacy, and we believe these considerations were instrumental in allowing us to recruit a combined total of 300 individuals. from these individuals, we learned: \u2022 (rq1) email notifications indeed pose an information disclosure risk. \u2022 (rq2) the real or perceived severity of these risks depend both on user characteristics (e.g. the nature of occupation) and attributes of the meeting or email (e.g., the number of recipients or attendees). \u2022 (rq3) machine-learned models can learn attributes, patterns and signals associated with risky email-meeting pairs. here, user-level features are more informative than generic meeting or email-level features. the best performing models incorporate all features, together with user history. taken together, our findings present a rich picture of notifications, as viewed through the lens of privacy. we hope that our findings will inform the design of future notification-capable systems."}
{"id": 1011, "date": "2018-10-13", "title": "On the Internet, Nobody Knows You're a Dog... Unless You're Another Dog", "url": "", "keywords": ["Animal-Computer Interaction", "Animal Internet", "Design Fiction", "Dog-Computer Interaction"], "abstract": "how humans use computers has evolved from humanmachine interfaces to human-human computer mediated communication. whilst the field of animal-computer interaction has roots in hci, technology developed in this area currently only supports animal-computer communication. this design fiction paper presents animalanimal connected interfaces, using dogs as an instance. through a co-design workshop, we created six proposals. the designs focused on what a dog internet could look like and how interactions might be presented. analysis of the narratives and conceived designs indicated that participants' concerns focused around asymmetries within the interaction. this resulted in the use of objects seen as familiar to dogs. this was conjoined with interest in how to initiate and end interactions, which was often achieved through notification systems. this paper builds upon hci methods for unconventional users, and applies a design fiction approach to uncover key questions towards the creation of animal-to-animal interfaces.\u2022 human-centered computing \u2192 human computer interaction (hci).", "rq": ["rq 1: what would a dog internet look like?", "rq 2: what would these dog-to-dog interactions look like?", "rq 3: how effective is the method of design research for animal-to-animal internet interactions?"], "relatedWork": ": aci investigates how animals interact with technology, among other things, and the design of these technologies . whilst initially aci took primary influences from hci contexts centering around the usability and user experience of the technology towards interactive devices, frameworks have since been developed across areas such as interaction design , game design and ubiquitous computing . recently, as the motivation of animal-computer technologies has often been welfare based , aci also draws from animal behavior and cognition and animal welfare . part of this conversation includes investigating the role and position that the technology plays within the interaction space towards human-animal interactive systems and animalcomputer systems . aci also functions to develop playful systems for animal entertainment and wellbeing where consumer products predominantly exist in the pet sector.", "conclusion": "<title>conclusion</title> as the explosion of the internet and a multitude of devices have allowed for humans to be constantly connected, we speculate that the evolution from human-machine to human-human mediated via machine will happen with non-human animals. this ideation of animal-animal interactions over the web is not a new occurrence, but has yet to be implemented beyond animal-machine interfaces. in this paper we use dogs to explore what dog-to-dog technology mediated interactions would look like. this choice is taken as dogs are currently the key player within animal-computing, taking roles within our homes and workplaces. furthermore, dogs are repeatedly left alone causing potential behavioral issues from lack of socializing creating a need for in-home technology. this study conducted through nine participants in a workshop, uses a design fiction method to produce six scenarios and then further reflecting upon this discursive space. through this co-design, participations raise questions on the technology used to mediate the interaction. these focus on both a human's ability to measure an animal's behavior, and an animal to feed back. drawing from this, further queries are noted around what it means for a dog to interact, if this interaction needs to be asynchronous and what would this interaction look like. we suggest that this problem be tackled through drawing upon more well-researched fields in hci such as child-computer interaction (cci). in conclusion, six design fictions for dog-to-dog interactions are presented; companion-dog, virtual walk, dogflix, tangiball, ropepull and laser collar. in the field of hci, much is made of design fiction to help stimulate conversations around future technology. whilst the dialogues around dog-to-dog interactions hold note towards animal-computing systems, as demonstrated, the conversation held these points of interest (such as feedback loop, agency and technology mediators) ring true towards current hci matters. it is in way that we encourage designers working in this area to draw and engage in currently deployed hci. overall, this study contributes new understandings in the co-design of computer interactions for animal users to connect to other animals, highlighting key questions for both those in aci and hci."}
{"id": 1052, "date": "2018-10-13", "title": "Smartphone Security Behavioral Scale: A New Psychometric Measurement for Smartphone Security", "url": "", "keywords": ["Psychometrics", "Security behavior", "Mobile Devices", "Mental Health"], "abstract": "espite widespread use of smartphones, there is no measurement standard targeted at smartphone security behaviors. in this paper we translate a well-known cybersecurity behavioral scale into the smartphone domain and show that we can improve on this translation by following an established psychometrics approach surveying 1011 participants. we design a new 14-item smartphone security behavioral scale (ssbs) exhibiting high reliability and good fit to a two-component behavioural model based on technical versus social protection strategies. we then demonstrate how ssbs can be applied to measure the influence of mental health issues on smartphone security behavior intentions. we found significant correlations that predict ssbs profiles from three types of mhis. conversely, we are able to predict presence of mhis using ssbs profiles. we obtain prediction aucs of 72.1% for internet addiction, 75.8% for depression and 66.2% for insomnia.", "rq": ["rq 1: how adequate is the application of general computer security behavior measurement to smartphone security?", "rq 4: can mental health issues be potentially leveraged as an important predictor of smartphone security behaviors?", "rq 5: can smartphone security attitudes be potentially leveraged as an important predictor of mental health issues?"], "relatedWork": ": prior works have examined users' perceptions, attitudes, and behaviors toward smartphone security. their findings can be summarized into three realms: the inattentiveness toward security warnings/messages , the misconceptions of smartphone security , and low level of smartphone security behavior . in terms of behavioral measurements, previous studies have assessed users' smartphone security behaviors via two main approaches: field observation and self-reported measurement. for field observations, most studies focus on two aspects: users' authentication and locking behaviors on smart-phones , and users' behaviors on granting access . although field observation can probe into users' actual behaviors in the real world, it usually focuses on a single aspect of the behavior, making it difficult to conveniently gain a comprehensive understanding on users' behaviors in a short period of time. therefore, many studies adopt a self-reported approach to measure users' smartphone security behaviors. there are various means to measure self-reported smartphone security behaviors. the most used approach in prior work is to develop measurements by adapting more general computer security assessments or by modifying a developed measurement from previous studies. for example, das and khan generated a 6-item measure that was adapted from microsoft's computing safety index. jones and chin performed a survey study to investigate students' usage and security behaviors on smartphones by asking seven questions about security practices. a more recent study by thompson et al. designed a five item measure to assess smartphone security behavior in a personal context, which was adapted from a security behavioral assessment in personal computer usage by liang and xue . another recent (2018) survey study by verkijika examined south african users' smartphone security practices by using five questions that were adapted from the measurement developed by thompson et al. . while reviewing developed security measurements, we found that there is no standardized and targeted way to measure smartphone security behavior (or behavior intentions) across different contexts. existing methods are all adopted or adapted from general computer security behavior. however, it is possible that users' smartphone behaviors can deviate from their computer behaviors. for instance, chin et al. found that participants' behaviors and activities on smartphones were quite different from their use of laptops. for example, users were less likely to purchase and perform sensitive tasks on their smartphones because of security concerns regarding mobile devices. we identify two key gaps in the current literature: 1) there is no standardized measurement of smartphone security behaviors across contexts; 2) it remains unclear if general computer security behavior measurements is adequate to apply to assess smartphone security behaviors. thus, a key goal of this study is to develop a standardized and valid measurement of smartphone security behavior intentions that can be used in different contexts. toward this goal, we ask the following concrete research questions: \u2022 rq1: how adequate is the application of general computer security behavior measurement to smartphone security? \u2022 rq2: if the application of computer security behavior is not adequate, can we develop a measurement tool which can capture smartphone security behavior intentions?", "conclusion": "<title>conclusion</title> in this work we found that smartphone security behavior differs from general security behavior. driven by this, we carried out a series of factor analyses to create a smartphone security behavior scale (ssbs) with 14 questions that load onto two factors: technical (using technical strategies to protect smartphones) and social (being contextually cautious while using smarpthones). our scale exhibited satisfactory psychometric properties: the full scale and both the subscales have high internal consistency, all items map uniquely on one single component, and no correlation exists between the subscales. we establish convergent validity between ssbs and a well established security behavior measurement. to showcase the application of ssbs we perform a first-of-its-kind analysis of the effects of popular mental health issues (mhis) in smartphone security behavior intentions. we found that individuals with high depression indicators are significantly more likely to use technical strategies to protect their smartphones than individuals with low depression indicators; while individuals with low internet addiction indicators are significantly more likely to use social strategies than those with high internet addiction indicators. lastly we show that smartphone security behavior intentions can be potentially leveraged to profile individuals according to mhis and illustrate how the most important behaviors for this task can be monitored by a thirdparty application on the most popular mobile operating system (android)."}
{"id": 1106, "date": "2018-10-13", "title": "CoachAI: A Conversational Agent Assisted Health Coaching Platform", "url": "https://arxiv.org/abs/1802.09100", "keywords": ["eHealth coaching", "chatbot", "validation study", "physical activity", "healthy diet", "mental wellness", "persuasive technology"], "abstract": "poor lifestyle represents a health risk factor and is the leading cause of morbidity and chronic conditions. the impact of poor lifestyle can be significantly altered by individual behavior change. although the current shift in healthcare towards a long-lasting modifiable behavior, however, with increasing caregiver workload and individuals' continuous needs of care, there is a need to ease caregiver's work while ensuring continuous interaction with users. this paper describes the design and validation of coachai, a conversational agent-assisted health coaching system to support health intervention delivery to individuals and groups. coachai instantiates a text-based healthcare chatbot system that bridges the remote human coach and the users. this research provides three main contributions to the preventive healthcare & healthy lifestyle promotion: (1) it presents the conversational agent to aid the caregiver; (2) it aims to decrease caregiver's workload and enhance care given to users, by handling (automating) repetitive caregiver tasks; and (3) it presents a domain-independent mobile health conversational agent for health intervention delivery. we will discuss our approach and analyze the results of a one-month validation study on physical activity, healthy diet and stress management.", "rq": ["rq 1: what is the overall user experience of using coachai system?", "rq 4: how much do users prefer a direct human agent support or to what extent does the chatbot agent satisfy their needs?"], "relatedWork": "elated work: promoting individual's behavior has been shown to be quite a challenging task . to ease this burden while improving the care process, a study by ibrahim et al., developed a multi-agent platform to automate the process of collecting patient-provided clinical outcome measures without clinician's intervention. health coaching approaches are widely adopted in various health domains to monitor cardiac rehabilitation , promote physical activity at home for elderly , medication adherence , assist pregnant women , promote healthy diet , support individuals with spinal cord injury and assist with hand therapy . health coaching may vary in their techniques to tackle health issues. that said, most provide remote monitoring to patients through either a smartphone, sensors or wearable trackers. health coaching is either fully automated (virtual agent), fully manual (human agent) or semi-automated (a combination of the two). some coaching systems can be text-based , whereas others use an avatar or speech-powered agents . despite the abundance of health tracking and monitoring systems, tailored coaching and personalized feedback techniques are still in their infancy. a study by villalonga et al., presented an ontologybased approach to model tailored motivational messages for physical activity promotion. the ontology messages can be categorized into multiple classes e.g., sedentary, mild or vigorous activities. for example, a mild activity class is defined as \"messagecomponent \u2229 \u2203hasaction.(action \u2229 (\u2203hasintensity.double))\". similarly, boratto et al., provided an overview of an e-coaching system designed for runners. the platform stimulates individual's motivation to exercise provided through the coach-user interaction engagement. the results showed users tendency to be more engaged to train when their trainings are developed and remotely supervised by a human coach. the findings showed that e-coaching systems may benefit from considering the support of qualified professionals. the role of mobile apps to facilitate behavior change has shown promising results in providing rich context information including an objective assessment of physical activity level and information on the emotional and physiological state of the person . current health coaching systems integrate ai-based chatbot powered with machine learning and natural language understanding . such systems are flexible and can respond to users' requests. finally, to enhance user's engagement with health coaching system persuasive techniques and gamification design elements can be integrated within the dialog model . our approach in coachai differs from existing literature in the technical and design aspects. rather than relying on sms services, we used a natural conversation to interact with users, delivered by the conversational agent. a substantial body of evidence spanning several years of research demonstrates that text-messaging interventions have positive effects on health outcomes and behaviors . most mobile apps and wearable trackers suffer from user abandonment. instead of a standalone app or wearable tracker, we use a chatbot inside a messaging app to handle most user interactions and use the wearable tracker as a supportive tool, rather than the main tool to gather user health data. building a free conversation-style dialog model with deep learning still has its limitations in terms of conversation accuracy and context relevancy. we relied on a task-oriented finite state machine architecture to handle the chatbot dialog. chatbot systems are still emotionless, hence a human in the loop can cover this part and provide supports beyond the technical capabilities or in domains such as healthcare where precision is important. the presence of a human-in-the-loop avoids the shortcomings of pure agent-based control, affording an experience in which the system responds appropriately to both verbal and nonverbal cues in dialogues with a user. self-assessment of how one handled different situation and a feedback about one's performance from a coach enhances learning from the experience.", "conclusion": "<title>conclusion and future work</title> existing health applications for lifestyle promotion mostly focus on handling user's condition and recommending activities and plans to improve their condition. we took a different approach and focused first on increasing the caregiver's time efficiency and decrease their fatigue during user follow up, and hence improving the efficiency of care. conversational agent powered health coaching systems can offer a lot of benefit to the mhealth domain both for healthcare providers and patients. chatbots cannot replace what humans are good at, but they can provide an interesting channel to support patients in delivering services through a simple conversation delivering personalized care. our system was evaluated in a one-month validation study, where participants interacted with the chatbot on different health related topics provided with the health coaching portal and providing them with clinically validated health activities. the study provided a set of dimensions when building chatbot powered health intervention tools. the results validated some of the questions and provided interesting insights when using conversational agents in health coaching systems. future work will try to overcome some of the limitations emerged during the experiment. to identify patterns of use among participants, we plan to analyze the log data from the experiment. this will help understand when participants interact with the chatbot, hence identify a fingerprint for their optimal notification timing. finally, a randomized control trial experiment with/without a human coach (with control and intervention group) will validate if users perform more activities when supervised by a human agent over the chatbot agent."}
{"id": 1107, "date": "2018-10-13", "title": "Outlining the Design Space of Explainable Intelligent Systems for Medical Diagnosis", "url": "https://arxiv.org/abs/1712.09923", "keywords": ["Explainable artificial intelligence", "human-centered design", "medical data", "system design H.5.m. Information interfaces and presentation (e.g., HCI): Miscellaneous"], "abstract": "he adoption of intelligent systems creates opportunities as well as challenges for medical work. on the positive side, intelligent systems have the potential to compute complex data from patients and generate automated diagnosis recommendations for doctors. however, medical professionals often perceive such systems as \"black boxes\" and, therefore, feel concerned about relying on systemgenerated results to make decisions. in this paper, we contribute to the ongoing discussion of explainable artificial intelligence (xai) by exploring the concept of explanation from a human-centered perspective. we hypothesize that medical professionals would perceive a system as explainable if the system was designed to think and act like doctors. we report a preliminary interview study that collected six medical professionals' reflection of how they interact with data for diagnosis and treatment purposes. our data reveals when and how doctors prioritize among various types of data as a central part of their diagnosis process. based on these findings, we outline future directions regarding the design of xai systems in the medical context.", "rq": ["rq: how do medical professionals interact with patients' data for diagnosis and/or treatment purposes?"], "relatedWork": "background & related work: in this section, we first lay out a background review on xai research, and then zoom into an hci-oriented approach towards xai. since our focused field is in medicine, we further discuss prior work in medical ai, and specifically copying permitted for private and academic purposes. this volume is published and copyrighted by its editors. related to our interest-literature on the reasoning process of medical professionals.", "conclusion": ""}
{"id": 1110, "date": "2018-10-13", "title": "PerfVis: Pervasive Visualization in Immersive Augmented Reality for Performance Awareness", "url": "", "keywords": [], "abstract": "evelopers are usually unaware of the impact of code changes to the performance of software systems. although developers can analyze the performance of a system by executing, for instance, a performance test to compare the performance of two consecutive versions of the system, changing from a programming task to a testing task would disrupt the development flow. in this paper, we propose the use of a city visualization that dynamically provides developers with a pervasive view of the continuous performance of a system. we use an immersive augmented reality device (microsoft hololens) to display our visualization and extend the integrated development environment on a computer screen to use the physical space. we report on technical details of the design and implementation of our visualization tool, and discuss early feedback that we collected of its usability. our investigation explores a new visual metaphor to support the exploration and analysis of possibly very large and multidimensional performance data. our initial result indicates that the city metaphor can be adequate to analyze dynamic performance data on a large and non-trivial software system.", "rq": ["rq: how can visualization support developers in the analysis of the impact of source code changes to the performance of a system?"], "relatedWork": ": a number of 3d visualization tools have been proposed to support software development concerns. seeit 3d uses a 3d scatter plot visualization to represent software metrics collected from java source code to support developers on software comprehension tasks. synchrovis employs a visualization based on the 3d city metaphor that displays the structure and metrics of software systems, as well as program traces and synchronization aspects (e.g., semaphores/wait) to support the analysis of the behavior of concurrent software systems. these tools display the 3d visualization on a standard computer screen and focus on performance data collected using static analysis. in contrast, we propose the visualization to be displayed in immersive augmented reality and focus on live performance data collected using dynamic analysis. there are some visualization tools that use virtual reality to support software comprehension tasks. code park proposes an immersive visualization of software metrics and source code; an evaluation showed that the visualization displayed in virtual reality excels at usability and significantly helps in code understanding. explorviz introduces a visualization of software landscapes to support software comprehension tasks. cityvr gamifies software implementations using a 3d city visualization displayed in virtual reality to boost developer engagement. in contrast, we propose the use of immersive augmented reality to improve the awareness of the impact of changes on the source code to the performance of software systems. moreover, some of these tools focus on various static software metrics, as opposed to our tool that includes the visualization of dynamic live performance data. several existing performance visualizations focus on the analysis of static performance data. jove is a visualization tool for monitoring the performance of java programs. using the visualization, developers can obtain details on demand to identify routines and threads in which the application spends much time. \u25cb the complementary scatter plot that maintains the history of the overall performance of the system for a configurable interval of time. another tool includes the visualization of the structure of parallel software systems. the visualization uses an execution graph to simplify the analysis of the complex run-time behavior. moreta and telea present a visualization of the behavior of the memory allocator in c programs to optimize functionality, decrease fragmentation, and improve response time. another tool facilitates the visualization of software performance in real-time, using the city metaphor to show the structure and performance of a program. the buildings in the city represent the classes in the system, and the heights of the buildings represent the number of times the methods of a class are called during execution. all these tools support the analysis of various aspects of software performance through visualizations displayed on a standard computer screen. in contrast, we rely on immersive augmented reality to display our visualization. a few software visualizations chose augmented reality as a display medium. one study evaluated a city visualization displayed in immersive augmented reality to support software comprehension tasks. another study used the city metaphor in augmented reality to support the analysis of software evolution. in contrast, we propose a city-based visualization using immersive augmented reality to support software performance tasks, which is an innovative and not-yet explored approach.", "conclusion": "<title>conclusion and future work</title> we introduced perfvis, a visualization tool displayed in immersive augmented reality that supports developers in the analysis of software performance. we elaborated on design choices and discussed implementation details, lessons learned, and early impressions of developers who used prototypes of our visualization tool. in the future, we plan to conduct a thorough evaluation of perfvis to identify strengths and improvement opportunities."}
{"id": 1117, "date": "2018-10-13", "title": "Fragments of the Past: Curating Peer Support with Perpetrators of Domestic Violence", "url": "https://arxiv.org/abs/2005.14341", "keywords": ["Domestic Violence", "Intimate Partner Violence", "Violence Prevention", "Peer Support Networks", "Digital Civics", "Social Care First Author's Name, Initials, and Last Name, Second Author's Name, Initials, and Last Name, and Third Author's Name, Initials, and Last Name. 2018. The Title of the Paper: ACM Conference Proceedings Manuscript Submission Template: This"], "abstract": "here is growing evidence that digital peer-support networks can have a positive influence on behaviour change and wellbeing outcomes for people who harm themselves and others. however, making and sustaining such networks are subject to ethical and pragmatic challenges, particularly for perpetrators of domestic violence whom pose unique risks when brought together. in this work we report on a ten-month study where we worked with six support workers and eighteen perpetrators in the design and deployment of fragments of the past; a socio-material system that connects audio messages with tangible artefacts. we share how crafting digitally-augmented artefacts -'fragments' -of experiences of desisting from violence can translate messages for motivation and rapport between peers, without subjecting the process to risks inherent with direct inter-personal communication. these insights provide the basis for practical considerations for future network design with challenging populations.", "rq": ["rq 1:. how can digital peer-support be configured to safely accomodate perpetrators of domestic violence after the conclusion of a domestic violence perpetrator programme?", "rq 2:. how might digital peer-support processes be designed to address ethical concerns around potential negative feedback loops for perpetrators of domestic violence?"], "relatedWork": "background and related work: peer support is a process where people who share common experiences or face similar challenges come together to give and receive help based on the knowledge derived from shared experience . importantly, peer support can positively benefit both the person receiving support and can make the provider feel valued, needed and included . peers can also influence the behaviour of other group members that can be prosocial or harmful , or be a combination of the two . moreover, peer support can transcend or extend traditional social care delivery settings, making it a viable option to reach minority or marginalised populations including people impacted by domestic violence . such a process can be delivered through one-onone support by a trained peer, team-based support, or peer-ran groups ; be organically occurring (i.e. a spontaneous connection between people) or structured by a professional provider ; and be mediated with or without digital technologies .", "conclusion": "<title>conclusion</title> in this paper we outlined the benefits that peer support mechanisms can provide to individuals following behaviour change interventions for harmful behaviour and the challenges encountered with the creation and"}
{"id": 1127, "date": "2018-10-13", "title": "Information search in a professional context -exploring a collection of professional search tasks", "url": "", "keywords": ["Professional search", "complex search tasks", "data collection"], "abstract": "search conducted in a work context is an everyday activity that has been around since long before the web was invented, yet we still seem to understand li le about its general characteristics. with this paper we aim to contribute to a be er understanding of this large but rather multi-faceted area of 'professional search'. unlike task-based studies that aim at measuring the e ectiveness of search methods, we chose to take a step back by conducting a survey among professional searchers to understand their typical search tasks. by doing so we o er complementary insights into the subject area. we asked our respondents to provide actual search tasks they have worked on, information about how these were conducted and details on how successful they eventually were. we then manually coded the collection of 56 search tasks with task characteristics and relevance criteria, and used the coded dataset for exploration purposes. despite the relatively small scale of this study, our data provides enough evidence that professional search is indeed very di erent from web search in many key respects and that this is a eld that o ers many avenues for future research.", "rq": ["rq 2:. are these characteristics su ciently pronounced to justify treating professional search as a separate search genre?", "rq 3:. are the needs, goals and behaviours of professional searchers su ciently homogeneous and consistent to justify viewing 'professional search' as a coherent, single eld of enquiry?"], "relatedWork": "background and related work: collections of professional search tasks. most collections of search tasks have been created in the context of trec. a few of the relevant tracks for professional search are the total recall track, the enterprise track, and the legal track. trec collections have been designed for evaluation purposes; they have shown to be indispensable for system comparisons and benchmarking. to the contrary, our collection is not meant for benchmarking purposes. e collection comprises user-created descriptions of a work task, created a er completion of the task. although our work does not contribute a test collection (it has no relevance assessments), the topics in our collection were collected similar to those in the isearch collection , where the searchers themselves (experts) formulated you could help us collecting example search tasks. please describe one search task that you have undertaken recently. please be as speci c as possible (not: \"trying to nd papers\", but \"trying to nd papers that referenced ingwersen and j\u00e4rvelin (2005)\"). \u2022 what was the goal of the search? coding schemes for search tasks. search tasks can be coded in a variety of ways. in early work, bates identi ed a set of 29 search 'tactics' which she organised into four broad categories of information seeking behaviour. ellis and colleagues developed a model consisting of a number of broad information seeking behaviours, noting also that it is possible to display more than one behaviour at any given time. makri et al extended this work, focusing on the information behaviours observed within the legal profession. more recently, russell-rose et al used a grounded-theory approach to identify a taxonomy of information behaviours derived from a corpus of enterprise search tasks. in many of these previous studies of information seeking behaviour, interview transcripts have served as the primary data source, o ering an indirect, verbal account of end user information behaviours. by contrast, the data source used in this study represents a self-reported account of information behaviour, generated directly by end users (albeit retrospectively). relevance criteria. in 1998, rieh and belkin identi ed seven di erent factors of information quality: source, content, format, presentation, currency, accuracy, and speed of loading, and two di erent levels of source authority: individual and institutional. savolainen and kari found in an exploratory study that specicity, topicality, familiarity, and variety were the four most mentioned criteria in user-formulated relevance judgments, but there was a high number of individual criteria mentioned by the participants. we include the relevance factors from these prior works in the scheme for coding the relevance criteria mentioned by our respondents.", "conclusion": "<title>conclusions</title> rq1. to what extent are the characteristics of professional search (a)-(c) re ected by the data acquired in our survey? e results of our survey re ect that the search tasks in professional search are complex and highly speci c, but not necessarily exploratory. e results also show that not every professional searcher is an expert in the search domain; they can also be lis experts. rq2. are these characteristics su ciently pronounced to justify treating professional search as a separate search genre? e characteristics that we found con rm the di erences between professional search and web search mentioned in the literature. ese have implications for the design of professional search systems. first, the nding that many professional searchers search for others means that the searcher may not be in a good position to assess the relevance of results. for that reason it might be a good idea to provide additional information in the interface of the ir system based on possible relevance criteria (e.g. publication date, expertise level) , to aid the user in creating the (short)list for the client. second, the complex information needs of professional searchers, for example in systematic reviews, means that professional searchers are searching for information spread across multiple documents. is means that there is no one particular document that best provides the information, and that there is no clear requirement what document should be ranked rst. e user interface of a professional search system should ideally be adapted for this characteristic, and show a result set covering a diverse set of aspects to the information need. rq3. are the needs, goals and behaviours of professional searchers su ciently homogeneous and consistent to justify viewing 'professional search' as a coherent, single eld of enquiry? based on the data of this research, it seems that the same characteristics of professional search apply to professional searchers from all the domains that participated in our study. further research is required before it can be determined whether all groups can be treated as one eld of enquiry for these purposes. a prominent nding from our survey is the evidence of multiple sources being used -and that the tools do not support this that well. as a result, many di erent search engines are used to search the relevant sources."}
{"id": 1138, "date": "2018-10-13", "title": "A Survey Investigating Usage of Virtual Personal Assistants", "url": "https://arxiv.org/abs/1608.07323", "keywords": ["human-computer interaction, survey"], "abstract": "espite significant improvements in automatic speech recognition and spoken language understanding -human interaction with virtual personal assistants (vpas) through speech remains irregular and sporadic. according to recent studies, currently the usage of vpas is constrained to basic tasks such as checking facts, playing music, and obtaining weather updates. in this paper, we present results of a survey (n = 118) that analyses usage of vpas by frequent and infrequent users. we investigate how usage experience, performance expectations, and privacy concerns differ between these two groups. the results indicate that, compared with infrequent users, frequent users of vpas are more satisfied with their assistants, more eager to use them in a variety of settings, yet equally concerned about their privacy.", "rq": ["rq 1: how do functionality, usage, and satisfaction differ between frequent and infrequent vpa users?", "rq 3: are privacy concerns different between frequent and infrequent vpa users?"], "relatedWork": "elated work: intelligent personal assistants were originally developed to make the interaction with computer systems more human-like, enabling people to use natural language to manage their schedules, and access a variety of tasks and services . the present generation of such assistants (e.g. cortana, siri, etc.), often referred to as voice powered assistants (vpas) is the focus of our study. the growing popularity of vpas and their improved accessibility can be attributed to the latest advances in speech technology. in recent years, the introduction of deep neural networks (dnn) for acoustic and language modelling has made automatic speech recognition (asr) systems more robust , while the implementation of the knowledge graph enhanced the spoken language understanding (slu) capabilities of question answering systems . recent studies in the area addressed usage patterns of virtual assistants and problems with their adoption. the evaluation of vpas focused on different aspects that affect their continued use, such as usage experience , performance expectations , privacy concerns and social acceptability . we discuss these studies and their findings below. usage experience: kiseleva et al. found that users tend to be more satisfied with using vpas for simple tasks (such as device control) rather than more complex, multi-turn tasks (e.g. making travel arrangements etc.) where preserving the context is crucial. despite being comprehensive, the study was limited to one type of virtual assistant (cortana). our survey adopts a broader perspective by probing users satisfaction with a variety of vpas. cowan et al. focused on the experiences of infrequent vpa users and their reasons for not using vpas on a regular basis. the feedback obtained from the focus groups indicates that privacy concerns over data usage, and lack of trust in the assistant's capability to perform the task are some of the main reasons for people not to use the technology on a regular basis. performance expectations: luger and sellen conducted a series of semi-structured interviews (14 participants) to get insights into users' expectations regarding the performance of voice-controlled assistants. it was reported that users' poor understanding of how their vpa worked and lack of device feedback led to frustration and discontinued use. our survey incorporates feedback from a larger (n = 118) and more diverse sample. in a similar study, conducted by sorensen , expectations of novice users were compared between two different chatbot systems (i.e. a human-like and a robot-like system). the results indicated that the system that asked questions, provided feedback and informed user about its current status was perceived as better meeting users performance expectations. while sorensen's study dealt exclusively with text as the input method, in our work we focus on voice interaction. moore et al. analysed the opinions of members of the public expressed in two surveys on spoken language technology. one that compared the opinions of experts and non-experts, and another that evaluated the degree of usage of voice technology on a daily basis. the overall results suggest that the ordinary people (non-experts) are more optimistic about the future capabilities of voice technology. however, poor system accuracy and inadequate language understanding skills prevent regular usage. in current work, we ask our respondents about their perception of their vpa's current language capabilities, and expectations regarding future natural language and conversational capabilities. privacy concerns and social acceptability: easwara and vu ran an online survey study which explored the impact of privacy and social acceptability concerns on the usage of vpas. the results of the study indicated that people were more likely to interact with their devices via voice in private locations and when surrounded by the people who they knew. the two main reasons that participants did not use vpas were privacy concerns and concerns over being judged by other people. another study examining privacy and social acceptability was conducted by efthymiou and halvey in the context of voice based smartwatch search. the findings indicated that voice search has low social acceptability when carried out in front of strangers, mostly due to privacy concerns. our work builds up on previous studies by incorporating questions on respondents' concerns over privacy and social acceptability of vpas when used in private and public spaces. in this paper, we replicate, collate and extend the prior work on vpas to get better understanding of current usage and factors that drive vpa adoption. our focus is to determine how voice interaction and vpa usage vary between frequent and infrequent user groups. unlike previous research on virtual assistants, we do not limit our investigation to any particular device.", "conclusion": "<title>conclusions and future work</title> this paper has presented results of a survey on current usage of vpas with focus on differences between frequent and infrequent users in terms of usage experience, performance expectations and privacy concerns. based on the obtained results we address our research questions (formulated in section 1). rq1: as indicated by the quantitative data from questions on usage experience -most of the respondents currently use their vpas for simple tasks such as factoid queries, weather updates or playing music, while many functions are hardly used or completely unexplored (see figure 2 for details). we find that satisfaction varies between different users groups -with frequent users being significantly more satisfied with their vpas overall (as presented in table 1). this indicates a potential link between user satisfaction and vpa usage frequency. we observe that both frequent and infrequent vpa users have similar perceptions and expectations regarding performance of their virtual assistants. however, overall, the latter group tend to be more concerned with asr rather than nlu capabilities of their vpas (see table 3 for details). this finding suggests that, despite recent technological developments, asr is still perceived as a barrier to frequent usage of vpas. rq3: both frequent and infrequent users seem to be equally concerned about their privacy when talking to vpas in various settings. yet, despite these concerns, frequent users are more eager to use their vpas in front of different audiences including family members, and partners (as shown in table 2). we find it particularly interesting that asr is currently considered as one of the major concerns of infrequent users of vpas. thus, we intend to investigate this aspect further in our future work. in order to obtain more insights on perception of vpa speech recognition performance at individual user level, we will conduct diary studies of day-to-day vpa usage and follow them up with ethnomethodological analysis. in summary, we provided a broad overview of current vpa usage and highlighted some perceived barriers to regular use. the study opens up new research avenues that can be explored in order to get better understanding of human-vpa interaction."}
{"id": 1192, "date": "2019-01-14", "title": "Characterizing and Predicting Email Deferral Behavior", "url": "https://arxiv.org/abs/1901.04375v1[cs.IR]", "keywords": ["Email Management", "Triage", "Deferral", "Users Behavior Modeling"], "abstract": "mail triage involves going through unhandled emails and deciding what to do with them. this familiar process can become increasingly challenging as the number of unhandled email grows. during a triage session, users commonly defer handling emails that they cannot immediately deal with to later. these deferred emails, are often related to tasks that are postponed until the user has more time or the right information to deal with them. in this paper, through qualitative interviews and a large-scale log analysis, we study when and what enterprise email users tend to defer. we found that users are more likely to defer emails when handling them involves replying, reading carefully, or clicking on links and attachments. we also learned that the decision to defer emails depends on many factors such as user's workload and the importance of the sender. our qualitative results suggested that deferring is very common, and our quantitative log analysis confirms that 12% of triage sessions and 16% of daily active users had at least one deferred email on weekdays. we also discuss several deferral strategies such as marking emails as unread and flagging that are reported by our interviewees, and illustrate how such patterns can be also observed in user logs. inspired by the characteristics of deferred emails and contextual factors involved in deciding if an email should be deferred, we train a classifier for predicting whether a recently triaged email is actually deferred. our experimental results suggests that deferral can be classified with modest effectiveness. overall, our work provides novel insights about how users handle their emails and how deferral can be modeled.", "rq": ["rq 1:] how common is deferral?", "rq 2:] what motivations are behind deferral?", "rq 3:] what factors impact deferral for an email?", "rq 4:] what strategies are employed for deferral?"], "relatedWork": ": previous work has studied several aspects of how people interact with email and how to assist them with email management. two lines of prior work are especially relevant, one on email management and organization and the other on large-scale log analysis of email interaction. we cover both of them below. email organization and management. one line of work on email management focused on understanding activities and workflows in email. venolia and gupta identified five major activities surrounding how people use email. in particular, they highlighted two activities: keeping up with the flow of incoming messages, and triaging existing messages and discussed how mail clients could better support these activities. siu et al. studied email use in the context of everyday work practices. they examined how users interlace email with their day-to-day, ongoing work processes. they demonstrated that subjects use email as a tool for managing moment-to-moment attention and task focus, and built on top of the work by venolia and gupta to propose a model of this workflow. much of the early research on email focused on how people organized and managed their email. mackay described a set of interviews that focused on understanding the way professional workers use email. whittaker and sidner proposed the concept of email overload to describe the usage of emails beyond communication needs, such as task management and personal archiving. they identified common strategies for handling email overload such as filing, searching, and cleaning. fisher et al. found similar results in their study of mailboxes at a large tech company. gwizdka identified two additional email management practices, cleaners and keepers, based on clustering responses to a questionnaire about email practices. grevet et al. revisited these previous findings with a qualitative study of gmail users and found that email overload was still prevalent in both work and personal settings. grbovic et al. showed that, with the increase of email messages over time, users do not use folders and argue that search is an increasingly important alternative to human-generated folders and tags. several studies have focused on developing effective search systems for email . dumais et al. found that email was the most commonly retrieved source of personal information (e.g. files, web history, emails, etc.). horvitz et al described experiments with bounded deferral, a method aimed at reducing the disruptiveness of incoming messages and alerts in return for bounded delays in receiving information. they showed that bounded deferral policies could help with balancing awareness about potentially urgent messages with the cost of interruption. earlier work also focused on studying how people triage their email. neustaedter et al. performed a set of interviews and surveys to understand how people handle email during triage and what email do people decide to handle first. pierce et al. also studied triage but they focused on mobile use. they showed that triage is a more dominant activity on mobile and that users often triage on mobile and defer their action until they reach a desktop. perhaps the most relevant to our work in this line is the work of wainer et al. . they studied how top-level cues, including message importance, organization utility, subject line specificity, curiosity, workload and personal utility, influence attention to email. our work is similar to this line of research in that we also study aspects of email management and organization. we examine in greater detail one aspect of email management focused on deferred action on emails and provide in-depth qualitative and quantitative studies to characterize and support users with deferral. log-based analysis of email interaction. large-scale log analysis has been extensively used in the literature to study different aspects of email interactions. kalman and ravid conducted a study of email management strategies on thousands of users over a period of 8 months using a popular email web client add-in. they showed that people use a wide variety of strategies to manage their emails, many more than had been identified in earlier studies. other work focused on using large-scale log analysis to study re-finding in email. elsweiler et al. studied several email interactions such as sorting, changing views, searching, selecting messages and opening folders. their work revealed strong relationships between difficulty in re-finding emails and the time lapsed since a message was read, remembering when the sought-after email was sent and remembering other recipients of the email. whittaker et al. carried out a large-scale study of users using a web-based email client. they investigated different re-finding strategies. they found out that some users create and use complicated folder structures to use them for email retrieval with no improvement in retrieval success. dumais et al. showed that re-finding previously seen information is a frequent activity that goes beyond email. however, they showed that email is by far the most common type of information that people re-find in a desktop search application. log-based studies have also been used to study email search. ai et al. examined the actions that people perform on emails after searches and compared re-finding in email search with web search. narang et al. also examined the activities performed on messages following searches, and how this related to the characteristics of people's mailboxes and email organization strategies. more recently, castro et al. studied what actions the users might conduct on received messages by analyzing the actions of a large number of users in yahoo! mail. they found out that the most frequent actions are typically read, reply, delete and a sub-type of delete, delete-without-read. yang et al. studied email reply behavior in enterprise settings. they characterized the influence of various factors such as email content and metadata, historical interaction features and temporal features on email reply behavior. we also develop models to predict whether a recipient will reply to an email and how long it will take to do so alrashed et al. studied the lifetime of email messages with a focus on revisiting patterns. they showed that some emails are never revisited, while others are revisited for multiple times. they also showed that some users revisit messages for a variety of reasons including taking an action or for finding location information. this line of work is related to our study since we also use largescale log analysis to study email interactions. we build on top of previous work on understanding email triage and re-finding but focus on the act of email deferral. we also augment the log-based analysis with a qualitative study and use the findings of both studies to define a prediction task to help users get back to deferred emails more efficiently.", "conclusion": "<title>conclusions</title> we sought to understand one important aspect of email triage where people defer taking action on emails after seeing it for the first time. we employed a mixed-methods approach where we combined qualitative analysis, via interviews, and quantitative analysis, via a largescale log study, to develop a better understanding of why people defer emails, what strategies they employ to do so and how we can provide better support for deferring and getting back to deferred emails. we found that users are more likely to defer emails that require responding or processing information in an attachment. we also observed that deferred message share common characteristics related to the importance of the sender, the number of recipients and the content of the message. further, the decision to defer a message depends not only on the message itself but also on other contextual information such as the current workload of the user. our log analysis revealed several insights about deferral strategies. for example, we showed that flag and markasunread are more likely to be observed for deferred than non-deferred messages but are only observed for a limited portion of deferred messages. we used these insights to define a prediction task to assess the feasibility of using machine learning to assist users with their deferral workflows. understanding email deferral could have implications on understanding how people interact with their email and designing email clients and intelligent agents to help people with managing and organizing their messages. our future work will aim to explore applications and user experiences that would better support email deferral."}
{"id": 1207, "date": "2019-02-07", "title": "Community Animation: Exploring a design space that leverages geosocial networking to increase community engagement", "url": "https://arxiv.org/abs/1902.02842v1[cs.HC]", "keywords": ["Community engagement", "mobile apps", "requirements analysis", "co-working spaces", "innovation ecosystem"], "abstract": "his paper explores a design study of a smartphone enabled meet-up app meant to inspire engagement in community innovation. community hubs such as co-working spaces, incubators, and maker spaces attract community members with diverse interests. this paper presents these spaces as a design opportunity for an application that helps host communitycentered meet-ups in smart and connected communities. our design study explores three scenarios of use, inspired by previous literature, for organizing meet-ups and compares them by surveying potential users. based on the results of our survey, we propose several design implications and implement them in the community animator geosocial networking application, which identifies nearby individuals that are willing to chat or perform community-centered activities. we present the results of both our survey and our prototype, discuss our design goals, and provide design implications for civic-minded, geosocial networking applications. our contribution in this work is the development process, proposed design of a mobile application to support community-centered meet-ups, and insights for future work.", "rq": ["rq 2: how do potential users believe community animator use can contribute to elements of engagement in their community and why?", "rq 3: how do potential users believe the app will contribute to their engagement in community innovation and why?"], "relatedWork": ": previous work has indicated that when it comes to developing community innovations, the collective vision of local businesses, organizations, educational institutions, and local government are often disconnected, even though they share a common goal for positive change . mccarthy affirmed community spaces (often referred to as third places ) benefit communities by enabling people to discuss, plan and execute \"potentially useful collective undertakings.\" a lack of these third spaces removes the social environment necessary to facilitate civic interactions. to avoid the increase of social isolation and loss of social connections, urban planners are putting more effort into creating new third places and reinvigorate metropolitan neighborhoods by breaking down social siloes . for instance, the outbox experiment provided an outside and wall-less vestibule equipped with wi-fi and seating, available for people to use throughout the day. web media such as dodgeball.com, meetup.com, foursquare, and facebook check in are examples of geosocial platforms that enable meeting others, which are experiencing a boom in popularity. these options work with user's location to offer community groups or to spread information about a local place. dating applications such as tinder and okcupid are examples of geolocation sites increasingly used for social interaction by connecting individuals in person. however, these online dating applications differ from other types of social interaction as they enable only pairwise interactions, which limits their potential for community expansion. interactions around local place have long been theorized in community informatics literature. carroll describes the community informatics as a field concerned with the challenges and opportunities for citizens in an environment increasingly dominated by technology. civic technology holds the potential to motivate local citizens to become active in community events . considerable efforts have been dedicated to the development of applications that integrate innovations and technology to facilitate community citizen engagement. various designs have been developed to inspire meet-ups and engage citizens in their communities. here we explore previous methods used to host introductions using mobile apps.", "conclusion": "<title>conclusion</title> this work has identified community animation as a design space to leverage geosocial networking technology. we are interested in connecting communities as a whole, and this paper begins with the first step towards that end. the survey and evaluation that is presented in this paper is one piece of a larger project. our study addresses two components: the first one we described is the likelihood and value of using the app, and the second examined the hypothesized contribution of various design scenarios. we explored in this study which of three scenarios is most likely to contribute to the hypothesized contribution. our view of the survey results is not that users' preference for task-based meet-ups is a lapse into instrumentality, but rather as a more active expression of community-centric activities. our review of community informatics literature shows that being informed (reading the newspaper) is sometimes a proxy for being engaged in the community. we believe that the results of the survey hold individual validity and importance and can be seen as a contribution from the development process. based on the survey a prototype that utilizes task-based meetups was designed. the community animator application uses the gps in your smartphone to find \"animated\" citizens near you that are interested in collaborating in the same civic tasks, but also supports civic interest-based conversations. community animator has been investigated through the implementation of the app and the results of that analysis have been analyzed. we explore the effectiveness of these contributions with an evaluation of the application. we might interpret our results to mean that people are interested in the app perhaps as a way to coordinate and engage in tasks over finding news or discussing interests. this is good news in that people may view community animator as a way of doing tasks together rather than learning about them like a news feed, which is a higher level of engagement. from a design perspective, we believe that the result of the testing supported our hypothesis that interest-based match would be most useful for users to engage in community-centered activities. today, the modern casual encounter has more frequently become an activity coordinated by algorithms and geolocations , as many people have changed the way that they make friends and interact with others . as society has become more accustomed to these behaviors, mobile applications that host introductions appear among \"most downloaded\" lists in app stores and are widely discussed in popular culture . the same technologies that have been used to inspire friendships and dating, can also be used within community technologies to reduce the social transaction costs of participation in civic networks . in such networks, inspiring interactions among citizens has the potential to lead to direct economic impacts for organizations and the local market ."}
{"id": 1288, "date": "2019-05-14", "title": "Exploring Interactions with Voice-Controlled TV", "url": "https://arxiv.org/abs/1905.05851v1[cs.HC]", "keywords": [], "abstract": "ntelligent agents such as alexa, siri, and google assistant are now built into streaming tv systems, allowing people to use voice input to navigate the increasingly complex set of apps available on a tv. however, these systems typically support a narrow range of control-and search-oriented commands, and do not support deeper recommendation or exploration queries. to learn about how people interact with a recommendationoriented voice-controlled tv, we use research through design methods to explore an early prototype movie recommendation system where the only input modality is voice. we describe in-depth qualitative research sessions with 11 participants. we contribute implications for designers of voice-controlled tv: mitigating the drawbacks of voice-only interactions, navigating the tension between expressiveness and efficiency, and building voice-driven recommendation interfaces that facilitate exploration.", "rq": ["rq 1: how do users want to speak to a voice-controlled tv?", "rq 3: how do users interact with a recommender system on a voice-controlled tv?"], "relatedWork": ": researchers have considered the potential of voice user interfaces (vuis) from a human-computer interaction (hci) perspective for decades. in this section, we first summarize related work in the domain of tv and recommender systems, then explore more broadly the research that informs our understanding of vui design factors that impact the user experience.", "conclusion": "<title>conclusion</title> while voice user interfaces for tvs are becoming widely available, current systems treat voice input as an optional, secondary input, and rarely include voice output. to learn about the opportunities of voice-controlled tvs, we built a prototype system where the only input modality is voice. we conducted interview sessions to learn about how people might interact with such a system, and to develop a set of themes to guide future designs. we find that in a voice-only system, spoken inputs and outputs can be slow or repetitive, and that a key design guideline is to streamline these interactions. however, we also see a design tension between the competing needs for efficiency and expressiveness, pointing to future work in systems that can detect and adapt their output to user preferences and context. finally, we see promise in supporting natural language interactions with recommendation technology; our design research underscores the importance of displaying the right balance of familiar and novel content, and suggests a new research direction around context-and user-personalized voice command suggestions."}
{"id": 1335, "date": "2019-07-11", "title": "The Illusion of Animal Body Ownership and Its Potential for Virtual Reality Games", "url": "https://arxiv.org/abs/1907.05220v1[cs.HC]", "keywords": ["virtual reality", "animal avatars", "embodiment"], "abstract": "virtual reality offers the unique possibility to experience a virtual representation as our own body. in contrast to previous research that predominantly studied this phenomenon for humanoid avatars, our work focuses on virtual animals. in this paper, we discuss different body tracking approaches to control creatures such as spiders or bats and the respective virtual body ownership effects. our empirical results demonstrate that virtual body ownership is also applicable for nonhumanoids and can even outperform human-like avatars in certain cases. an additional survey confirms the general interest of people in creating such experiences and allows us to initiate a broad discussion regarding the applicability of animal embodiment for educational and entertainment purposes.", "rq": ["rq 3: is there any difference between fb and hb for the same animal?"], "relatedWork": ". related work on ivbo: immersive setups are capable of inducing the illusion of virtual body ownership (ivbo), also referred to as body transfer illusion, agency, or embodiment. ivbo is an adaption of the effect of body ownership (bo), a term coined by botvinick et al. . the authors conducted an experiment to induce the socalled rubber hand illusion, in which they hid the participants real arm and replaced it with an artificial rubber limb. both arms were then simultaneously stroked by a brush, which produced the illusion of owning the artificial arm. this effect has gained great publicity and was further researched by tsakiris et al. . these results eventually led to the first neurocognitive model regarding body ownership , which emphasized the interplay between external sensory stimuli and the internal model of our own body. additional studies extended these finding to other limbs and whole-body representations - . the effect of bo was initially transferred to virtual environments for arms by slater et al. and entire bodies by banakou et al. . however, these early studies used the original visuotactile stimulation introduced by botvinick et al. . later research introduced sensorimotor cues, i.e., the tracking of hand and finger movement , which was reported to be more important than visuotactile cues . this finding is essential for vr setups as it releases possible experiments from the need for tactile stimulations. furthermore, these two types of different cues are completed by the so-called visuoproprioceptive cues. these cues are a series of different body representations and include subdimensions such as perspective, body continuity, posture and alignment, appearance, and realism. these different subdimensions are listed in the correct order of influence on the effect of ivbo , , , , and together are sufficient for inducing the illusion of body ownership . moreover, maselli et al. reported the necessity of a first-person perspective. in sum, ivbo is induced by correct visuoproprioceptive cues. misalignments and visual errors can be compensated for through the weaker aspects of sensorimotor and visuotactile cues. however, this effect can be observed with anthropomorphic characters as well as realistic representations , , . riva et al. illustrated the current interest in significantly altering the morphology of our virtual representation by the following question: but what if, instead of simply extending our morphology, a person could become something else-a bat perhaps or an animal so far removed from the human that it does not even have the same kind of skeleton an invertebrate, like a lobster? especially for animals that have few characteristics in common with our human body, the approach of sensory substitution is also a promising direction for ivbo research. for instance, we could replace the echolocation feature of a bat by visual or even tactile feedback in vr. recently, researchers have studied adapting and augmenting human bodies in vr. kilteni et al. stretched the virtual arm up to four times its original length and were still able to confirm ivbo. these findings are in line with the work of blom et al. , who reported that a strong spatial coincidence of real and virtual body part is not necessary for the illusion. furthermore, researchers have determined that additional body parts are not necessarily destroying ivbo. instead, it is possible to add a third arm and induce a double-touch feeling , . apart from additional arms, other body parts have also been added successfully: steptoe et al. reported effects of ivbo upon attaching a virtual tail-like body extension to the users virtual character. the authors further discovered higher degrees of body ownership when synchronizing the tail movement with the real body. another prominent example of body modification that could be relevant for embodying flying animals is virtual wings. in that area, egeberg et al. proposed several ways to couple wing control with sensory feedback. won et al. further analyzed our ability to inhabit nonhumanoid avatars with additional body parts. regarding realistic avatars, waltemate et al. showed that customizable representations lead to significantly higher ivbo effects. strong effects of body ownership can produce multiple changes in the feeling or behavior of the user , resembling the proteus effect by yee et al. . for instance, peck et al. reported a significant reduction in racial bias when playing a black character. additionally, virtual race can also affect the drumming style when playing virtual drums . other reactions are more childish feelings arising from child bodies or greater perceived stability due to a robotic self . these findings demonstrate that ivbo is not just a one-way street but can be used to evoke specific feelings and attributes and possibly also change self-perception. we point readers to the recent work in progress by roth et al. regarding ivbo experience. in particular, the paper presented a ivbo questionnaire based on a fake mirror scenario study. the authors suggested acceptance, control, and change as the three factors that determine ivbo. in our experiments, we administered the proposed questionnaire as we were curious to see how it performs for animal avatars. our research follows up on the works-in-progress paper by krekhov et al. . the authors conducted a preliminary study with eight participants, and, by applying the alpha ivbo questionnaire , concluded that ivbo might indeed work for animal avatars. we significantly extend that apparatus to gather more insights and to produce reliable results, and also to introduce additional surveys about virtual animals to explore the overall benefits of such research.", "conclusion": "<title>v. conclusion and future work</title> backed by our supplementary studies, we underpinned the large potential of animal avatars for vr research and applications, be it for education or entertainment. to provide a starting point for future research, we proposed a number of different control modes for upright/flying species, four-legged mammals, and arthropods. our evaluation revealed that ivbo can be considered for nonhumanoid avatars and led us to a first set of design implications in that area. we conclude that half-body tracking is a viable alternative to control animals that are not in an upright position as it offers a promising trade-off between fatigue and ivbo. for that reason, we suggest examining such half-body approaches in more depth. to provide higher degrees of control, a combination with sensory substitution might be a viable approach for future research. finally, as desired by the majority of participants, we propose to enhance the avatars with appropriate capabilities such as flying and see how this would impact ivbo. hereby, the ultimate goal is the construction of a zoological ivbo framework that would support researchers and practitioners in designing meaningful virtual animals."}
{"id": 1470, "date": "2019-10-13", "title": "Toward a Curriculum Proposal for CSCW Education and Training in Latin America", "url": "", "keywords": ["CSCW", "Latin America", "HCI Education and Training"], "abstract": "omputer-supported cooperative work, or simply cscw, is the research area that studies the design and use of socio-technical technology for supporting group work. cscw has a long tradition in interdisciplinary work exploring technical, social, and theoretical challenges for the design of technologies to support cooperative and collaborative work and life activities. however, most of the research tradition, methods, and theories in the field follow a strong trend grounded in social and cultural aspects from north america and western europe. therefore, it is inevitable that some of the underlying-and established-knowledge in the field will not be directly transferrable or applicable to other populations. this paper presents the results of an interview study conducted with latin american faculty on the feasability, viability, and prospect of a curriculum proposal for cscw education in latin america. to this end, we conducted nine interviews with faculty currently based in six countries of the region, aiming to understand how a cscw course targeted to undergraduate and/or graduate students in latin america might be deployed. our findings suggest that there are specific traits that need to be addressed in such a course, such as: tailoring foundational cscw concepts to the diversity of local cultures, motivating the involvement of students by tackling relevant problems to their local communities, and revitalizing cscw research and practice in the continent.\u2022 human-centered computing \u2192 collaborative and social computing; \u2022 social and professional topics \u2192 computing education; model curricula.", "rq": ["rq 1: how does a cscw undergraduate and/or graduate course in latin america should look like?", "rq 2: what would be the challenges and barriers to overcome for effectively implementing such a course?"], "relatedWork": ": the human-computer interaction (hci) community has a long tradition of building curricular material to enhance and expand the field through education. just before the 90's decade began, sigchi (i.e., acm special interest group on computer-human interaction) started a series of panels which eventually became the acm curricula for human-computer interaction, commonly known as the \"lime green report\" . this framework has been used by researchers, academics, and professionals to educate on subjects related to hci. even though that curriculum is still used, several authors argued on behalf of improving it to (1) update themes and (2) add a global perspective . therefore, initiatives such as sigchi education project and the hci living curriculum emerged to fulfill these needs. in that respect, education professionals from various world regions have participated in the integration of different cultural perspectives through workshops held in events such as africhi and chi . aligned with these efforts, hci collab is an ibero-american network that aims to structure an hci curricular proposal that works as a model for several institutions in the region. this innitiative seeks to counteract that hci has not received full recognition within the countries in this region . other researchers in latam have proposed mechanisms for teaching and learning hci through design and evaluation of computer games . likewise, the mexican community has published two books to support hci courses . more closely related to cscw, two members of the brazilian research community started in 2010 a collaborative project aiming to produce a book about cscw to be used in undergraduate and graduate courses in brazil. this book was eventually published in 2012 with 26 chapters that where written by 49 brazilian cscw researchers. chapters were organized in 5 different parts, namely: fundamentals, systems and domains, techniques, development , and research . since this book was designed to be used in undergraduate and graduate classes in brazil, it was written entirely in portuguese. interestingly, although some chapters use examples from the brazilian context, none of them addresses something that is unique to brazil. almost ten years after such a valuable contribution, we aim to contribute to cscw education and training by exploring viewpoints and expectations of faculty working in latam institutions in regard to a cscw curriculum proposal that focuses on the singularities of the latam context.", "conclusion": "<title>conclusion and future work</title> cscw is the research area that studies the design and use of sociotechnical technology for supporting group work, whereas such group work can be conducted by teams, organizations, communities, or networks. cscw has a tradition in interdisciplinary work exploring technical, social, and theoretical aspects related to the design of technologies to support cooperative activities at work and/or home. most cscw research is strongly grounded in social and cultural aspects from north america and western europe. therefore, it is inevitable that some of the underlying-and established-knowledge in the field will not be directly transferrable or applicable to other populations. this paper presented an exploratory study to focus on this aspect, i.e., the feasability, viability, and prospect of a curriculum proposal for cscw education in latam. we interviewed nine faculty from six countries of the region, aiming to understand how a cscw course targeted to undergraduate and/or graduate students in latam might be deployed. our preliminary findings suggest that there are specific traits that need to be addressed in such a course, such as: (1) tailoring foundational cscw concepts to the diversity of local cultures, (2) motivating the involvement of students by tackling relevant problems to their local communities, and (3) revitalizing cscw research and practice in the continent. as future work, we plan to conduct additional interviews with other faculty to understand whether there are new issues that were not reported by our study participants. likewise, we will explicitly collect complementary viewpoints, such as those coming from industry partners and non-governmental organizations, as a way to have a richer view on the feasability and viability of proposing a latam-centric cscw course proposal."}
{"id": 1487, "date": "2019-10-13", "title": "", "url": "", "keywords": [], "abstract": "would first like to thank my thesis advisor prof. dr. avishek anand for allowing me to work on an interesting topic and providing constant guidance not only during the duration of the thesis but also throughout my masters course. i would like to show an immense gratitude for my supervisor dr. ujwal gadiraju who was always available to solve my doubts. his confidence in my work was most motivational. he was always available to discuss various approaches and steer me in the right direction. during the stressful periods of thesis, he made himself available even during his non-working days for which i will forever be grateful. i would also like to thank prof. dr. wolfgang nejdl for giving me a working space in l3s research center during the entire duration for my masters and for funding the experimental work carried out in thesis. i would like to thank my friends who were always present to support me emotionally and help me cope with the ups and downs of life during my entire masters course. finally, i would like to thank my family, especially my grandfather who taught me the importance of education since i was a child, my loving mother who always saw to it that i fed myself on time and lastly, my sister who was always awake when i needed a break.", "rq": ["rq 1: how does a user's knowledge evolve in a search session online with respect to the varying cognitive learning levels?", "rq 2: how is search behavior impacted by cognitive learning level?"], "relatedWork": "elated work: learning is not restricted to classrooms anymore. in addition, learning style in today's age is not constrained to a classroom setup of 'teacher and students'. wilson mentions that information need often refers to one's underlying motivation to seek the specific type of content. in his book , schutz and luckmann discuss how every individual has his or her own view of the world around them, specific typification that are used to model and explain all the phenomena around them and when one encounters a problem which won't fit in their model, it requires more information and knowledge remodeling in order to solve the problem and fix the anomaly. several literature talk about relationships between sense-making models and information seeking. views information seeking as a means to demolish the uncertainty between desired and observed scenarios. further, reviews user's sense making approach by transforming user's conceptualization from noun based knowledge framework to verb based framework. likewise, there have been discussions where strong relations between information seeking, knowledge and human cognition levels have been displayed. 's theory on text retrieval and cognitive framework as well as 's problem solution model are a few of such examples. however, the focus of this thesis is not only in information seeking but also in searching and learning of information. there exists an abundant amount of literature which emphasizes on relations between search, learning, and user or more specifically user behavior in the area of information science. explains how annotation in a collaborative environment affects learning of an individual in an online system through theoretical experiments. while explores learning online by providing a knowledge building model in order to support collaborative learning, inspects learners' behavior in an online collaborative system. in order to comprehend the interrelation between search, user, and learning; it is crucial to recognize the procedure of learning. not only, is it essential to understand the process but it is also required to identify the different stages of learning. developed taxonomic structure to encourage education at a deeper level as compared to mere fact recalling. the categories of taxonomic structure was viewed as learning levels. his motivation was to create thinkers in the world and in order to do so, he proposed six levels in the taxonomy where the levels on top of the structure were more abstract and required higher level of thinking and reasoning in contrast to lower levels. the six categories of bloom's taxonomy from least abstract to most abstract are: knowledge, comprehension, application, analysis, synthesis, and evaluation. bloom's taxonomy is not a perfect taxonomy to categorize and order learning levels. supports this fact by arguing that there aren't any perfect educational taxonomies and many taxonomies have their weaknesses, including that of bloom's. the original bloom's taxonomy has loopholes and have been challenged by many. studies showed that while all the other categories of bloom's taxonomy led to increase in memory, the evaluation level failed to do so. he questioned position and inclusion of evaluation in the educational taxonomy. argued the usability of bloom's taxonomic structure in educational systems as educators are used to designing the learning objectives in a \"subject-description\" format where subject would refer to subject matter of the content and description would include an explanation of how to deal with the content. he further illustrated that this \"subject-description\" format can also be viewed as a \"noun-verb\" pair. krathwohl modified the original taxonomy into 2-dimensional where knowledge formed one of the dimensions and cognitive processes of learning the knowledge formed the second dimension. the revision allowed evaluation for both, the learning outcomes as well as the cognitive process used by learner . we will be adopting this revised version of bloom's taxonomy for our study here and it will be used as a scripting guide for designing the tasks and measuring knowledge as well as user interactions at various cognitive levels.", "conclusion": "<title>conclusion and future work</title> in this thesis, we developed six search tasks corresponding to each of the krathwohl's cognitive complexity levels. these tasks were designed specifically to measure user interactions and knowledge gain across varying cognitive learning levels. we asked participants of a crowd-sourcing platform to answer the search tasks in a consecutive manner. the unique design of the experimental set-up on the crowd-sourcing platform ensured that no user participated in search tasks of two or more cognitive learning complexity levels. this allowed us to accumulate user's search behavior which was purely for the chosen cognitive complexity. we analyzed the user's search interactions to establish a relation between search behavior and the taxonomic structure of revised bloom's taxonomy. not only did we collect user's search interaction but we also calculated user's knowledge gain by devising a set of rules to compute user's knowledge gain for the first four cognitive domains of revised taxonomic structure. we also demonstrated a relation between the search task complexity and knowledge gain with empirical data that showed an impact in knowledge gain by the cognitive learning level. the results of user's interaction was able to support the revised bloom's taxonomic structure with empirical proof for the first time. while not true for each domain level, user's interactions however, showed a general upward trend while traveling from a lowest cognitive complexity level to highest. this allowed us to conclude that if user advances to highest complexity level from lowest, there will definitely be an increase in the observed search behavior. this study is one of the unique studies that was able to find a statistically significant difference in all of the discussed user interactions across all of the cognitive learning levels of revised bloom's taxonomy. the impact of this finding reveals the importance of the search tasks designed. the search tasks can be used to study the user interactions by search interfaces facilitating learning needs. it can also be used to used to enhance specific cognitive needs. further, since a one-way between subjects anova shows that all the results are significantly different across the cognitive levels, a machine learning model can be designed to train the model with the user interaction data collected which will allow in detecting user's cognitive learning level or even predict the possible knowledge gain. we aim to present this supervised machine learning model in near future. for our future studies we would also like to conduct the same experiments for different topic domain to eliminate any topic bias that could have appeared in the results. we would also to like conduct a study where the 30 minute time limit is relaxed to study the knowledge gain over a longer period to determine the consequences of time on knowledge gain."}
{"id": 1490, "date": "2019-10-13", "title": "Head-mounted Displays, Smartphones, or Smartwatches? -Augmenting Conversations with Digital Representation of Self", "url": "", "keywords": ["Face-to-face interactions", "head-mounted displays", "smartwatch", "smartphone", "conversation"], "abstract": "echnologies that augment face-to-face interactions with a digital sense of self have been used to support conversations. that work has employed one homogenous technology, either 'off-the-shelf' or with a bespoke prototype, across all participants. beyond speculative instances, it is unclear what technology individuals themselves would choose, if any, to augment their social interactions; what influence it may exert; or how use of heterogeneous devices may affect the value of this augmentation. this is important, as the devices that we use directly affect our behaviour, influencing affordances and how we engage in social interactions. through a study of 28 participants, we compared head-mounted display, smartphones, and smartwatches to support digital augmentation of self during face-to-face interactions within a group. we identified a preference among participants for head-mounted displays to support privacy, while smartwatches and smartphones better supported conversational events (such as grounding and repair), along with group use through screensharing. accordingly, we present software and hardware design recommendations and user interface guidelines for integrating a digital form of self into face-to-face conversations.", "rq": ["rq 1: what are the device affordances in using head-mounted displays, smartphones, and smartwatches, and how do people use these devices in social collocated multiple-user interactions?"], "relatedWork": ": assisting collocated people 'to get to know each other' via technological solutions has been an active research topic since the classic work by mccarthy et al. . however, less consideration has been paid toward the characteristics of devices aimed at providing this support. the evolution of devices that support socialising has progressed from large screens such as tabletop devices to mobile devices, such as smartphones 51], smartwatches , head-mounted displays , and laptops and from there to more experimental prototypes, including etextiles , coffee mugs , ambient displays , and wristbands . these different interfaces also play diverse roles within social interaction, from being a public display where the screen is viewable by many people to acting as a private device with its screen viewable by only one person. in addition, the devices' affordances vary between these settings, in distinct contextswith smartphones, for instance, being potentially viewable by others . the devices also go through paradigm shifts, as has been noted for tabletop devices, from lab prototypes to real-world collaborative applications and from single-touch to multitouch with multiple users . the data held on and presented by said devices are often shown in user profiles. these representations are either mined from the participants' current online sources, such as facebook and twitter , or created for the context by the users themselves .", "conclusion": ""}
{"id": 1493, "date": "2019-10-13", "title": "The Next Generation of Human-Drone Partnerships: Co-Designing an Emergency Response System", "url": "", "keywords": ["Situational Awareness", "Human-CPS interactions", "Unmanned Aerial Vehicles", "Emergency Response", "Participatory design"], "abstract": "he use of semi-autonomous unmanned aerial vehicles (uav) to support emergency response scenarios, such as fire surveillance and search and rescue, offers the potential for huge societal benefits. however, designing an effective solution in this complex domain represents a \"wicked design\" problem, requiring a careful balance between trade-offs associated with drone autonomy versus human control, mission functionality versus safety, and the diverse needs of different stakeholders. this paper focuses on designing for situational awareness (sa) using a scenario-driven, participatory design process. we developed sa cards describing six common design-problems, known as sa demons, and three new demons of importance to our domain. we then used these sa cards to equip domain experts with sa knowledge so that they could more fully engage in the design process. we designed a potentially reusable solution for achieving sa in multi-stakeholder, multi-uav, emergency response applications.", "rq": ["rq 1: what design solutions were adopted in droneresponse, and which of these can potentially be reused in other uavbased socio-technical cps?"], "relatedWork": ": our work focuses on participatory design for sa in a challenging socio-technical cps domain. while numerous authors have described studies on participatory design , there is little work at the intersection of participatory design and sa, especially in the cps domain. the seminal work on sa demons by endsley focused on user-centered design rather than participatory design; however, our goal is to engage domain experts as co-designers rather than to design the product for them. in one exception, lukosch et al. , explored the use of participatory design for serious games that provided a virtual world environment in which to develop sa skills. however, the virtual environment is very different from the life-or-death domain of emergency response. several researchers have reported case studies of sa in specific domains. for example, breuer et al. , explored sa for operators in the control center of a tsunami early warning system. similar to our work, they adopted endsley's principles of design for sa and then used domain experts to evaluate the ui for conformance to sa guidelines. however, their domain was centered around a single control center, did not include autonomous agents partnering with humans, and did not engage users in a participatory design process. similarly, onal et al., applied a situation awareness-oriented design (saod) process to analyze, design, and evaluate the ui for an electric mining shovel . they used goal-directed task analysis to understand users' goals, followed by a ui design phase, and finally a ui evaluation step based on simple assessment rubriks; however, they did not use participatory design. many papers have explored sa in systems where operators interact with a single robot or machine . while we can draw lessons from their work, sa challenges associated with a single machine differ significantly from a multi-uav emergency response environment. in addition, several authors developed communication dashboards to support situational awareness across teams . such dashboards could be used to support situational awareness between multiple people and machines in droneresponse. oliveira et al. , explored and evaluated ways to visualize information in support of sa. yet other work has described novel design techniques for achieving sa. for example, daniello et al. , presented an approach that uses adaptive goal selection to achieve sa. finally, many researchers have explored \"artificial\" situational awareness for autonomous vehicles . while this is of direct relevance for our project, our focus in this paper has been on sa for human operators.", "conclusion": "<title>conclusion</title> this paper has described our participatory design process in which we engaged domain experts in identifying and analyzing design tensions, and designing a ui to support effective sa in a socio-technical cps where humans and uavs partner together to support emergency response. the design produced by this process reflected the domain knowledge and vision of the firefighters as well as ideas for human-drone partnerships in collaborative mission-centric environments. we documented key design observations that emerged from the participatory design process, producing a solution that could potentially be reused across other multi-user uav applications, or even in other applications in closely related domains . the participatory design process not only provided a solid foundation for the design of the system, but established a shared vision for moving the project forward. in the next phase of our multi-year project, we will extend the ui to enable human operators to communicate mission goals to uavs. we plan to conduct field tests with the south bend fire department and to further evaluate the ui design's support for situational awareness using physical uavs in the spring of 2020. we have established a review board in conjunction with the south bend firefighters and the city of south bend, whereby we will design and develop droneresponse through a series of simulations and field-tests (on our campus and in the downtown area of south bend), and the review board will evaluate when droneresponse can be safely and beneficially deployed in a live emergency mission."}
{"id": 1503, "date": "2019-10-13", "title": "Intergroup Contact in the Wild: Characterizing Language Differences between Intergroup and Single-group Members in NBA-related Discussion Forums", "url": "https://arxiv.org/abs/1908.10870v1[cs.CY]", "keywords": ["intergroup contact", "polarization", "intragroup behavior", "language usage", "NBA-related discussion forums"], "abstract": "ntergroup contact has long been considered as an effective strategy to reduce prejudice between groups. however, recent studies suggest that exposure to opposing groups in online platforms can exacerbate polarization. to further understand the behavior of individuals who actively engage in intergroup contact in practice, we provide a large-scale observational study of intragroup behavioral differences between members with and without intergroup contact. we leverage the existing structure of nba-related discussion forums on reddit to study the context of professional sports. we identify fans of each nba team as members of a group and trace whether they have intergroup contact. our results show that members with intergroup contact use more negative and abusive language in their affiliated group than those without such contact, after controlling for activity levels. we further quantify different levels of intergroup contact and show that there may exist nonlinear mechanisms regarding how intergroup contact relates to intragroup behavior. our findings provide complementary evidence to experimental studies in a novel context, and also shed light on possible reasons for the different outcomes in prior studies. ccs concepts: \u2022 applied computing \u2192 law, social and behavioral sciences; \u2022 human-centered computing \u2192 collaborative and social computing.", "rq": ["rq 1: how do members with intergroup contact differ from those without such contact in intragroup language usage in nba fan groups?", "rq 2: how do different levels of intergroup contact relate to intragroup language usage?"], "relatedWork": ": in this section, we first discuss studies that use language as a lens to understand human behavior, especially recent studies on the use of negative language in the context of antisocial behavior. next, we explain the growing concerns of tribalism, echo-chambers, and polarization, and highlight our specific context, sports, as a testbed for understanding these issues. we then discuss the role of intergroup contact in affecting individual opinions towards opposing groups, including recent work on its backfire effect in online platforms. finally, we point out opportunities in online sports discussion forums for understanding human behavior.", "conclusion": "<title>conclusion</title> in this paper, by applying our computational framework to nba-related discussion forums on reddit, we identify clear language differences between intergroup and single-group members in their affiliated group (the intragroup setting). we find that in the affiliated team subreddit, intergroup members tend to use more negative and swear words, and generate more hate speech comments compared with single-group members. moreover, we quantify different levels of intergroup contact for each intergroup member based on the fraction of their comments in the intergroup setting (/r/nba). interestingly, the level of intergroup contact can relate to differences in language usage in different ways, though the relationship is mostly monotonic. to further shed light on the behavior of intergroup members, we also compare the language usage of intergroup members between the intragroup setting and the intergroup setting. this setup naturally controls for the subject because we compare the same person across two different environments. we observe that intergroup members are even more negative and more likely to swear in the intergroup setting. as intergroup contact in online platforms becomes increasingly common and can play an important role in opinion formation, our work demonstrates how observational studies can provide complementary evidence to experimental studies on this topic."}
{"id": 1522, "date": "2019-10-13", "title": "Understanding Mobile Search Task Relevance and User Behaviour in Context", "url": "", "keywords": ["mobile search", "context", "user study", "field study"], "abstract": "mprovements in mobile technologies have led to a dramatic change in how and when people access and use information, and is having a profound impact on how users address their daily information needs. smart phones are rapidly becoming our main method of accessing information and are frequently used to perform \"on-thego\" search tasks. as research into information retrieval continues to evolve, evaluating search behaviour in context is relatively new. previous research has studied the effects of context through either self-reported diary studies or quantitative log analysis; however, neither approach is able to accurately capture context of use at the time of searching. in this study, we aim to gain a better understanding of task relevance and search behaviour via a task-based user study (n=31) employing a bespoke android app. the app allowed us to accurately capture the user's context when completing tasks at different times of the day over the period of a week. through analysis of the collected data, we gain a better understanding of how using smart phones on the go impacts search behaviour, search performance and task relevance and whether or not the actual context is an important factor.", "rq": ["rq 2: how does perceived task relevance vary by temporal context and what impact does this variation have on user behaviour and performance?"], "relatedWork": ": research on human interaction with mobile devices has been growing in recent years. one of the main focuses in this field of research has been to understand how users interact with search engines on mobile devices . in this section, we start with brief overview of studies that analyse mobile query logs. we then consider those that analyse human interaction when performing mobile search and, finally, we summarise studies that try to understand human interaction with mobile devices thorough various methods of study.", "conclusion": "<title>conclusions and future work</title> the main goal of this study was to understand how temporal and situational contexts affect user behaviour and search performance on mobile devices when performing web search tasks. we carried out a task-based field study consisting of 31 participants and 12 search tasks in a period of 7 days. we developed omicron, a bespoke android app, for this study, enabling us to capture various aspects of users' context and behaviour. the participants were given a maximum of two tasks per day at predefined time slots. randomly distributing the tasks, we were able to cover all different time slots, for different search tasks, on different days. this enabled us to conduct a thorough analysis on the impact of temporal and situational contexts on user behaviour and performance. our results indicate that more dynamic interfaces should be designed to encourage users to search while walking or on transport. also, we observed substantial variation in user behaviour and performance at various times, suggesting that the ui must be aware of the temporal context of the user. moreover, we saw that users are more willing to complete new search tasks -which presumably require more attention -during early hours of the day. this suggests the need for a more proactive search interface that could provide information cards or suggested queries based on users' regular querying patterns. as future work we plan to conduct a follow-up study, focusing on user behaviour as they search in various apps. recent research has shown that users submit most of their queries within multiple apps . therefore, it would be interesting to see how users interact with the search engine designed in different apps, under various temporal and situational contexts. also, as discussed in other studies, user behaviour in terms of app usage vary before, during, and after a search session . it would also be interesting to study the effect app usage before a search session has on the results that users scan or bookmark. for example, if a user spends a considerable amount of time on youtube, is he/she more likely to interact with results from http://www.youtube.com or not?"}
{"id": 1599, "date": "2019-10-13", "title": "You Drive Me Crazy! Interactive QoE Assessment for Telepresence Robot Control", "url": "", "keywords": ["Telepresence Robotics", "Remote Navigation", "Subjective QoE Assessment", "Interactive QoE", "Network Impairments"], "abstract": "elepresence robots (tprs) are versatile, remotely controlled vehicles that enable physical presence and humanto-human interaction over a distance. thanks to improving hardware and dropping price points, tprs enjoy the growing interest in various industries and application domains. still, a satisfying experience remains key for their acceptance and successful adoption, not only in terms of enabling remote communication with others, but also in terms of managing robot mobility by means of remote navigation. this paper focuses on the latter aspect of remote operation which has been hitherto neglected. we present the results of an extensive subjective study designed to systematically assess remote navigation quality of experience (qoe) in the context of using a tpr live over the internet. participants were 'beamed' into a remote office space and asked to perform characteristic tpr remote operation tasks (driving, turning, parking). visual and control dimensions of their experience were systematically impaired by altering network characteristics (bandwidth, delay and packet loss rate) in a controlled fashion. our results show that users can differentiate well between visual and navigation/control aspects of their experience. furthermore, qoe impairment sensitivity varies with the actual task at hand.", "rq": ["rq 2:) to what extent do users discriminate between navigation task quality and video streaming quality?"], "relatedWork": ". background and related work: a tpr is a wheeled device with wireless internet connectivity, which allows a human operator to be virtually present and to actively interact in a remote environment via bidirectional audio, video and data transmission , . navigation represents the additional dimension of tprs when compared with conventional stationary teleconference systems. nevertheless, navigating a tpr may pose challenges to the end users that influence their qoe. most importantly, user awareness of the 978-1-7281-5965-2/20/$31.00 \u00a92020 ieee arxiv:2003.10914v1 24 mar 2020 navigated environment depends on the quality and variety of the available sensors . for instance, the 2d cameras used in many telepresence systems offer a limited range of vision, which leads to a limited user experience . moreover, a robot's movement capabilities and responsiveness to interactions impact end-users' experience, too . consequently, navigating a robot may result not only in dissatisfaction, but also in undesired accidents such as breaking objects or harming humans. to study the qoe of navigating a tpr, different ifs should be considered. qoe ifs are classified into human ifs, system ifs and context ifs . regarding the influence of device related system ifs on human ifs, in , three navigation strategies for a tpr were studied. the authors found that meeting users' varying preferences may require offering multiple navigation interfaces. for instance, arrows may be appropriate for small distances and obstacle avoidance, while clicking on the camera image or in a map may be proper for long distance navigation. similar results were found in . additionally, navigation assistance was studied in , in which two tprs, one including a navigation assistance system, one without, were compared. they found that such assistance helps users avoid obstacles enhancing their satisfaction. the user interface design for navigation tasks has also been studied. presents a qualitative study in which the interface ease of use of a tpr was assessed positively by a group of users. however, the study was conducted in a highly controlled static environment, in which there was only one person and five exhibits of an art gallery used for the study. thus, their results are not applicable in dynamic contexts, in which obstacle avoidance may pose a challenge. although it was not studied rigorously, the authors found that users required less than half of the time when visiting the environment in person, than during the virtual training. regarding context ifs, in , the authors assessed navigation in terms of social interaction and environment layout. their results indicate that users found it easy to turn, stop, go backwards, follow a person and go back to the docking station, though high interaction episodes were identified during transitions between different locations. they found that social interaction may enhance the perceived presence, and the environment layout impacts the perceived ease of navigation. navigation challenges have also been studied in other domains such virtual reality. vlahovic et al. presented a comparison of four locomotion techniques in a virtual reality environment; i.e., controller movement, controller movement with tunneling, teleportation and human joystick. the overall qoe was rated lower for controller movement and human joystick, which were also the ones which resulted in more physical discomfort for the testers. the authors found that comfort may have a stronger impact on the qoe for navigation in virtual reality environments than the perceived immersion. to the best of our knowledge, no study has been conducted so far on how network related system ifs, such as bandwidth, delay and packet loss rate, impact the qoe of navigating a tpr. nevertheless, this aspect has been investigated in other domains. in , the authors demonstrated that variations in de-lay impact users' qoe while teleoperating a car in a simulator system. participants performed navigation tasks in four scenarios: parking, snake, pylon, i.e., big double curve and zigzag, and a long track. study results indicate that small delays worsen driving performance, and increase perceived workload. moreover, they did not find a significant difference between 0.0s and 0.3s delay in the testers' driving performance for the parking scenario. in the context of tprs, these results may be different since travel distances are normally shorter and range of vision might be more limited than in car driving scenarios. to summarise, previous work has demonstrated that 1) navigating a tpr is a challenging endeavour requiring empirical investigation; 2) network related system ifs and type of navigation task may affect qoe of controlling a tpr; and 3) the qoe of navigating a tpr has not been studied considering those system ifs. therefore, we conducted a subjective qoe study to investigate the impact of the type of navigation task and network related ifs on the qoe of navigating a tpr.", "conclusion": "<title>vi. conclusion and future work</title> in this paper, we evaluated the influence of network impairments (bandwidth, delay and packet loss rate) on tpr qoe on behalf of a subjective experiment addressing visual quality, navigation and acceptability aspects. our experiment features a very common tpr use case (remote presence in an enterprise office) and sheds light on the qoe impact of network-related impairments, task and other factors in this context. our results show that users can differentiate fairly well between visual and navigation/control aspects of tpr operation. in general, visual and navigation qoe sensitivity to specific impairments correlate weakly with each other, depending on the actual task at hand. our study was intentionally limited in scope by focusing on qoe assessment of remote tpr navigation, omitting other aspects such as social interaction, presence and embodiment. also, the three considered ifs are independently considered in our methodology. however, in practice, they may jointly affect qoe. thus, concerning future work we foresee the development of a more generic, empirically validated tpr qoe framework, taking additional aspects such as human-tohuman and human-to-robot interaction into account. to this end, we also plan to investigate the viability of using qoe models and frameworks from other related domains like vr and gaming to better characterise and predict tpr qoe."}
{"id": 1666, "date": "2019-11-27", "title": "Why Does My Model Fail? Contrastive Local Explanations for Retail Forecasting", "url": "https://arxiv.org/abs/1908.00085v2[cs.HC]", "keywords": ["Explainability", "Interpretability", "Erroneous predictions"], "abstract": "n various business se ings, there is an interest in using more complex machine learning techniques for sales forecasting. it is di cult to convince analysts, along with their superiors, to adopt these techniques since the models are considered to be \"black boxes,\" even if they perform be er than current models in use. we examine the impact of contrastive explanations about large errors on users' a itudes towards a \"black-box\" model. we propose an algorithm, monte carlo bounds for reasonable predictions. given a large error, mc-brp determines (1) feature values that would result in a reasonable prediction, and (2) general trends between each feature and the target, both based on monte carlo simulations. we evaluate on a real dataset with real users by conducting a user study with 75 participants to determine if explanations generated by mc-brp help users understand why a prediction results in a large error, and if this promotes trust in an automatically-learned model. our study shows that users are able to answer objective questions about the model's predictions with overall 81.1% accuracy when provided with these contrastive explanations. we show that users who saw mc-brp explanations understand why the model makes large errors in predictions signi cantly more than users in the control group. we also conduct an in-depth analysis on the di erence in a itudes between practitioners and researchers, and con rm that our results hold when conditioning on the users' background.", "rq": ["rq 2: how does providing contrastive explanations generated by mc-brp for large errors impact users\\' perception of the model?"], "relatedWork": ": guido i et al. compile a survey of current methods in interpretable machine learning and develop a taxonomy for classifying methods using four criteria: \u2022 problem: existing work on generating outcome explanations speci cally for tree ensembles involves nding counterfactual examples , identifying in uential training samples , or identifying important features . importantly, none of these publications are speci cally about (i) explaining errors, or (ii) explaining regressions. on the contrary, these publications are all based on binary classi cation tasks and the explanations do not necessarily provide insight into prediction mistakes. (i) tolomei et al. propose a method for generating counterfactual examples by identifying decision paths of interest that would result in a di erent prediction, then traversing down each of these paths and perturbing the instance x such that it satis es the path in question. if this perturbation, x , (i) satis es the decision path, and (ii) changes the prediction in the overall ensemble, then it is a candidate transformation of x. a er computing all possible candidate transformations by traversing over all paths of interest (i.e., those leading to a di erent prediction), the candidate transformation with the smallest distance from x is selected as the counterfactual example. e explanation, then, is the di erence between x and x . although tolomei et al. 's method also produces contrastive explanations, our method di ers from theirs since we are not aiming to identify one counterfactual example, but rather a range of feature values for which the prediction would be di erent. another di erence is that we do not assume full access to the original model. sharchilev et al. also generate outcome explanations for tree ensembles. eir methodology is based on nding in uential training samples in order to automatically improve the model, which di ers from our work since their explanations are not of a contrastive nature. ese in uential training samples help us understand why a certain class was predicted for a given instance, but they make no reference to the alternative class(es). it should be noted that they include a use case on identifying harmful training examples -ones that contributed to incorrect predictions -which can be seen as a way to explain errors. lundberg et al. propose a method for determining how much each feature contributes to a prediction and present a ranked list of the most important features as the explanation. e approach is based on the computationally intensive shapley values , for which the authors develop a tree-speci c approximation. is differs from our method since identifying the most important features is only a preliminary step in our pipeline -our work extends beyond this by including (1) feature bounds that result in reasonable predictions, and (2) the relationship between the features and the target as a tool to help users inspect what goes wrong when the prediction error is large. ribeiro et al. also propose a method for identifying local feature importances and this is the one we use in our pipeline. eir method, lime, is model-agnostic and is based on approximating the original model locally with a linear model. we share their objective of evaluating users' a itudes towards a model through local explanations but we further specify our task as explaining instances where there are large errors in predictions. based on preliminary experiments, we nd that lime is insu cient for our task se ing for two reasons: (i) for regression tasks, lime's approximation of the original model is not exact. is \"added\" error can be quite large given that our target is typically of order 10 6 , and this convolutes our de nition of a large error. (ii) e features lime deems most important are similar regardless of whether the prediction results in a large error or not, which does not provide any speci c insight into why a large error occurs. ese experiments are detailed in section 4. other work on contrastive explanations includes identifying features that should be present or absent in order to justify a classication or model-agnostic counterfactuals . ese all di er from our method since they are not speci cally about explaining errors. furthermore, the work by dhurandhar et al. and hendricks et al. is based on the binary presence/absence of input features, whereas our method perturbs inputs instead of removing them altogether. our work can also be viewed as a form of outlier detection. however, it di ers from the standard literature outlined by pimentel et al. with respect to the objective: we are not necessarily trying to identify outliers in terms of the training data but rather explain instances in the test set whose errors are so large that they are considered to be anomalies. miller et al. perform a survey of the papers cited in the \"related works\" section of the call for the ijcai 2017 explainable ai workshop and nd that the majority do not base their methods on the available research about explanations from other disciplines such as philosophy, psychology or cognitive sciences, or evaluate on real users. in contrast, our method is rooted in the corresponding philosophical literature and our evaluation is based on a user study.", "conclusion": "<title>conclusion</title> we have proposed a method, monte carlo bounds for reasonable predictions (mc-brp), that provides users with contrastive explanations about predictions resulting in large errors based on: (i) the set of bounds for which reasonable predictions would be expected for each of the most important features. (ii) the trend between each of these features and the target. given a large error, mc-brp generates a set of perturbed versions of the original instance that result in reasonable predictions. is is done by performing monte carlo simulations on each of the features deemed most important for the original prediction. for each of these features, we determine the bounds needed for a reasonable prediction based on the mean and standard deviation of this new set of reasonable predictions. we also determine the relationship between each feature and the target through the pearson correlation, and present these to the user as the explanation. we evaluate mc-brp both objectively (rq1) and subjectively (rq2) by conducting a user study with 75 real users from ahold delhaize and the university of amsterdam. we answer rq1 by conducting two types of simulations to quantify how (i) interpretable, and (ii) actionable our explanations are. rough forward simulations, we show that users are able to interpret mc-brp explanations by simulating the model's output with an average accuracy of 84.5%. rough counterfactual simulations, we show that mc-brp explanations are actionable with an accuracy of 76.2%. we answer rq2 by conducting a between-subject experiment with subjective questions. e treatment group sees mc-brp explanations, while the control group does not see any explanation. we nd that explanations generated by mc-brp help users understand why models make large errors in predictions (sq1), but do not have a signi cant impact on support in deploying the model (sq2), trust in the model (sq3), or perceptions of the model's performance (sq4). ese results still hold when conditioning on users' background (practitioners vs. researchers). we also conduct an analysis on the treatment group to compare results between practitioners and researchers. we nd signi cant di erences for sq2, sq3 and sq4, but do not nd a signi cant di erence in a itudes for sq1. for future work, we intend to explore allowing a predictive model to abstain from prediction when a particular instance has unusual feature values and determine the impact this has on users' trust, deployment support and perception of the model's performance. we also plan to compile a more comprehensive set of subjective questions by using multiple questions to evaluate users' impressions on the same topic."}
{"id": 1671, "date": "2019-12-01", "title": "An Observational Investigation of Reverse Engineers' Processes", "url": "https://arxiv.org/abs/1912.00317v1[cs.CR]", "keywords": [], "abstract": "everse engineering is a complex process essential to software-security tasks such as vulnerability discovery and malware analysis. significant research and engineering effort has gone into developing tools to support reverse engineers. however, little work has been done to understand the way reverse engineers think when analyzing programs, leaving tool developers to make interface design decisions based only on intuition. this paper takes a first step toward a better understanding of reverse engineers' processes, with the goal of producing insights for improving interaction design for reverse engineering tools. we present the results of a semi-structured, observational interview study of reverse engineers (n=16). each observation investigated the questions reverse engineers ask as they probe a program, how they answer these questions, and the decisions they make throughout the reverse engineering process. from the interview responses, we distill a model of the reverse engineering process, divided into three phases: overview, sub-component scanning, and focused experimentation. each analysis phase's results feed the next as reverse engineers' mental representations become more concrete. we find that reverse engineers typically use static methods in the first two phases, but dynamic methods in the final phase, with experience playing large, but varying, roles in each phase. based on these results, we provide five interaction design guidelines for reverse engineering tools.", "rq": ["rq 1:. what high-level process do res follow when examining a new program?", "rq 3:. how does the re process align with traditional program comprehension?"], "relatedWork": "background and related work: while little work has investigated expert re, there has been significant effort studying similar problems of naturalistic decision-making (ndm) and program comprehension. because of their similarity, we draw on theory and methods that have been found useful in these areas as well as in initial studies of re .", "conclusion": "<title>conclusion</title> our goal is to carefully model res' processes, in order to support better design of re tools. to do this, we conducted a semi-structured observational interview study of 16 professional res. we found that re involves three distinct phases: overview, sub-component scanning, and focused experimentation. reverse engineers work through a program using a variety of manual and automated approaches in each of these phases, often using a combination of methods to accomplish a specific task (e.g., a static analysis alongside a debugger). in the first two phases (overview and sub-component scanning), res typically use static techniques (e.g., looking at a control-flow graph), but switch to using dynamic techniques (e.g., debugging or dynamic analysis) in the last phase (focused experimentation). based on our results, we proposed five design guidelines for re tools. we believe our model will help in the design and development of re tools that more closely match the re process."}
{"id": 1705, "date": "2020-01-15", "title": "Scout: Rapid Exploration of Interface Layout Alternatives through High-Level Design Constraints", "url": "https://arxiv.org/abs/2001.05424v1[cs.HC]", "keywords": ["Interface design", "alternatives", "program synthesis", "constraints"], "abstract": "lthough exploring alternatives is fundamental to creating better interface designs, current processes for creating alternatives are generally manual, limiting the alternatives a designer can explore. we present scout, a system that helps designers rapidly explore alternatives through mixed-initiative interaction with high-level constraints and design feedback. prior constraint-based layout systems use low-level spatial constraints and generally produce a single design. to support designer exploration of alternatives, scout introduces high-level constraints based on design concepts (e.g., semantic structure, emphasis, order) and formalizes them into low-level spatial constraints that a solver uses to generate potential layouts. in an evaluation with 18 interface designers, we found that scout: (1) helps designers create more spatially diverse mobile interface layouts with similar quality to those created with a baseline tool and (2) can help designers avoid a linear design process and quickly ideate layouts they do not believe they would have thought of on their own.", "rq": ["rq 3: how does scout affect designer processes of exploring potential interface layouts?"], "relatedWork": ": scout is inspired by past systems for interacting with alternatives. designscape provides alternative suggestions for graphic design layouts using an energy-based model based on design principles. sketchsplore is an interface sketching tool that provides alternatives generated by human performance models. scout improves upon these systems by letting designers give direct feedback on attributes of alternatives and by letting designers create high-level constraints on the semantics and emphasis of their interfaces. designers frequently explore alternatives by looking for examples . d.tour lets designers search for examples by color and style, but not adapt them into their own designs. other example exploration tools let designers both search for examples and extract styles , copy elements from examples , or transform a layout into the content and style of another . rewire systems for creating and managing alternatives have been created for 2d graphic designs, 2d interfaces, and 3d modeling. for 2d interfaces, juxtapose supports simultaneous editing of linked alternatives. subjunctive interfaces lets a person simultaneously manage alternatives by editing parametric models. in parallel paths , people can create alternatives by branching from an initial design. unlike these systems, scout requires specifying only high-level semantics (e.g., emphasis), does not require an initial design, and focuses on early ideation support. for 2d generative designs, gem-ni supports parallel creation and exploration of alternatives. for 3d designs, dream sketch and dream lens enable exploration of largescale generative design alternatives through sketching or through interface tools for selecting, filtering, and visualizing parameters . scout supports a similar scope of capabilities (i.e., generating, viewing, and comparing alternatives), but focuses on support for exploring 2d interface alternatives. to create alternatives, scout systematically modifies design variables (e.g., arrangement, alignment). this concept is like parameter spectrum's approach that previews alternatives from a range of parameter values. juxtapose extends this to interface design by enabling the creation of parallel alternatives through code-based tuning of design parameters. scout does not expose these parameters to designers, however, it would be possible to make these customizable. model-based user interfaces let designers specify a high-level model and generate alternatives maintaining the model. smart templates and damask use models to maintain interface conventions across platforms. scout similarly maintains high-level constraints across alternatives. rather than creating templates or patterns, scout requires defining only high-level constraints between elements, which can enable it to generate many more alternatives. scout's approach is conceptually closer to previously-discussed generative design approaches or similar approaches in data visualization , yet focuses on 2d interface design. scout enables rapid generation of alternatives through constraint solving techniques . many past constraint-based layout tools focus primarily on creating a single design. scout instead can aid ideation by generating many alternatives. scout's approach is like that of pbm , which exploits constraint ambiguities to explore alternative data visualizations, or supple's generation of interfaces customized to motor and vision abilities. zeidler et. al. and jiang et. al. apply constraints to generate layouts adapted to alternate screen dimensions or orientations. machine learning has also been applied to explore alternatives by transforming the content of an interface into the style and layout of another . layoutgan synthesizes alternative layouts with a generative adversarial network based on modeling geometric relations of 2d elements. scout's use of constraint solving, rather than machine learning, gives it direct control over the attributes of layouts that the generation algorithms explore. scout can also generate reasonable alternatives without requiring a design dataset.", "conclusion": "<title>discussion and conclusion</title> scout can enhance designer ideation by helping rapidly visualize many layouts through mixed-initiative interaction with high-level constraints and feedback on alternatives. our evaluation found scout can aid designers in creating layout ideas they do not believe they would have otherwise thought of, can help designers avoid developing too early of a focus on a single design, and can help designers consider layouts different from established patterns. scout designs were also more spatially diverse both within and across designers. although not statistically significant, our quality analysis found scout designs were awarded slightly lower overall quality scores by expert designers. this suggests opportunities to improve scout in terms of balance, emphasis, and alignment. however, participants also had access to the functionality of adobe xd to refine their designs after scout ideation (i.e., the same tool used in the baseline). any difference in quality may therefore be due to a lack of time. scout required time for specifying elements as well as their grouping, ordering, and emphasis, which may have left less time for refinement of designs at the end of the task. future work could explore integrating capabilities developed in scout as a feature in an existing design tool (e.g., adobe xd), such that elements, grouping, ordering, and emphasis could be inferred from an existing layout to generate new alternatives. scout points to a new approach to using constraints to support ideation and presents new techniques for providing feedback to systems applying constraint solving. future systems can explore: (1) formalizations of interface design principles into tools that help designers apply those principles, especially when supporting novice designers, (2) scaling interactive constraint solving to larger interfaces (e.g., webpages), and (3) defining more layout variables and constraints to enable systems like scout to explore larger and higher-quality spaces of alternatives."}
{"id": 1729, "date": "2020-01-27", "title": "Conversations with Documents An Exploration of Document-Centered Assistance", "url": "https://arxiv.org/abs/2002.00747v1[cs.CL]", "keywords": ["Document-centered assistance", "Productivity", "Digital assistants", "Question answering"], "abstract": "he role of conversational assistants has become more prevalent in helping people increase their productivity. document-centered assistance, for example to help an individual quickly review a document, has seen less significant progress, even though it has the potential to tremendously increase a user's productivity. this type of document-centered assistance is the focus of this paper. our contributions are three-fold: (1) we first present a survey to understand the space of document-centered assistance and the capabilities people expect in this scenario. (2) we investigate the types of queries that users will pose while seeking assistance with documents, and show that document-centered questions form the majority of these queries. (3) we present a set of initial machine learned models that show that (a) we can accurately detect document-centered questions, and (b) we can build reasonably accurate models for answering such questions. these positive results are encouraging, and suggest that even greater results may be attained with continued study of this interesting and novel problem space. our findings have implications for the design of intelligent systems to support task completion via natural interactions with documents.", "rq": ["rq 1: what kinds of conversational assistance would people like to receive in a document consumption scenario?", "rq 2: what kinds of queries might people use to receive this assistance when conversing with a document-aware assistant?", "rq 3: how well do initial baseline models do in a document-centered scenario?", "rq 3: how well do initial baseline models do in a documentcentered scenario?"], "relatedWork": ": this paper is related to two broad strands of research. in the first part of this section we look into voice controlled document narration and natural language interactions with productivity software, which is relevant to the first step of our research, the survey. our initial modeling steps focus on single-turn conversations, and so we conclude this section with work on question answering.", "conclusion": "<title>conclusions and future work</title> in this paper, we explored the novel domain of document-centered digital assistance. we focused on a consumption scenario, in which individuals are a (co-)owner of a document. through a survey, we identified a set of primary capabilities people expect from a digital assistant in a document-centered scenario, as well as a large set of questions that gave us insight into the types of queries that people might pose about a document when they have an approximate or good idea what the document is about. our explorations shed light on the hierarchy of questions that might be posed, and demonstrate that the types of questions people ask in a document-centered scenario are different from the factoid questions in conventional qa datasets. we show that state-of-the-art qa models can be finetuned to perform with reasonable accuracy on the new dqa data. yet, it has proven to be an unsolved task, which makes this a fertile area for future work. this research opens a new direction for digital assistance. avenues for future work include deeper explorations of query rewriting to better tailor document-centered questions to conventional qa systems, and also exploring ways to scale up the data to a much larger and broader range of documents."}
{"id": 1811, "date": "2020-04-01", "title": "Cognitive Production Systems: A Mapping Study", "url": "https://arxiv.org/abs/2003.13235v3[cs.MA]", "keywords": ["production systems", "robotics", "coginitive", "IIoT", "Multi-Agent-Systems", "Human-Maschine-Interaction"], "abstract": "production plants today are becoming more and more complicated through more automation and networking. it is becoming more difficult for humans to participate, due to higher speed and decreasing reaction time of these plants. tendencies to improve production systems with the help of cognitive systems can be identified. the goal is to save resources and time. this mapping study gives an insight into the domain, categorizes different approaches and estimates their progress. furthermore, it shows achieved optimizations and persisting problems and barriers. these representations should make it easier in the future to address concrete problems in this research field. human-machine interaction and knowledge gaining/sharing represent the largest categories of the domain. most often, a gain in efficiency and maximized effectiveness can be achieved as optimization. the most common problem is the missing or only difficult generalization of the presented concepts.", "rq": ["rq 1: what types of concepts exist for cps?", "rq 1: what types of of concepts exist for cognitive production systems?", "rq 2: are these types only theory and concepts or are some of them used in practice?", "rq 4: what are problems and barriers for cps-prototypes?", "rq 4: what are the most relevant problems and barriers for cps-prototypes?"], "relatedWork": ": lots of papers describe the future challenges and requirements of modern manufacturing. osterrieder et al. are using the term \"smart factory\" in their literature review. they define the smart factory as a \"future state of a fully connected manufacturing system, mainly operating without human force by generating, transferring, receiving and processing necessary data to conduct all required tasks for producing all kinds of goods\". this work aims deeper into the area and does not restrict the manufacturing itself to work without human help. the human-robot collaboration is used in cognitive production systems to fulfil specific jobs. contrary to the paper of sharp et al. this work is more generalised. sharp et al. prove a growing interest in the use of machine learning in production. they mark for instance \"nearest-neighbour\" and \"support-vector-machine\" as popular algorithms in production. machine learning focuses on autonomous knowledge gain of computers. the reasons why a computer reacts in different situation with different actions are usually hided and afterwards not explainable. cps also consider the past and the future of certain processes as important. decisions in these systems are only made through clear reasons that a human person can understand. according to goebel \"an effective explanation helps the explainer cross a cognitive valley\". that is why we want explainable-ai for users of cps in the factory. missing tools that \"support for managing the various aspects and complexities involved in the transformation towards a smart industry\" are described by breivold . he marked the following six topics as the key drivers for developing production environments with cloud and iot systems: this work delivers methods and constructs to reach cognitive production. we tried to identify rudiments in which future tools could take place. the implementation of a cps introduces new challenges that have to be solved. herv\u00e9 et al. describe the importance of human-machine collaboration in socio-technical systems in their paper. for the operator 4.0, which is also often mentioned in other works ( , , ), technologies must be used to this operator even better and more efficiently with intelligent systems. other concepts such as decision-making and self-organization are also emerging as important cornerstones in future cyber-physical production systems. there are overlaps to this work. these and other challenges that were defined and explained by panetto et. al are addressed by cognitive production systems with different concepts and methods. the goal of mass-personalization is used as one main motivation in the critical review of moghaddam et al. . in addition manufacturing should provide \"smart and sustainable products and services, and enable real-time adaption to customer demand\". they criticize the mass of new paradigms for smart manufacturing and try to filter out the characteristics of this type of production. cps should not become a new basic paradigm, but rather combine existing concepts and techniques with some limitations to meet the requirements of modern manufacturing.", "conclusion": "<title>conclusion and future work</title> we carried out extensive research on the topic of cognitive production systems (cps) in five scientific online databases. a first set of results consisting of 1255 papers from 2015-2019 was narrowed down to a final set of 88 papers. the carefully selected papers, corresponding to only 7.01 % of the first result set, represent a representative amount of keywords documented above during this period. four research questions were set up, which were then answered step by step by means of an analysis according to aspects such as categorisation, condition, advantages and problems. the established categories reflect different aspects of cps such as human-machine interaction and multi-agent systems. the state of the papers in terms of theory and practice produced different results in the individual categories. for example, the category knowledge gaining/sharing was significantly more practice-oriented than the other categories, while the category human-machine interaction was evenly distributed across all states. the advantages identified partly coincided with the expectations of cps. for example, the most frequently mentioned advantage \"efficiency gain/improvement in effectiveness\" best contributes to \"mass customization\" and the resulting shorter reaction time to changes. other optimizations such as \"information retrieval/distribution/use optimized\" and \"manual intervention reduced\" also meet the expectations of modern production systems and contribute to better integration of people in production and better interaction with machines. problems and barriers arise above all in the generalizability of the concepts discussed. furthermore some approaches are too complex, too slow or too imprecise. however, the authors of the papers often mention plans to tackle the problems mentioned in the future and thus to further develop their concepts. generalizable concepts that can be used for various applications in production should be further researched in the future. especially the use of artificial intelligence to automate complex tasks is worthwhile. at the same time, human beings and their role in production should also be considered. cognitive skills should develop the human being into a supervisor rather than a mere production worker. further research is also needed into solutions that provide humans with information in a compressed form that enables them to react quickly to the role of the supervisor even when changes occur frequently. although the human being is still an important part of the production after evaluation of the available work, direct manual interventions in the production should be further reduced. it remains to be seen how long humans will be able to withstand the ever-increasing demands in terms of reaction speed, efficiency and amount of information, until they will eventually be completely replaced by machines in the production process."}
{"id": 1865, "date": "2020-05-07", "title": "Faceted search of heterogeneous geographic information for dynamic map projection", "url": "https://arxiv.org/abs/2005.03531v1[cs.HC]", "keywords": ["faceted information exploration", "dynamic projection of geographic maps", "GIS", "geographic information search"], "abstract": "his paper proposes a faceted information exploration model that supports coarse-grained and fine-grained focusing of geographic maps by offering a graphical representation of data attributes within interactive widgets. the proposed approach enables (i) a multi-category projection of long-lasting geographic maps, based on the proposal of efficient facets for data exploration in sparse and noisy datasets, and (ii) an interactive representation of the search context based on widgets that support data visualization, faceted exploration, category-based information hiding and transparency of results at the same time. the integration of our model with a semantic representation of geographical knowledge supports the exploration of information retrieved from heterogeneous data sources, such as public open data and openstreetmap. we evaluated our model with users in the ontomap collaborative web gis. the experimental results show that, when working on geographic maps populated with multiple data categories, it outperforms simple category-based map projection and traditional faceted search tools, such as checkboxes, in both user performance and experience.", "rq": ["rq 2: how does a compact, graphical view of the exploration options available to the user, which also shows the status of the information visualization constraints applied to a map, impact on her/his efficiency and experience in data exploration?", "rq 3: how much does the user's familiarity with the widgets for faceted exploration impact on her/his efficiency in search and on her/his appreciation of the exploration model they offer?"], "relatedWork": "background and related work: exploratory search of large information spaces challenges users in the specification of efficient queries because, as most people are hardly familiar with the search domain, their information goals are often ill-defined (marchionini, 2006;white & roth, 2006). in this paper we focus on faceted search as an alternative, or a complement, to query typing in order to use browsing-based navigation as a proactive guide to information exploration, given the structure of the information space. starting from the pioneer filtering model proposed by ahlberg & shneiderman (1994), both sacco (2000)'s dynamic taxonomies and hearst (2006)'s faceted search model propose to use dynamic filters extracted from items metadata as constraints that the system can suggest to help the user identify relevant terms for information filtering and visualization of results. specifically, hearst et al. (2002) present the flamenco framework in which facet-based filtering is based on the exposure of hierarchical faceted metadata that describes the items of the search domain, i.e., apartments, or images (yee et al., 2003). researchers also investigate ways to support the specification of the facets to filter results, as well as the access to semantic web information and linked data (w3c, 2018). as far as facet specification is concerned, new types of elements are proposed to filter the set of results; e.g., keywords or terms extracted from textual queries, as in hotmap (hoeber & yang, 2006), concepts extracted from a document pool, as in concept highlighter (hoeber & yang, 2006), or terms extracted from a thesaurus as in thesaurus-results browser (sutcliffe et al., 2000). facetlens (lee et al., 2009) visualizes clickable facets in matrix-based bubbles, each one associated with a different search filter. moreover, facetzoom (dachselt et al., 2008) proposes a stack-based visualization of hierarchical facets, also applied in mambo (dachselt & frisch, 2007) as a model to combine faceted browsing with zoomable user interfaces. searchlens (chang et al., 2019) enables users to define long-lasting composite facet specifications (denoted as lenses) to support information filtering on multiple search sessions. in searchlens, the user can specify the importance of the selected facets; thus, filtering is based on soft constraints used to rank search results. in the faceted exploration of semantic data (tzitzikas et al., 2017) the specific words occurring in the queries, via natural language processing (ardissono et al., 2016;mauro et al., 2017). more generally, ontomap enables search support over a configurable set of data categories; in this way, it enables complex map development on different information domains. in contrast, most of the previous systems work on a single data type or on a pre-defined set of data categories, as in (petrelli et al., 2009). the dynamic extraction of facets can challenge the user with a large number of browsing options. oren et al. (2006) focus on the efficiency of exploration and they promote the facets that enable the user to split the set of results in balanced subsets in order to minimize navigation steps. in comparison, we propose a facet selection policy suitable for sparse and highly unbalanced result sets, such as those typically retrieved from crowdsourced data sources, in which very few properties of items split results in subsets having similar cardinality. some works propose interactive graphical presentations of keywords to support sensemaking in the exploration of document sets. for instance, peltonen et al. (2017) propose the topic-relevance map to summarize on a radial basis the keywords (filters) characterizing the result set, using distance from the center to represent relevance to the search query and angle between keywords to denote their topical similarity. moreover, facetatlas (cao et al., 2010) relates topics in a 3d diagram supporting the representation of multi-dimensional relations among them, and solarmap (cao et al., 2011) combines topic-based document clustering with a radial representation of facets to support a twolevel, topic-based document filtering. while these models are appropriate to the representation of topics in datasets of unstructured information, they are less relevant to ontomap, which is fed with structured data and benefits from its domain ontology to organize the presentation of information.", "conclusion": "<title>conclusions and future work</title> we presented a faceted information exploration approach supporting a flexible visualization of heterogeneous geographic data. our model provides a multicategory faceted projection of long-lasting geographic maps to answer temporary information needs; this is based on the proposal of efficient facets for data exploration in sparse and noisy datasets. moreover, the model provides a graphical representation of the search context by means of alternative types of widget that support interactive data visualization, faceted exploration, category-based information hiding and transparency of results at the same time. we carried out a user study involving 62 people who have diverse familiarity with technology and with map-based online systems. the results of this study show that, when working on maps populated with multiple data categories, our model outperforms simple category-based map projection and traditional faceted search tools such as checkboxes. moreover, the layout that uses the sunburst diagram as a graphical widget supports the best user performance and experience, thanks to its clarity and visual compactness. we thus conclude that this implementation is promising for flexible faceted exploration in geographic information search. the described work has limitations that we plan to address: \u2022 our model only supports the specification of hard visualization constraints on facet values; i.e., the items having a certain value of a facet are either shown, or hidden. however, the user might want to specify preferences. therefore, similar to what has been done in some related works (see section 3), we plan to manage soft visualization constraints. \u2022 so far, we present search results in geographic maps and we provide item details in dynamically generated tables showing their properties. in order to enhance data interpretation and sensemaking, we plan to develop additional visualization models supporting visual analytics; e.g., see (andrienko et al., 2007;tsai & brusilovsky, 2019;cardoso et al., 2019). \u2022 we designed the questionnaires of our user study by taking inspiration from existing sources (nasa tlx and user experience questionnaire) but we personalized the questions in order to test the specific aspects which are the focus of the present paper. we plan a credibility/validity analysis to verify that our questionnaires are strictly related to these sources. \u2022 further experiments are needed to validate the proposed model with a larger set of people and on mobile phones (the ontomap user interface scales well to the screens of tablets). \u2022 currently, our model supports a \"one size fits all\" type of faceted search that exploits general efficiency criteria to guide the user in data explo-ration. however, some researchers propose to adapt facet suggestion to the user's preferences in order to personalize the navigation of the information space; e.g., see (tvaro\u017eek et al., 2008;tvaro\u017eek & bielikov\u00e1, 2010;koren et al., 2008;abel et al., 2011). in our future work, we plan to offer multiple data exploration strategies which the user can choose from, including a user-adaptive facet suggestion that depends on her/his preferences and on the search context. \u2022 depending on their roles, in some scenarios users might need to access different, long-lasting custom views of a shared information space (rasmussen & hertzum, 2013). we plan to extend our model by introducing permanent, user-dependent views on map content."}
{"id": 1887, "date": "2020-05-27", "title": "Code Duplication and Reuse in Jupyter Notebooks", "url": "https://arxiv.org/abs/2005.13709v1[cs.SE]", "keywords": ["Jupyter", "computational notebooks", "code duplication", "code clones", "code reuse", "data analysis", "data exploration", "exploratory programming"], "abstract": "uplicating one's own code makes it faster to write software. this expediency is particularly valuable for users of computational notebooks. duplication allows notebook users to quickly test hypotheses and iterate over data. in this paper, we explore how much, how and from where code duplication occurs in computational notebooks, and identify potential barriers to code reuse. previous work in the area of computational notebooks describes developers' motivations for reuse and duplication but does not show how much reuse occurs or which barriers they face when reusing code. to address this gap, we first analyzed github repositories for code duplicates contained in a repository's jupyter notebooks, and then conducted an observational user study of code reuse, where participants solved specific tasks using notebooks. our findings reveal that repositories in our sample have a mean self-duplication rate of 7.6%. however, in our user study, few participants duplicated their own code, preferring to reuse code from online sources.", "rq": ["rq 1: how much cell code duplication occurs in jupyter notebooks?", "rq 2: how does cell code reuse happen in jupyter notebooks?", "rq 3: what are the preferred sources for code reuse in jupyter notebooks?"], "relatedWork": ". background and related work: computational notebooks are a relatively new interactive computational paradigm that allows users to interleave code and text via a web interface. programming code is introduced and segmented into code cells that are executed in a kernel (python, r, julia, c++, other) with computation output/results returned to the web interface for display. this new way of computation makes sharing and coding easy for programming newcomers as users do not need to compile code or deal with low-level configurations. several services currently offer computational notebooks: google colab & cloud ai platform , azure notebooks , databricks , nteract , apache zeppelin , to name a few. these services provide even more abstraction by taking care of kernel configurations and just providing one for the user to select and use. in this section, we will discuss code reuse within this medium of computation.", "conclusion": "<title>vii. conclusion</title> we examined how code duplication and reuse happens in jupyter notebooks. our first study looked at how much selfduplication (i.e., within the repository) exists. we discovered that on average 7.6% of code in repositories is self-duplicated. however, this did not explain how or from where code was duplicated to begin with. we conducted a lab study with eight participants and deliberately crafted tasks designed to encourage reuse behaviour. we observed how participants reused code to solve data science tasks and how they leveraged version control, online sources and other notebooks. reusing code from online sources proved to be the preferred method of reuse for our participants, with 18% of their time spent browsing for code examples online, and version control systems proved to be the least effective method of reuse. snippets of code that visualize data are the ones that are duplicated the most. we conclude this paper by discussing observations and implications from our studies. first, while code duplication is clearly common in notebooks, the source of that duplication is important. second, although much attention focuses on version control, for code reuse, other sources, such as api examples, are more important. finally, these external sources are used for various tasks. notebook interfaces should support modularization and reuse to improve cognitive support for data scientists."}
{"id": 1987, "date": "2020-08-03", "title": "Hate begets Hate: A Temporal Study of Hate Speech", "url": "https://arxiv.org/abs/1909.10966v2[cs.SI]", "keywords": ["Hate Speech", "Temporal Analysis", "Gab", "Freedom of Speech", "Moderation", "Degroot", "Language Analysis"], "abstract": "ith the ongoing debate on 'freedom of speech' vs. 'hate speech,' there is an urgent need to carefully understand the consequences of the inevitable culmination of the two, i.e., 'freedom of hate speech' over time. an ideal scenario to understand this would be to observe the effects of hate speech in an (almost) unrestricted environment. hence, we perform the first temporal analysis of hate speech on gab.com, a social media site with very loose moderation policy. we first generate temporal snapshots of gab from millions of posts and users. using these temporal snapshots, we compute an activity vector based on degroot model to identify hateful users. the amount of hate speech in gab is steadily increasing and the new users are becoming hateful at an increased and faster rate. further, our analysis analysis reveals that the hate users are occupying the prominent positions in the gab network. also, the language used by the community as a whole seem to correlate more with that of the hateful users as compared to the non-hateful ones. we discuss how, many crucial design questions in cscw open up from our work.", "rq": ["rq 1: how can we characterize the growth of hate speech in gab?", "rq 2: how have the hate speakers affected the gab community as a whole?", "rq 2: what was the impact of the hateful users on gab?"], "relatedWork": "prior work: the hate speech research has a substantial literature and it has recently gained a lot of attention from the computer science perspective. in the following sections, we will examine the various aspects of research on hate speech. interested readers can follow fortuna et al. and schmidt et al. for a comprehensive survey of this subject.", "conclusion": ""}
{"id": 2027, "date": "2020-08-21", "title": "Investigating Differences in Crowdsourced News Credibility Assessment: Raters, Tasks, and Expert Criteria", "url": "https://arxiv.org/abs/2008.09533v1[cs.HC]", "keywords": ["misinformation", "crowdsourcing", "credibility", "news", "expert"], "abstract": "misinformation about critical issues such as climate change and vaccine safety is oftentimes amplified on online social and search platforms. the crowdsourcing of content credibility assessment by laypeople has been proposed as one strategy to combat misinformation by attempting to replicate the assessments of experts at scale. in this work, we investigate news credibility assessments by crowds versus experts to understand when and how ratings between them differ. we gather a dataset of over 4,000 credibility assessments taken from 2 crowd groups-journalism students and upwork workers-as well as 2 expert groups-journalists and scientists-on a varied set of 50 news articles related to climate science, a topic with widespread disconnect between public opinion and expert consensus. examining the ratings, we find differences in performance due to the makeup of the crowd, such as rater demographics and political leaning, as well as the scope of the tasks that the crowd is assigned to rate, such as the genre of the article and partisanship of the publication. finally, we find differences between expert assessments due to differing expert criteria that journalism versus science experts use-differences that may contribute to crowd discrepancies, but that also suggest a way to reduce the gap by designing crowd tasks tailored to specific expert criteria. from these findings, we outline future research directions to better design crowd processes that are tailored to specific crowds and types of content.", "rq": ["rq 1: how do crowd raters compare with experts when it comes to news credibility assessments?", "rq 2: how do personal characteristics of age, education, gender, and political leaning affect credibility ratings from the crowd?", "rq 4: how do experts in science versus journalism differ in the criteria they use to assess news credibility?"], "relatedWork": "2.1 credibility: credibility is often defined as a multi-dimensional construct comprising believability , fairness , reliability , quality , trust , accuracy , objectivity/bias and \"dozens of other concepts and combination thereof\" . compared to other works, credibility has been defined by flanagin and metzger as made up of two primary dimensions: trustworthiness and expertise . oftentimes, credibility is targeted at just the message and/or the source, while some extend it to consider context, such as the channel or medium where the message is published . however, research has also shown that receivers often do not distinguish between message source and the medium . furthermore, scholars from information science to cognitive psychology can range in their definition of credibility as a purely objective assessment or a subjective judgment by the information receiver, adding complexity to the primary dimensions . despite significant scholarly work in multi-disciplinary domains, the definition of credibility and its measurement still lacks a unified strategy . consequently, in this work, we approach credibility as a blend of subjective and objective assessments of the \"message, \" in this case, the news article.", "conclusion": "<title>conclusion</title> in this work, using the domain of climate news, we dive into the notion of crowdsourcing credibility through a series of analyses on its main components: the makeup of the crowd, the scope of tasks that the crowd is assigned, and the subject area expert criteria in question. in particular, we explore characteristics of the \"crowd, \" in terms of traits such as background, demographics, and political leaning, and whether they have bearings on task performance. we show this in a comparison between ratings made by students and others recruited through journalism networks versus crowd workers on upwork. we also interrogate the nature of the crowdsourcing task itself, finding that the genre of the article and partisanship of the publication has different relationship to both crowds and experts. this led us to better understand the reasoning of experts themselves. in our case, we looked at how experts in journalism versus experts in science have different ways to assess article credibility based on the factors such as credible evidence/grounding and publication reputation. disagreement among raters is neither always bad nor always about their capacities, but at times about suitability of the task and about the particular subject area expertise in question as well. by investigating the variability introduced by all these components, we point towards how the design of crowd assessments to approximate expert-level credibility can be made more robust. for expert groups, we take all 3 ratings. then we compute the spearman \u03c1 between the mean responses from each group on all 50 articles. the plot shows average \u03c1 after 100 resamplings."}
{"id": 2046, "date": "2020-08-27", "title": "Good for the Many or Best for the Few? A Dilemma in the Design of Algorithmic Advice", "url": "https://arxiv.org/abs/2008.12147v1[cs.HC]", "keywords": [], "abstract": "pplications in a range of domains, including route planning and well-being, offer advice based on the social information available in prior users' aggregated activity. when designing these applications, is it better to offer: a) advice that if strictly adhered to is more likely to result in an individual successfully achieving their goal, even if fewer users will choose to adopt it? or b) advice that is likely to be adopted by a larger number of users, but which is sub-optimal with regard to any particular individual achieving their goal? we identify this dilemma, characterized as goal-directed vs. adoption-directed advice, and investigate the design questions it raises through an online experiment undertaken in four advice domains (financial investment, making healthier lifestyle choices, route planning, training for a 5k run), with three user types, and across two levels of uncertainty. we report findings that suggest a preference for advice favoring individual goal attainment over higher user adoption rates, albeit with significant variation across advice domains; and discuss their design implications. ccs concepts: \u2022 human-centered computing \u2192 empirical studies in hci.", "rq": ["rq 1: are participants' preferences between offering goal-directed advice and adoption-directed advice sensitive to different domain scenarios, or do they transcend specific settings?", "rq 2: are participants' preferences between offering goal-directed advice and adoption-directed advice sensitive to the different perspectives of 'advice giver' and 'advice receiver'?"], "relatedWork": ": this research was inspired by the observation that users may discount or ignore algorithmic advice intended to support the choices they make towards achieving particular goals, specifically when this advice may appear counter-intuitive or challenging to adhere to. in order to situate our work we provide an overview of related prior research in 1) decision making under uncertainty; and 2) online advice and recommendation.", "conclusion": "<title>conclusion</title> in this paper we have made an initial step towards better understanding the advice design dilemma that arises when advice most likely to maximize an individual's chances of achieving their goal is not the same as advice most likely to maximize the number of people who will adopt it. we studied participants' preferences when selecting between goal-directed and adoption-directed advice online in an experimental study spanning four domain scenarios, three user types, and two variations in the gap between goal attainment and advice adoption probabilities. we found an average preference for advice that favors individual goal attainment over higher user adoption rates, albeit with some variation across advice domains. the implications of these findings are both practical and theoretical. from a practical perspective, choosing between presenting advice that may be best in terms of individual goal attainment but which will reach few users, or advice that is merely good but will be adopted by many, is likely to be an increasingly common dilemma for designers to face in algorithmic advice design scenarios. from a theoretical perspective, the preferences shown for goal-directed advice (i.e. advice best for individual goal attainment that will be adopted by few users), and the explanations revealed in participants' survey comments, echo responses to moral dilemmas, e.g. , where people eschew making decisions that are sub-optimal at the individual level, even if they are optimal at the population level. with the rapid growth in applications driven by algorithmic advice based on the social information derived from aggregated prior use, hci and cscw researchers and practitioners are likely to increasingly engage with these fundamental questions. our findings will help inform this conversation."}
{"id": 2054, "date": "2020-08-31", "title": "Quaternion-Based Self-Attentive Long Short-term User Preference Encoding for Recommendation", "url": "https://arxiv.org/abs/2008.13335v1[cs.IR]", "keywords": ["Long-term and short-term user preferences", "Quaternion-based recommenders", "Quaternion-based attention", "adversarial training"], "abstract": "quaternion space has brought several benefits over the traditional euclidean space: quaternions (i) consist of a real and three imaginary components, encouraging richer representations; (ii) utilize hamilton product which better encodes the inter-latent interactions across multiple quaternion components; and (iii) result in a model with smaller degrees of freedom and less prone to overfitting. unfortunately, most of the current recommender systems rely on realvalued representations in euclidean space to model either user's long-term or short-term interests. in this paper, we fully utilize quaternion space to model both user's long-term and short-term preferences. we first propose a quaternion-based self-attentive long term user encoding (quale) to study the user's long-term intents. then, we propose a quaternion-based self-attentive short term user encoding (quase) to learn the user's short-term interests. to enhance our models' capability, we propose to fuse quale and quase into one model, namely qualse, by using a quaternionbased gating mechanism. we further develop quaternion-based adversarial learning along with the bayesian personalized ranking (qabpr) to improve our model's robustness. extensive experiments on six real-world datasets show that our fused qualse model outperformed 11 state-of-the-art baselines, improving 8.43% at hit@1 and 10.27% at ndcg@1 on average compared with the best baseline.\u2022 information systems \u2192 recommender systems.", "rq": ["rq 1: how do our proposals work compared to the baselines?", "rq 2: how do a user's long-term, short-term preference encoding models and the fused model perform?", "rq 3: is using quaternion representation helpful and why?", "rq 4: are the gating fusion mechanism and the quaternion bpr adversarial training helpful?"], "relatedWork": ": general recommenders. matrix factorization is the most popular method to encode global user representations by using unordered user-item interactions . its basic idea is to represent users and items by latent factors and use dot product to learn the user-item affinity. despite their success, they cannot model non-linear user-item relationships due to the linear nature of dot product. to overcome the limitation, neural network based recommenders were recently introduced . combined a generalized matrix factorization component and a non-linear useritem interactions via a mlp architecture. substituted the mlp architecture with the auto-encoder design. used memory augmentation to learn different user-item latent relationship. when non-existed users come with some observed interactions (i.e., recently created user accounts with some item interactions), the recommenders need to be rebuilt to generate their representations. to avoid these issues, current works encode users by combining the users' consumed item embeddings in two main streams: (i) taking average of the consumed items' latent representations , or (ii) attentively summing the consumed items' embeddings. despite their success, general recommenders mostly consider all users' unordered consumed items, and produce global/long-term user representations, which are supposed to be static, or changed slowly. thus, they failed to capture the user's dynamic behavior, that is captured by the user's short-term preference (see figure 1). sequential recommenders. sequential recommendation is known for its superiority to capture temporal dependencies between historical items . early works relied on markov chains to capture item-item sequential patterns . other works exploited the convolution architecture to capture more complex temporal dependencies . these methods used short-term item dependencies to model a user's dynamic interest. other sequential recommenders focused on modeling long-term user preferences using rnn-based architectures . however, modeling either long-term user interests or short-term user interests is suboptimal since they concurrently affect a user's intent (figure 1). recent works combined both long and short-term user preferences in real-valued representations to obtain satisfactory results . compared with the prior works which used real-valued representations , we propose quaternion-based models to capture the user's long-term and short-term interests. quaternion was first introduced by and it has recently shown its effectiveness over real-valued representations in nlp and computer vision domains . we acknowledge that qcf model is the first quaternion-based recommender. however, the authors used it as a simple extension of the matrix factorization method, where users and items are quaternion embeddings. thus, the benefits of quaternion representation were not fully exploited in their network. furthermore, they designed the model for a general recommendation problem, which has an inherent limitation of only modeling the user's global interest.", "conclusion": "<title>conclusion</title> in this paper, we have shown that user's short-term and longterm interests are complementary and both of them are indispensable. we fully utilized quaternion space and proposed three novel quaternion-based models: (1) a quale model learned the user's long-term intents, (2) a quase model learned the user's short-term interests, and (3) a qualse model fused quale and quase to learn both user's long-term and short-term preferences. we also proposed a quaternion-based adversarial attack on bayesian personalized ranking (qabpr) loss to improve the robustness of our proposals. through extensive experiments on six real-world datasets, we showed that our qualse improved 6.87% at hit@1 and 8.71% at ndcg@1, and aqualse improved 8.43% at hit@1 and 10.27% at ndcg@1 on average compared with the best baseline. our proposed models consistently achieved the best results when varying top-n (e.g., hit@100 and ndcg@100). these results show the effectiveness of our proposed framework."}
{"id": 2068, "date": "2020-09-05", "title": "Friend Network as Gatekeeper: A Study of WeChat Users' Consumption of Friend-Curated Contents", "url": "https://arxiv.org/abs/2009.02531v1[cs.SI]", "keywords": ["Friend-curated content", "information consumption", "gatekeeper"], "abstract": "social media enables users to publish, disseminate, and access information easily. the downside is that it has fewer gatekeepers of what content is allowed to enter public circulation than the traditional media. in this paper, we present preliminary empirical findings from wechat, a popular messaging app of the chinese, indicating that social media users leverage their friend networks collectively as latent, dynamic gatekeepers for content consumption. taking a mixed-methods approach, we analyze over seven million users' information consumption behaviors on wechat and conduct an online survey of 216 users. both quantitative and qualitative evidence suggests that friend network indeed acts as a gatekeeper in social media. shifting from what should be produced that gatekeepers used to decide, friend network helps separate the worthy from the unworthy for individual information consumption, and its structure and dynamics that play an important role in gatekeeping may inspire the future design of socio-technical systems.\u2022 human-centered computing \u2192 empirical studies in collaborative and social computing; social media.", "rq": ["rq 1:. how do wechat users utilize friend networks and subscriptions collectively as latent gatekeepers for content consumption?", "rq 3:. how do wechat users adapt gatekeeping for content consumption over time?"], "relatedWork": "background and related work 2.1 gatekeeping in social media era: unlike traditional media, today's social media can be indelibly remarked as we media , i.e., user-operated media, in which there is no clear boundary between information producers, disseminators, and consumers, and the contents published are no longer constrained by length, timeliness, and the relevance to readers in a geographical and cultural sense . although social media users play an active role in shaping the online information landscape , they might not have the same level of professional qualities as the experts in the media industry for \"gatekeeping\", i.e., scrutinizing content, safeguard its validity, veracity, and integrity before reaching the public . ira basen pointed out that digital media platforms have fewer filters and gates than traditional media, making it challenging for users to determine what is new and what is important. keen mentioned that web 2.0 has a negative impact on gatekeeping because of the reduction in gates or official gatekeepers who are accountable and professional. he maintained that \"gatekeepers are a necessity due to the flood of information coming digitally.\" clark interviewed several news professionals and asked how social media plays roles in their daily professional lives, showing that the downsizing of newsrooms has made an impact on the traditional role of the editors as a gatekeeper. besides, different from the definition of \"gatekeeper\" for traditional media that in a sense if something is \"gatekept\", it won't go public to anyone, many social media services offer the \"share\" features for users to spread information in their social circles. in other words, even if a user decides not to share the content, the content could still be seen by its friends through other friends (if they choose to share the content). the above studies mainly focus on studying the changes of gatekeeping from traditional media era to today's social media era, under the context that social media consumers have to face a flood of fake news and information. leavitt et al. looked at reddit to understand how the design of reddit's platform impacts the information visibility in response to ongoing events in the context of controlling information flows (through gatekeeping). similar to the functions of gatekeeping in social media platforms, social media influencers (smis) represent a new type of independent third party endorser who shape audience attitudes through blogs, tweets, and the use of other social media , and there are technologies developed to identify and track the influencers. however, different from social influencers, the gatekeeping in social platform plays a latent role in a collective and dynamic manner. in our work, we focus on moments -a distinguishing feature of friend network in wechat, and study how wechat users utilize their friend networks as latent gatekeepers collectively and dynamically to safeguard the information they consume.", "conclusion": "<title>conclusion</title> in this paper, we conduct a mixed-methods approach to studying \"friend network as a latent gatekeeper\" phenomenon on a friendbased social media wechat. we analyze over seven million users to infer how they accommodate and safeguard their information through social circles and social ties. we also conduct a survey of 216 wechat users about their reading activities on wechat. results indicate that wechat users prefer the friend network when information is overloaded. they like to leverage weak-ties getting exposed to new domains, and turn to strong-ties when demanding credible and reliable information. elder users with fewer experience using wechat are more likely to consume friend-curated contents. users leverage social circles to gatekeep information interests and the interests and attention paid to them can shift from one social circle to another."}
{"id": 2083, "date": "2020-09-09", "title": "Presenting and Evaluating the Impact of Experiential Learning in Computing Accessibility Education", "url": "https://arxiv.org/abs/2002.06445v3[cs.SE]", "keywords": ["Accessibility Education", "Computing Education", "Computing Accessibility"], "abstract": "studies indicate that much of the software created today is not accessible to all users, indicating that developers don't see the need to devote sufficient resources to creating accessible software. compounding this problem, there is a lack of robust, easily adoptable educational accessibility material available to instructors for inclusion in their curricula. to address these issues, we have created five accessibility learning labs (all) using an experiential learning structure. the labs are designed to educate and create awareness of accessibility needs in computing. the labs enable easy classroom integration by providing instructors with complete educational materials including lecture slides, activities, and quizzes. the labs are hosted on our servers and require only a browser to be utilized. to demonstrate the benefit of our material and the potential benefits of our experiential lab format with empathy-creating material, we conducted a study involving 276 students in ten sections of an introductory computing course. our findings include: (i) the demonstrated potential of the proposed experiential learning format and labs are effective in motivating and educating students about the importance of accessibility (ii) the labs are effective in informing students about foundational accessibility topics (iii) empathy-creating material is demonstrated to be a beneficial component in computing accessibility education, supporting students in placing a higher value on the importance of creating accessible software. created labs and project materials are publicly available on the project website: http://all.rit.edu", "rq": ["rq 1:. how effective are the labs in motivating students about the importance of accessibility?", "rq 2:. how effective are the labs in informing students about foundational accessibility principles?", "rq 3:. how impactful are 'empathy-creating' materials in accessibility education?"], "relatedWork": ": existing projects have created accessibility related educational activities and focused on different methods of accessibility education . however, to our knowledge none: (i) have been thoroughly evaluated to determine their educational effectiveness (ii) offer a complete experiential learning experience, proving all instructional material (iii) are hosted and do not require the installation of any software (iv) contain empathy building material. teaching accessibility in computing courses has been a significant challenge in higher education . while some institutions have developed entire courses or degrees devoted towards the topic of accessibility, our work focuses on creating easily adoptable material that can readily integrate into existing curriculum. kane et al. described an initial study where a web programming course used pedagogical techniques drawn from architecture and industrial design support students in empathizing with users with disabilities. initial observations indicate that this approach is effective in encouraging accessible design practices. this work differs from ours in that it focused on encouraging students from a design perspective, and did not provide a complete set of hands-on activities such as those in our work. additionally, the evaluations were conducted on a much smaller scale (17 vs. 276 students). there are also accessibility teaching materials available online. for example, the 'teach access tutorial' provides developers and designers with a set of lessons and exercises that teach basic accessible web development practices . additional teaching resources are compiled by accesscomputing , which is an alliance that supports students with disabilities learn computing. accesscomputing focuses on making computing courses accessible to students with disabilities, and also on supporting instructors teaching about accessibility. for example, accesscomputing shares curriculum resources e.g., educational components that teach students and developers how to create accessible mobile applications . to our knowledge, no existing material provides a complete educational experience (experiential activity, lecture slides, etc.) that have been evaluated to demonstrate their educational effectiveness as we have done with our accessibility learning labs. lewthwaite et al. identified several of the challenges for teaching and learning accessibility in computing education. this work contends that accessibility education in computing presents a set of unique and challenging characteristics. our work differs in that we do not focus on identifying specific challenges in computing accessibility education, but focus in presenting and evaluating a set of unique experiential educational materials. educators have integrated accessibility into existing courses such as web design , hci , and software engineering courses using various pedagogical methods such as lectures , programming activities , and projects . educators found that when students interact with individuals with disabilities, e.g., project stakeholders, they better understand and apply accessibility principles in their work . similarly, students who watched videos for individuals with disabilities and older adults , or were required to use assistive technology e.g., screen readers were found to be more aware of the needs of the diverse base of users . industry has partnered with academia and advocates for people with disabilities in an initiative known as teach access . a goal of teach access is to improve accessibility education in higher education . despite these efforts and previously published work, including accessibility in computing courses is still an individual effort that is driven by faculty who have experience in accessibility or a related field e.g., hci , constituting only approximately 2.5% of instructors . recent interviews and surveys indicate that computing instructors have the desire to integrate accessibilityrelated topics in their courses, however they frequently lack access to teaching materials to use in their courses . we address this problem by creating instructional resources that are easy to integrate into existing courses, with defined learning objectives. our labs adhere to experiential learning principles, which have been shown to be beneficial to computing education . experiential learning provides a complete learning experience for the student, one where they both understand the concept behind an idea and interactively learn about it . within the context of experiential learning, different activities have been employed by instructors such as exercises , projects , simulations , and role-playing . experiential learning, compared to traditional teaching approaches such as lectures, has been demonstrated to be more engaging for students , and supports student retention of information . examples of experiential learning in computing education include teaching software engineering using interactive tutorials and software estimation using legos . there have been a large number of previous works that have examined best practices for motivating students in computing education. these focus on a wide-range of topics such as general computing and cybersecurity to how to best motivate students in an online instructional format . our work differs in that we specifically focus on computing accessibility education, while additionally seeking to determine the specific impact of empathy-creating material in computing accessibility education for both motivating and informing students.", "conclusion": "<title>conclusion</title> this work demonstrates the positive impact of experiential learning in computing accessibility education, specially through the use of our publicly available accessibility learning labs (all). our primary findings demonstrate: (i) the potential of the proposed experiential learning format and that the labs are effective in motivating students about the importance of accessibility (ii) the proposed material is effective in informing students about foundational accessibility topics (iii) empathy-creating material is demonstrated to be a beneficial component in accessibility education, supporting students in placing a higher value on the importance of creating accessible software. created labs and project materials are publicly available on the project website: http://all.rit.edu"}
{"id": 2136, "date": "2020-10-10", "title": "Designing for Recommending Intermediate States in A Scientific Workflow Management System", "url": "https://arxiv.org/abs/2010.04880v1[cs.IR]", "keywords": ["plant phenotyping", "association rules", "workflow", "intermediate states", "pipeline design"], "abstract": "o process a large amount of data sequentially and systematically, proper management of workflow components (i.e., modules, data, configurations, associations among ports and links) in a scientific workflow management system (swfms) is inevitable. managing data with provenance in a swfms to support reusability of workflows, modules, and data is not a simple task. handling such components is even more burdensome for frequently assembled and executed complex workflows for investigating large datasets with different technologies (i.e., various learning algorithms or models). however, a great many studies propose various techniques and technologies for managing and recommending services in a swfms, but only a very few studies consider the management of data in a swfms for efficient storing and facilitating workflow executions. furthermore, there is no study to inquire about the effectiveness and efficiency of such data management in a swfms from a user perspective. in this paper, we present and evaluate a gui version of such a novel approach of intermediate data management with two use cases (plant phenotyping and bioinformatics). the technique we call gui-risp ts (recommending intermediate states from pipelines considering tool-states) can facilitate executions of workflows with processed data (i.e., intermediate outcomes of modules in a workflow) and can thus reduce the computational time of some modules in a swfms. we integrated gui-risp ts with an existing workflow management system called sciworcs. in sciworcs, we present an interface that users use for selecting the recommendation of intermediate states (i.e., modules' outcomes). we investigated gui-risp ts 's effectiveness from users' perspectives along with measuring its overhead in terms of storage and efficiency in workflow execution. ccs concepts: \u2022 software and its engineering \u2192 software design engineering.", "rq": ["rq 1: how much performance overhead gui-risp ts adds in the system?", "rq 2: how can we incorporate tools' states in recommending intermediate states using association rules?", "rq 3: can we compose workflows while specifying intermediate states?"], "relatedWork": ": most of the swfmss are implemented as a process-aware based information system where data management is mostly neglected in terms of reuse for facilitating workflow execution. in this paper, our study is mainly focused on user evaluation of a data recommendation and management technique in a swfms. existing studies on recommendation, management and new technique evaluation for both data and processes in swfmss are presented below in two sections to compare with our proposed technique.", "conclusion": "<title>conclusion</title> to implement an efficient system for processing a large amount of data with numerous tools, proper data management in a system of workflow management is crucial. here, we propose a technique of intermediate data recommendation for both storing and retrieving data while building workflows in a swfms. in addition, this study is intended to investigate case studies of a gui version of the technique for comprehending users' behaviors and expectations in real-world workflow building. in our two case studies, from the provided raw data and generated intermediate data, in total intermediate data and raw data showed a split of 73% and 27% usage while building workflows by all participants. this usage trend and preference on intermediate data imply that the technique can fulfill users' expectations in most cases of efficient workflow execution. additionally, we found that the technique is more useful for the long-running and complex workflows, so we believe our technique (i.e., gui-risp ts ) has the potential to contribute to composing workflows with big data and heterogeneous tools. moreover, using the nasa-tlx study, we found that demand in each subscale of nasa-tlx does not produce any negative impact while assembling and executing workflows in the swfms with the technique. therefore, we believe the technique can be used in any swfms without any additional burden for introducing reusability and building workflow efficiently."}
{"id": 2147, "date": "2020-10-13", "title": "How Crisp is the Crease? A Subjective Study on Web Browsing Perception of Above-The-Fold", "url": "", "keywords": ["Visual Progress", "Perceived Progress", "Web QoE", "Network Impairments"], "abstract": "quality of experience (qoe) for various types of websites has gained significant attention in recent years. in order to design and evaluate websites, a metric that can estimate a user's experienced quality robustly for diverse content is necessary. speedindex (si) has been widely adopted to estimate perceived web page loading progress. it measures the speed of rendering pixels for the webpage that is visible in the browser window. this is termed above-the-fold (atf). the influence of animated content on the perception of atf has been less comprehensively explored. in this paper, we present an experimental design and methodology to measure atf perception for websites with and without animated elements for various page content categories. we found that pages with animated elements caused people to have more varied perceptions of atf under different network conditions. animated content also impacts the page load estimation accuracy of si for websites. we discuss how the difference in the perception of atf will impact the qoe management of web applications. we explain the necessity of revisiting the visual assessment of atf to include the animated contents and improve the robustness of metrics like si.", "rq": ["rq 1: can we annotate perceived atf based on vc time and progress to establish a range in subjective atf precision?", "rq 2: how does network bandwidth impact the visual perception of atf?"], "relatedWork": ". background and related work: performance of web applications are measured using quality metrics divided into two distinct categories: 1) time instant metrics: computed based on measuring the time instant that an event occurred during web page loading process. for example, time to first byte, time to dom load, time to first paint, largest content-full paint, atf time, time to last paint, page load time (plt) . 2) time integral metrics: used to quantify how fast a web page loads by integrating all events of a given type, tracked during the progress of a web page (using mathematical integration). for instance, speedindex , objectindex and byteindex . one criticism across much of the literature on the use of time instant metrics is that while they measure the exact time at which an event occurred, the user experience is more relevant to the flow experience than an occurrence of a particular event during the web page loading process. the shortcoming of time instant metrics motivated researchers to explore the effectiveness of time integral and visual metrics. interestingly, atf time is a time instant metric that has been widely used in as an input to time integral metrics such as speedindex (si) , perceptual speedindex , objectindex and byteindex . a. visual quality metrics si was introduced by google in 2012 . si is a speed score (expressed in milliseconds) that estimates how fast the atf content of a web page is visually painted (see fig. 1) . a lower si score points to a better perceived performance. si uses the following equation to estimate the loading speed: x = tend 0 (1 \u2212 x(t))dt (1 ) where x is the estimated speed, t end is the time the last event occurs, and x(t) \u2208 is the time evolution of the visual completion (vc) to reach t end (as shown in fig. 1, it calculates area above the curve). for example, plt is generally considered as the t end time while x(t) is the vc progress ratio of the web page over time. the vc progress ratio of si is calculated based on a comparison of mean pixel histogram difference (mphd) between the current state of the web page at time t and the state of the page at the plt time. si uses a series of snapshots (at a rate of 10 frames per second) from the time that the url is requested until plt. the frames are analysed in the same order to determine the vc progress ratio over time. the time that vc progress reaches to 100% is referred to as atf time . vc time and progress are related factors influencing the result of si. if the time increases and the vc progress has not reached to 100% (i.e., atf has not completed the page paint), the area above the curve also increases. saverimoutou et al. have proposed tfvr (time for full visual rendering), a browser-based method to determine atf time . tfvr calculates the atf time based on the loading time of the visible portion at first load of a web page. tfvr computes atf by extracting loading events and rendering timing from the browser http archive (har) file. da hora et al. argue that it is computationally expensive to measure atf time using mphd analysis . they proposed a metric called aproximated above-the-fold (aatf) time. similar to tfvr, aatf estimates atf time from the browser's heuristics without requiring image processing. asrese et al. used a thresholding technique to determine atf time over cellular networks . they argue that using a mphd analysis, a three seconds threshold (no visual change in three seconds) is sufficient to determine atf time for a wider range of websites with different content features.", "conclusion": "<title>vi. conclusion and future work</title> in this paper, we explored the influence of network bandwidth on the perception of atf for websites with and without animated content. in our experiment we used popular commercial websites homepages, representative of different content categories. our results show that the perception of atf does not significantly change for websites without animations. however, for websites with animations the perception of atf changes as the load time increases (as a result of decreasing the network bandwidth). content is a key influential factor in qoe studies. the amount of animation and multimedia content used in websites is increasing. this growth increases the challenges involved in accurate atf estimation. despite the fact that the heuristic methods work, we postulate that what the user perceives on the screen may deviate from what the heuristics tell us. i.e., the heuristics methods does not consider the visual content of the web elements. to this end, we plan to investigate how the accuracy of atf estimation can be improved for the websites with multimedia and animated"}
{"id": 2172, "date": "2020-10-13", "title": "Does Fair Ranking Improve Minority Outcomes? Understanding the Interplay of Human and Algorithmic Biases in Online Hiring", "url": "https://arxiv.org/abs/2005.14713.namecensus.com.2000", "keywords": [], "abstract": "anking algorithms are being widely employed in various online hiring platforms including linkedin, taskrabbit, and fiverr. prior research has demonstrated that ranking algorithms employed by these platforms are prone to a variety of undesirable biases, leading to the proposal of fair ranking algorithms (e.g., det-greedy) which increase exposure of underrepresented candidates. however, there is little to no work that explores whether fair ranking algorithms actually improve real world outcomes (e.g., hiring decisions) for underrepresented groups. furthermore, there is no clear understanding as to how other factors (e.g., job context, inherent biases of the employers) may impact the efficacy of fair ranking in practice. in this work, we analyze various sources of gender biases in online hiring platforms, including the job context and inherent biases of employers and establish how these factors interact with ranking algorithms to affect hiring decisions. to the best of our knowledge, this work makes the first attempt at studying the interplay between the aforementioned factors in the context of online hiring. we carry out a largescale user study simulating online hiring scenarios with data from taskrabbit, a popular online freelancing site. our results demonstrate that while fair ranking algorithms generally improve the selection rates of underrepresented minorities, their effectiveness relies heavily on the job contexts and candidate profiles.", "rq": ["rq 2: how effective are different ranking algorithms at mitigating gender bias?"], "relatedWork": "elated work: our work spans multiple topics under the broad umbrella of fairness and bias detection. more specifically, our work lies at the intersection of: 1) empirical evidence of gender bias in online portals, 2) fair ranking algorithms and their effectiveness, and 3) user-algorithm interaction. we discuss related work on each of these topics in detail below.", "conclusion": "<title>discussion & conclusion</title> in this work, we study how gender biases percolate in online hiring platforms and how they impact real world hiring decisions. more specifically, we analyze how various sources of gender biases in online hiring platforms such as the job context, candidate profiles, and inherent biases of employers interact with each other and with ranking algorithms to affect hiring decisions. our analysis revealed that fair ranking algorithms can be helpful in increasing the number of underrepresented candidates selected. however, their effectiveness is dampened in those job contexts where employers have a persistent gender preference (e.g., moving assistance jobs). our results also revealed that fair ranking is more effective when underrepresented candidate profiles (features) are similar to those in the overrepresented group. analyzing the textual responses of the study participants also revealed that several of the participants were cognizant of (un)fairness and possible underrepresentation. furthermore, some of the participants seem to be actively enforcing their preferred notions of fairness when making decisions. this work paves way for several interesting future research directions. firstly, this work underscores the importance of investigating how employers' mental models of fairness interact with ranking algorithms and impact hiring decisions in online and real world settings. secondly, while this work explicitly focuses on gender biases, it would also be interesting to systematically study the effect of racial biases in online hiring scenarios."}
{"id": 2261, "date": "2020-10-13", "title": "Evaluating the Need and Effect of an Audience in a Virtual Reality Presentation Training Tool", "url": "", "keywords": ["Virtual Reality", "Public Speaking", "3D Scanned Avatars"], "abstract": "public speaking is an essential skill in everyone's professional or academic career. nevertheless, honing this skill is often tricky because training in front of a mirror does not give feedback or inspire the same anxiety as presenting in front of an audience. further, most people do not always have access to the place where the presentation will happen. in this research, we developed a virtual reality (vr) environment to assist in improving people's presentation skills. our system uses 3d scanned people to create more realistic scenarios. we conducted a study with twelve participants who had no prior experience with vr. we validated our virtual environment by analyzing whether it was preferred to no vr system and accepted regardless of the existence of a virtual audience. our results show that users overwhelmingly prefer to use the vr system as a tool to help them improve their public speaking skills than training in an empty environment. however, the preference for an audience is mixed.", "rq": ["rq 1: what are people's opinions about va made with the current technology?"], "relatedWork": "elated work: virtual reality exposure therapies (vret) are therapies that use vr to expose patients to their fears . even before modern vr head-mounted displays (hmds), vret has shown potential . vret, for instance, has been shown to work well for different kinds of anxieties , such public speaking . further, one of the most prominent uses of vr is for training . several studies have shown that vr is a disruptive and useful tool for the training of various skills ; for technical , physical , and sociological training . even low-end vr can yield positive results . however, more realism does not always present the best results .", "conclusion": "<title>conclusion</title> in this paper we explored whether there is a need (and the effect) of a virtual audience in a presentation training scenario using virtual reality (vr). we did this analysis through a series of subjective metrics which indicate that even though most people do appreciate the virtual audience generated with the current technology, and it makes them somewhat positively nervous. for some people, the current virtual audience is not necessary, they are just as satisfied with the system without it. further, we observed that a simple audience that follows the users by looking at them is enough for creating a stimulating training environment for presentations in a vr environment. this is a system that aims to invoke feelings of anxiety and promote effective training. this vr environment was able to make users nervous and rated 4 out of 5 as an effective training tool. we observed that the development of a training tool for public speaking training is the most adequate when it can have the audience and users would preferred to have the option to it on and off, depending on their preferences. overall, the tool we developed seems to be able to help students."}
{"id": 2323, "date": "2020-10-13", "title": "Construction and Adaptability Analysis of User's Feature Models Based on Check-in Data in LBSN", "url": "", "keywords": ["user feature model", "adaptability analysis", "muti-channel CNN", "LBSN"], "abstract": "ith the widespread use of mobile phones, users can share their location anytime, anywhere, as a form of check-in data. the user context involved in these data and analysts' view towards these data are diverse. these data reflect user features, furthermore, the features rules for different users vary. therefore, how to analyze and quantify the impact of user context on different analyst views, how to discover a user's feature from their related data and how to validate whether a feature model is suited to a user is of great significance for providing users with contextualized services in complex mobile applications. in this study, firstly, the influence of user context to analysts' view is quantitative analyzed. secondly, multiple feature models from different views for each user are constructed. thirdly, whether a feature model is applicable to a user is validated. fourthly, a unified model, muti-channel convolutional neural network (cnn) is used to characterize this applicability. and finally, three data sets from multiple sources are used to verify the validity of the method, the results of which show the effectiveness of the method.", "rq": ["rq 1: is it effective to assume that the user is more suitable for a specific feature model if there is little difference in ucvf ij ?"], "relatedWork": "elated works: the extraction of user features is a hot research topic in lbsns, and many methods have been proposed to extract user features. these methods can be divided into two categories based on the extraction patterns: explicit and implicit extraction methods. explicit extraction methods extract user features directly using interviews and questionnaires , which is intuitive and easy to implement; however, users may not be able to articulate their features clearly, particularly in a complex context manner. furthermore, the method is unsuitable for large-scale applications; for example, it is impossible for a user to express their feature for thousands of different venues. therefore, an increasing number of researchers have focused on implicit extraction methods, which use various automated methods such as natural language analysis and data mining to extract user features from user comments and user check-in data. depending on influencing factors, these methods can be divided into four categories: content-based feature extraction, geographical-based feature extraction, temporalbased feature extraction, and social-based feature extraction methods . the content-based feature extraction method focuses on the analysis of content such as the user's age, job position, category of the venue, user comments on the venue, or venue photos . some methods have been proposed to locate the homes of the users, as a basis for calculating the distance to the venues from their homes . the geographicalbased feature extraction method is devoted to discovering the relationships between a user's check-in data and the distance from the user's home. some researchers have conducted experiments to build various formulas, such as a power-low distribution formula or a naive bayesian formula, to predict the probability of a venue being visited by a user at a certain distance , whereas other researchers are devoted to predicting the user's next location using historical check-in data . most users access different locations at different times, e.g., they tend to work in the morning and drink coffee or take a walk at night. therefore, the temporal-based feature extraction method focuses on the time information related to the user check-in data, using various analytical methods, such as data mining or machine learning, to reveal which venues the user likes to visit within a certain time . the social-based feature extraction method holds the idea that users share similar check-in patterns with their friends; correspondingly, users tend to make friends with those who share their features. these methods therefore use various strategies such as crawling through friend lists on user social accounts or clustering users with similar features to find other friends of a user, and apply the feature of their friends to infer their features . some studies combine more than one influencing factor to describe user features , which may be an interesting future research direction. although many methods have been proposed to describe users' features, to the best of our knowledge, few studies have focused on whether a user is suited to a feature model. in this study, we build a multiple feature model for each user and propose an algorithm to validate whether the user is suited to a feature model.", "conclusion": "<title>conclusions</title> in this study, multiple user feature models were built based on user check-in data in lbsn. based on the feature models, an applicability analysis algorithm was proposed to find a suitable user set for a specific feature model. a unified model was used to describe the user's applicability to different feature models. finally, experiments conducted on three data sets indicate that our method outperforms many baseline approaches. in the future, we plan to consider the user's social attributes to construct a user feature model. in addition, the method should be validated using more data sets from different sources."}
{"id": 2338, "date": "2020-10-13", "title": "Interface Features and Users' Well-Being: Measuring the Sensitivity of Users' Well-Being to Resource Constraints and Feature Types", "url": "", "keywords": ["Feature economics", "social information", "user preferences", "user interface"], "abstract": "sers increasingly face multiple interface features on one hand, and constraints on available resources (e.g., time, attention) on the other. understanding the sensitivity of users' well-being to feature type and resource constraints, is critical for informed design. building on microeconomic theory, and focusing on social information features, users' interface choices were conceptualized as an exchange of resources (e.g., time), in return for access to goods (social information features). we studied how sensitive users' well-being is to features' type, and to their cost level and type. we found that (1) increased cost of feature use leads to decreased well-being, (2) users' well-being is a function of features' cost type, and (3) users' well-being is sensitive to differences in feature type. the approach used here to quantify user well-being derived from interface features offers a basis for asynchronous feature comparison.", "rq": ["rq 1: how sensitive users' surplus is to a feature's cost?", "rq 2: how sensitive users' surplus is to a feature's cost type?", "rq 3: how sensitive users' surplus is to differences in feature type?"], "relatedWork": "elated work: applying economic theory to the study of users' choices in the context of interface design alternatives, toomim et al used the concepts of utility and revealed preference -the idea that agents' preferences can be revealed and compared by observing their choices between multiple goods. viewing utility as the extent to which a user prefers a particular choice over others, and considering all factors of functions and usability that affect users' preference and use, toomim et al suggested that utility(a) > utility(b) when a user chooses to use interface a instead of interface b. building on this notion, they developed a framework for eliciting a crowdsourcing labor supply curve given different interface variations. using an online crowdsourcing tasks, they investigated the relationships between task price, ui aesthetics and ease of use on worker supply. in a similar vein, other researchers discussed, developed and tested methods and tools to determine crowdsourcing pricing, and in particular, efficient and fair pricing of crowdsourcing tasks. other studies used economic theory concepts to study the relationship between design, behavior and utility, by focusing on the availability of different features to users, for example, by examining users' visual search strategies used given online images' ecology constraints . prior research, however, tended to focus on the supply side of online work in the context of different user interfaces, with little attention to the users' demand side -the choices users make about interface features' use as they go about performing their tasks. building on the notion that user interface preferences can be elicited experimentally, prior research examined the feasibility of eliciting demand for a sort feature , a commonly used ui feature. while this prior work constructed the feature's demand curve relative to its cost, the findings were limited to one type of cost (monetary) and one type of feature (sort), and are therefore silent on how variation in cost and feature type affect demand. various types of social information features were studied in prior research: some involve direct interaction or other financial and informational exchange between users, some include the presentation of \"feeds\" of information about other users, and others include the ability to broadcast information to large audiences of unknown others. specifically, hci research studied many settings in which the social aspect of the study was the effect of information about the choices or behaviors of other users on users' own choices or perceptions, with examples including the effects of information about others on investment decisions , trust and expertise perceptions , impression of peer workers , participation in distributed crowd work , aggregated recommendations in recommender's systems and users' agreement with their output and others. in the context of user behavior and personal finance, prior work examined how people manage and think about their money , how they make decisions about saving , and how financial information can be packaged in novel ways to assist with comparing potential investments . in recent years, personal finance is becoming increasingly social, with the emergence of peer-to-peer lending and payments platforms such (e.g. prosper) which combine enable monetary exchange informed by social information. understanding the value people place on social information is essential to the understanding (and design) of social systems that bring people to exchange not only information or information good (as they do in facebook or twitter), but also money (which social media platforms also attempt to do). prior studies, however did not consider a comparison of users' well-being associated with feature use, the tradeoff that features' choice represents, and the patterns of user surplus derived from social information features.", "conclusion": "<title>general discussion and conclusion</title> can we characterize quantitatively users' well-being associated with features, and the sensitivity to the constraints placed on users' resource? a method to address such questions can be highly valuable to researchers and practitioners: many user tasks take place in resources constrained contexts, and therefore designers have to make decisions about the types of features and information to be included in uis, and the level of detail they represent. such decisions can be better informed when based on clear understanding of users' preferences and constraint sensitivities. to demonstrate the feasibility of such characterization, in the experiments presented here we elicited user surplus, focusing on the use of social information interface features in situations of choice overload . it should be noted, however, that users' surplus associated with an interface feature is highly dependent on the task the user is engaged in. for example, a user who is interested in a quick answer to a time-sensitive question, would probably value speedy access to information in an aesthetically displeasing website, compared to a user who is interested in learning about a topic with no specific question in mind and less pressing time constraints. understanding and quantifying such tradeoffs can help in creating an environment that caters to users' needs. the focus on the role of interface features on users' behavior in a choice overload situation required a use case in which such choice overload is natural. personal finance offers a useful setting, since, in their interaction their finances, users often face more information than they can comprehend effectively, and need to reduce the number of alternatives they can consider. by conceptualizing interface features as economic goods, and by varying the constraint types and levels users may \"pay\" with, we could experimentally elicit users' surplus function. this function, and in particular, a comparison of the surplus across interface features, is highly useful for designers weighing design choices tradeoffs . to elicit the surplus for features realistically, participants were incentivized by making their compensation performance-based. prior work was extended by using two different cost types -money (in experiment 1) and time (in experiment 2). the surplus elicitation experimental design was then used to demonstrate (in experiment 3) how to compare users' surplus to two different information types. a similar procedure, in which feature and cost types vary in an otherwise-similar environment and then compared using a regression analysis in which both are independent variables, can be applied when comparing any number and types of information features. from a design practice perspective, the work presented here offers a way to study the return on investment in ui design . moreover, by examining two cost types and feature types, the approach used in the experiments makes such investments more evidence-based, informed, and explainable. being able to quantify user surplus as a function of feature costs denominated in time constraints can help designers make informed decisions as they consider the amount of time users are expected to spend on a given web page or app, and given the users' goals in visiting it. being able to quantitatively compare surplus across feature types is another way to inform designers' choices: using the surplus elicitation procedure applied in the experiments enables designers to compare the extent to which users value features in comparison to other present or future features. as such, it enables designers to make asynchronous comparisons, in a sequential and iterative process, and reduces the need for simultaneous a/b tests of a finite set of alternatives as means of feature evaluation. while there are many other features and cost types one can compare, the approach presented here offers a guideline on how to develop such comparisons. beyond the specifics of the results presented here, generalizing the findings to other types of settings and features would enable us to gain deeper insights into users' preferences and the tradeoffs they make, explicitly or implicitly, as they use interface features. future work could address the limitations of the work presented in this paper. first, the choice of using the personal finance context should be considered with the understanding of its limitations: being asked to perform a task within a personal finance scenario may prime users to think about the value of their interactions with user interface features primarily in monetary terms. moreover, in a crowd work context, users are likely to consider alternative earnings potentially available by working on other tasks, and therefore prioritize their time constraints. these characteristics of the task used in this work may therefore implicitly direct users' attention to costs denominated in money or time. for a more generalizable study of surplus patterns across cost types, alternative, constraint types can be examined in future research. costs can be operationalized in different ways, including variations of factors that have been studied in prior research -e.g. aesthetics and user annoyance . second, while only two feature types, in one user setting, were studied in this paper, future work can explore other features and other user settings and use cases. third, the experimental procedure presented here did not include a training phase, which could have helped users calibrate their time value estimates. it should be noted, however, that the effect of the training phase absence is likely to exist for all users, and therefore the patters of surplus found throughout the experiments would persist even with the presence of a training session. to check this assumption, we ran additional analyses of the experiments' data, this time eliminating the first round's results (that is, running the analyses only for rounds 2-10). we found that the use patterns (as a function of feature cost) were not different from the original experiments, therefore alleviating concerns about the lack of an experiment training phase. fourth, the studies presented here did not account for differences between users in terms of their individual income constraints and risk aversion -both of which may impact users' choices. with the growing constraints placed on users' available resources, including time, attention and screen real estate on one hand, and calls for evidence-based design on the other, the hci community can benefit from understanding, developing and using feature economics. more informed use of methods that have been developed to study allocation of scarce resources and people's choices , can help researchers and practitioners make design decisions and quantify the implications of these decisions."}
{"id": 2359, "date": "2020-10-19", "title": "Improving Prediction of Real-Time Loneliness and Companionship Type Using Geosocial Features of Personal Smartphone Data", "url": "https://arxiv.org/abs/2010.09807v1[cs.HC]", "keywords": [], "abstract": "oneliness is a widely affecting mental health symptom and can be mediated by and co-vary with patterns of social exposure. using momentary survey and smartphone sensing data collected from 129 androidusing college student participants over three weeks, we (1) investigate and uncover the relations between momentary loneliness experience and companionship type and (2) propose and validate novel geosocial features of smartphone-based bluetooth and gps data for predicting loneliness and companionship type in real time. we base our features on intuitions characterizing the quantity and spatiotemporal predictability of an individual's bluetooth encounters and gps location clusters to capture personal significance of social exposure scenarios conditional on their temporal distribution and geographic patterns. we examine our features' statistical correlation with momentary loneliness through regression analyses and evaluate their predictive power using a sliding window prediction procedure. our features achieved significant performance improvement", "rq": ["rq 3: how much can our geosocial features improve predictive power for momentary loneliness?", "rq 4: how much can our geosocial features improve predictive power for momentary companionship type?"], "relatedWork": "elated work: a subset of the broader mental health sensing literature has focused on predicting loneliness using human-centric sensing data . phone call and sms patterns proved important in distinguishing lonely from non-lonely individuals ; . doryab et al. used comprehensive daily mobile sensing features from both smartphone and fitbit to predict pre-/post-semester loneliness scores. other studies used indoor, smart home solutions to predict loneliness ; in senior citizens, who more likely than other demographic groups to stay at home. a major limitation in the existing literature on loneliness sensing is the emphasis it places on trait loneliness, such that the prediction task is aimed at diagnosing lonely individuals, thus using individual participants as the unit of analysis. however, state loneliness, on which we focus in this paper, has largely been overlooked. we target state loneliness by building models to detect lonely moments or episodes in daily life. a separate group of work has focused on using mobile sensing data to infer social context, for which bluetooth data from smartphones and wearable devices have proved especially useful . do et al. proposed a generative probabilistic model to extract latent human interaction types based on bluetooth encounters. yan et al. focused on classifying the context (e.g., in a meeting or at lunch) of bluetooth encounters and clustered users based on their encounter patterns. chen et al. used bluetooth features to predict five representative social-behavioral contexts, namely meeting in the hall, working indoors, taking the subway, shopping in the mall, and watching a movie in the cinema. limitations of these studies are that the definition of social context labels may be considered arbitrary and idiosyncratic, and applicable only to individuals with certain types of jobs: for example, \"in a meeting\" may only be applicable to office workers. we also find that the social context labels are confounded by locations or activities and fail to reflect the actual type of companionship in the moment; for example, for the context label \"watching a movie in the cinema\", does it matter if the subject is by herself or with friends or family? arguably watching a movie alone and together with familiar people should constitute different social contexts, but this difference is not reflected . to remedy these issues, we choose to focus on companionship type, a key component of social context that reflects the social significance of the persons one is with in a moment, and answer questions about its inference and effects on loneliness.", "conclusion": "<title>conclusion</title> in this paper we studied momentary loneliness and companionship type with self-report and smartphone sensing data collected from 129 android-carrying student participants over three weeks. we examined the relations between the two social-oriented outcomes and proposed novel geosocial features extracted from smartphone bluetooth and gps data that exhibited value in improving prediction of momentary loneliness and companionship type in correlation analysis and predictive modeling. we found that the companionship type is significantly related to loneliness experienced in a moment. of all the companionship type self-reports, moments being with a significant other were in average the least lonely ones and those being alone were the loneliest. moments spent with close-relationship companions are expected to be less lonely than those spent with non-close-relationship companions, in which participants experienced even lower loneliness than moments alone; however, being alone and feeling lonely have only a very limited correlation. we resorted to proximity-triggered bluetooth data as evidence for social exposure in participants' daily lives and developed features that capture the familiarity and the temporal and spatial predictability of a participant's encountered bluetooth devices observed over a short period of time, which we hypothesized to be correlated with and predictive of the participant's concurrent loneliness and companionship type. we supported this hypothesis in our regression analyses, where features such as the number and entropy of unique devices detected and the mean or maximum value of social spatial/temporal regularity showed significance consistently. participants tend to have experienced greater loneliness in moments where a larger number of unique devices are detected and moments that belong in sessions of a highly scheduled nature. we further validated our features in predictive models targeting loneliness and companionship type, where they provided a performance boost compared to baseline. for loneliness prediction, we observed an average auc of 0.74 from our full model (0.2 greater than baseline) over the three-week period and the benefit of incorporating daily updated training data. these patterns are less pronounced in predicting solitude and close-relationship companionship, suggesting our features' better suitability with mental health outcomes than social context outcomes. data used in this study come entirely from college student participants in our mobile sensing study, so the generalizability of our methods and findings to other demographic and occupational groups awaits future research to validate. moreover, due to limited temporal span of our data, we utilized the entire study period to compute features and evaluate models whereas for a new sensing study a warm-up period of data collection is required before testing. we call for future work to incorporate and evaluate the geosocial features proposed in this study in mental health sensing and context-aware computing applications to provide additional improvements in performance."}
{"id": 2360, "date": "2020-10-20", "title": "Social App Accessibility for Deaf Signers", "url": "https://arxiv.org/abs/2008.05691v2[cs.HC]", "keywords": ["accessibility", "sign language", "ASL", "Deaf culture", "social media"], "abstract": "social media platforms support the sharing of written text, video, and audio. all of these formats may be inaccessible to people who are deaf or hard of hearing (dhh), particularly those who primarily communicate via sign language, people who we call deaf signers. we study how deaf signers engage with social platforms, focusing on how they share content and the barriers they face. we employ a mixed-methods approach involving seven in-depth interviews and a survey of a larger population (n = 60). we find that deaf signers share the most in written english, despite their desire to share in sign language. we further identify key areas of difficulty in consuming content (e.g., lack of captions for spoken content in videos) and producing content (e.g., captioning signed videos, signing into a phone camera) on social media platforms. our results both provide novel insights into social media use by deaf signers and reinforce prior findings on dhh communication more generally, while revealing potential ways to make social media platforms more accessible to deaf signers. ccs concepts: \u2022 human-centered computing \u2192 social media; \u2022 social and professional topics \u2192 people with disabilities;", "rq": ["rq 1: how and with whom are deaf signers sharing content on social media?", "rq 2: what accessibility barriers do deaf signers face on social media platforms today?"], "relatedWork": "background and related work: we now discuss prior studies of dhh 3 users' experiences with social media platforms (mostly facebook). our work reassesses the social media usage patterns revealed in previous research on a wider range of platforms and provides more depth to understanding how users share (e.g., how, why, and with whom they share). a full review of studies of other disabled groups' social media use (e.g., visual , cognitive , and motor disabilities) is beyond our scope. additionally, we provide background information about sign language in general to provide a better understanding of deaf signers.", "conclusion": "<title>conclusion</title> we investigated how social media platforms can better accommodate deaf signers by asking 67 individuals about how they share and the barriers they face on popular platforms. we provide depth to current literature on dhh social media use by focusing specifically on deaf signers, their sharing behaviors on a variety of platforms, who they share with, and why they choose to share with the methods they do. while many deaf signers prefer to share in sign language, they resort to sharing in english on platforms due to barriers in sharing videos. we discuss in depth these novel barriers including difficulty in creating captions, difficulty filming sign, and language barriers. based on the insights found in this study, we present many feasible changes for platforms and areas for future research to better support deaf signers. we hope this work inspires similar in-depth explorations of the deaf community's unique usage of various interfaces."}
{"id": 2391, "date": "2020-11-12", "title": "Immediate or Reflective?: Effects of Real-time Feedback on Group Discussions over Videochat", "url": "https://arxiv.org/abs/2011.06529v1[cs.HC]", "keywords": [], "abstract": "having a group discussion with the members holding conflicting viewpoints is difficult. it is especially challenging for machine-mediated discussions in which the subtle social cues are hard to notice. we present a fully automated videochat framework that can automatically analyze audio-video data of the participants and provide real-time feedback on participation, interruption, volume, and facial emotion. in a heated discourse, these features are especially aligned with the undesired characteristics of dominating the conversation without taking turns, interrupting constantly, raising voice, and expressing negative emotion. we conduct a treatment-control user study with 40 participants having 20 sessions in total. we analyze the immediate and the reflective effects of real-time feedback on participants. our findings show that while real-time feedback can make the ongoing discussion significantly less spontaneous, its effects propagate to successive sessions bringing significantly more expressiveness to the team. our explorations with instant and propagated impacts of real-time feedback can be useful for developing design strategies for various collaborative environments.", "rq": ["rq 1: what is the instant effect of real-time feedback on groups having heated discussion over videochat?", "rq 2:a is \"yes\", then what is the effect of reflective feedback on groups in successive discussions?"], "relatedWork": ". related work a. behaviors in heated discussion: for the case of heated group discussions, various key behaviors contribute to escalating or resolving disrespectful or noncollaborative interactions. identifying these crucial behaviors is the first step towards addressing them. firstly, mutual respect for the group members is the key to a safe exchange of conflicting ideas , . mansbridge et al. suggest that participants involved in a difficult conversation should treat one another with mutual respect by actively listening and speaking in a way that helps comprehend the reasoning. mutual respect can get hampered by dominance and unperceptive behaviors . two key signs of projecting dominance in conversational setting are talking more and interrupting others , , . burgeon and hoobler observe that the amount of talking time plays a role in perceptions of dominance and credibility. dunbar et al. show that during conflict infusing conversations people interrupt more to take control and project dominance. thus, we identify talktime and interruption as two key features to consider for feedback in a heated discussion. negative emotion and affect also play important roles in difficult conversations. jung shows that affective imbalance during conflict interactions can negatively affect team performance. anderson and pearsson explain the concept and the factors of incivility spiral in workplace. they show that repairing negativity is crucial to prevent intense aggressive behaviors from escalating during interactions. this negativity can be expressed prominently through two ways: (a) voice, and (b) face , . we dive deeper into more prior work to address the feature of emotional negativity expressed through these two ways. research emphasizes vocal tone as a key factor in heated discussions. rothenberg explores the role of verbal hostility as an invariable accompaniments of anger. the research discusses that as a part of expressing anger, the involvements of muscle tension, vascular changes, and involuntary voice change are observed. negative facial emotion and high vocal tone thus contributes to elevated anger, hostility, and dominance towards other people present in the exchange . derby et al. mentions that people, out of anger or excitement, may shout or yell without realizing that they have raised their voices. the study suggests that a gentle feedback can be effective to mitigate the raised vocal volume. costa et al. externally manipulated voices to be calmer during conflicts, which resulted in less anxiety among participants. reflecting on these findings, we identify facial emotion and volume of the vocal tone as another two influential factors for heated conversations. overall, research has significantly emphasized features like balanced participation , emotional stability , , , gesture and language similarities , , etc. for coordinated teamwork. related research done on automated analysis of performance , and emotion , , have paved the way towards tracking group behavior. generally, maintaining a balance in these features brings better outcome in the form of performance or satisfaction for teams. for example, even though equal speaking time or participation is not always ideal for groups, it generally brings a better experience , . derby et al. discusses how emotional stability can be befinicial in a team setting, which can be achieved by being aware of positive, neutral, and negative emotions altogether. therefore, providing information about these three zones of emotion can help people having a broader insight to better help maintaining the stability. burgoon and newton observe that not actively participating in an interaction bars the feeling of being a part of the ongoing experience. on the other hand, active participants feel more immersed in the interaction and the overall experience , . these suggest that imbalanced participation can affect the group dynamics and overall experience. therefore, people need to carefully pay attention to both under and over participation to maintain a balance, as both can generate negative impact during conversation in a group , . therefore, in the light of prior work, we (1) identify four crucial features for heated discussion: talk-time, interruption, facial emotion, and vocal volume, and (2) recognize that an overall understanding (participation: over, balanced, under; facial emotion: negative, neutral, positive; voice: low, balanced, high) of the behaviors projected by each feature is needed to avoid the negative impact in a heated discussion.", "conclusion": "<title>vii. conclusion</title> in this paper, we present our video conferencing system incorporated with real-time feedback. we observe the instant and long-term reflective effect of the real-time feedback within a debate-like group discussion. we conduct a treatment-control user study with 40 participants in a total of 20 discussion sessions to compare the effects. our results show how realtime feedback reduces spontaneity of the discussion for the video conferencing platform, but influences the expressiveness in the following discussion without any feedback. the implications can be useful for research using real-time feedback and videoconferencing based group discussions. due to covid-19, all of our interactions are taking place online. it has further highlighting the importance of understanding the nonverbal nuances and conversational dynamics in videocalls. some of the fundamental aspects of building relationships like establishing rapport, showing empathy, sincerely listening to each other do not translate effectively. it is easy to misread cues resulting in unpleasant exchanges. there is an opportunity to design interventions to help individuals cope with new normal way of communicating online. this paper is an initial exploration towards that direction."}
{"id": 2414, "date": "2020-12-01", "title": "Audience and Streamer Participation at Scale on Twitch", "url": "https://arxiv.org/abs/2012.00215v1[cs.SI]", "keywords": ["Twitch", "Audience Participation Games", "Data Analysis"], "abstract": "arge-scale streaming platforms such as twitch are becoming increasingly popular, but detailed audience-streamer interaction dynamics remain unexplored at scale. in this paper, we perform a mixed methods study on a dataset with over 12 million audience chat messages and 45 hours of streamed video to understand audience participation and streamer performance on twitch. we uncover five types of streams based on size and audience participation styles: clique streams, small streams with close streamer-audience interactions; rising streamers, mid-range streams using custom technology and moderators to formalize their communities; chatterboxes, mid-range streams with established conversational dynamics; spotlight streamers, large streams that engage large numbers of viewers while still retaining a sense of community; and professionals, massive streams with the stadium-style audiences. we discuss challenges and opportunities emerging for streamers and audiences from each style and conclude by providing data-backed design implications that empower streamers, audiences, live streaming platforms, and game designers.", "rq": ["rq 1:. how does audience participation on twitch vary across different sized audiences?", "rq 2:. what type of techniques do streamers use to drive audience participation and how do these techniques vary?"], "relatedWork": ": livestreaming platforms provide an opportunity for audiences to attend and participate in live events . in the category of gaming, audience members join online to see and hear streamers as they play. an audio/video feed of the streamer's game-often superimposed with the streamer on webcam-is paired with a public text chat . the audience uses the chat to communicate with the streamer and each other. streamers follow along and converse audibly with the chat, as they play . together, livestreaming interfaces facilitate a shared community space and discourse .", "conclusion": "<title>conclusion</title> in this paper, we investigate twitch as a vehicle for understanding audience participation and streamer performance at different scales within online live streaming platforms. our research shows the characteristics presented by streamers and audiences on five different audience size scales: clique streams, rising streamers, the chatterboxes, spotlight streamers and celebrities and tournaments. we present tools and design implications for streamers, game designers and platforms designers to address various obstacles observed for these clusters that ultimately could improve the experience of streamers and audiences."}
{"id": 2417, "date": "2020-12-01", "title": "", "url": "https://arxiv.org/abs/2005.01575v8[cs.LG]", "keywords": ["Stacking", "stacked generalization", "ensemble learning", "visual analytics", "visualization"], "abstract": "fig. 1. constructing performant stacking ensembles from scratch with stackgenvis: (a) a panel for uploading data sets and choosing weights for performance metrics; (b) the history preservation panel with the composition and performance achieved by the user-built stored stacking ensembles; (c) the comparison of the metamodel's performance for both the active and stored stackings, based on four performance metrics (linked to view (a) with a dice glyph showing four); (d) the three exploration modes for the algorithms, data, and models; (e) the projection-based models' space visualization, which summarizes the results of all the selected performance metrics for all models; and (f) the predictions' space visual embedding, which arranges the data instances based on the collective outcome of the models in the current stored stack s6 (marked in bold typeface in (b)).", "rq": ["rq 1: how to build a stacking ensemble for a given problem with a focus on avoiding such trial and error methods, and/or increasing the overall efficiency?", "rq 2: how to monitor and control the complete process of training stacking ensembles, while preserving confidence and trust in their predictive results?", "rq 3: what performance/validation metrics fit better to a specific data set, and how can they be combined?"], "relatedWork": ": visualization systems have been developed for the exploration of diverse aspects of bagging, boosting, and further strategies such as \"bucket of models\". stacking, however, has so far not received comparable attention by the infovis/va communities: actually, we have not found any literature describing the construction and improvement of stacking ensemble learning with the use of va. in this section, we briefly discuss previous works on bagging, boosting, and buckets of models, and highlight their differences with stackgenvis in order to substantiate the novelty of our approach.", "conclusion": "<title>conclusion</title> in this paper, we introduced an interactive va system, called stack-genvis, for the alignment of data, algorithms, and models in stacking ensemble learning. the adaptation of an already-existing knowledge generation model leads us to stable design goals and analytical tasks that were realized by stackgenvis. with the careful selection of multiple coordinated views, we allow users to build an effective stacking ensemble from scratch. exploring the algorithms, the data, and the models from different perspectives and tracking the training process enables users to be sure how to proceed with the development of complex stacks of models that require a combination of not only the best performant but also the most diverse individual models. to retrieve preliminary results about the effectiveness of stackgenvis, we presented use cases with real-world data sets that demonstrated the improvements in performance and the process of achieving them. we also evaluated our approach with expert interviews by retrieving feedback about the workflow of our system, the interactive visualizations, and the limitations of our approach. those limitations were then identified as future work for further development of our system."}
{"id": 2424, "date": "2020-12-05", "title": "Using voice note-taking to promote learners' conceptual understanding", "url": "https://arxiv.org/abs/2012.02927v1[cs.HC]", "keywords": ["Distance education and online learning Teaching/learning strategies Human-computer interface"], "abstract": "hough recent technological advances have enabled note-taking through different modalities (e.g., keyboard, digital ink, voice), there is still a lack of understanding of the effect of the modality choice on learning. in this paper, we compared two note-taking input modalities-keyboard and voice-to study their effects on participants' learning. we conducted a study with 60 participants in which they were asked to take notes using voice or keyboard on two independent digital text passages while also making a judgment about their performance on an upcoming test. we built mixed-effects models to examine the effect of the note-taking modality on learners' text comprehension, the content of notes and their meta-comprehension judgement. our findings suggest that taking notes using voice leads to a higher conceptual understanding of the text when compared to typing the notes. we also found that using voice also triggers generative processes that result in learners taking more elaborate and comprehensive notes. the findings of the study imply that note-taking tools designed for digital learning environments could incorporate voice as an input modality to promote effective note-taking and conceptual understanding of the text.", "rq": ["rq 1: how does the note-taking modality affect learners\\' text comprehension?", "rq 2: how does the note-taking modality impact the contents of the notes made by learners?", "rq 3: can note-taking modality influence learners\\' meta-comprehension judgement?"], "relatedWork": "elated work: studies have shown that a majority of learners take notes during learning activities (peverly and wolf, 2019;morehead et al., 2019b). from a cognitive psychology perspective, note-taking relates to information management where learners need to comprehend and write down the information that is personally meaningful to them (piolat, olive and kellogg, 2005). while taking notes, learners must filter the incoming information, update their existing knowledge, and integrate the newly processed information (makany, kemp and dror, 2009). research on note-taking suggests that the quantity of notes taken can vary substantially between learners and that the quality is difficult to account for (peverly and wolf, 2019). some learners make a note of everything they hear in a lecture; others adopt a pick and choose a strategy where they take short and selective notes. the reasons for note-taking may also differ between learners, for example, some engage in note-taking as a \"process\" that can promote their recall and aid their concentration-known as the encoding effect-while others take notes because of the resulting \"product\", which can help them in revising the material and keeping track of what was covered-known as the external storage effect (vesta and gray, 1972). note-taking can also promote generative learning, as learners often relate the content they are reading to their prior knowledge (morehead et al., 2019b). the act of externalising their current knowledge can help learners realise meta-cognitive processes such as meta-comprehension (i.e. learners' judgement of their level of comprehension (dunlosky and lipko, 2007)), that can positively impact their decision to re-visit the material, and, in turn, can lead to improved learning (nguyen and mcdaniel, 2016a). prior research has investigated the effects of note-taking on text comprehension (moradi, ghahari and abbas nejad, 2020;\u00f6z\u00e7akmak, 2019;bahrami and nosratzadeh, 2017) and found that note-taking encourages learners to select, organise, and integrate ideas presented in the text. for instance, bahrami et al. investigated whether note-taking during reading improved learners' text comprehension. their findings suggest that learners who take notes while reading were better able to integrate ideas between separate texts and performed better in post-reading tests than learners who did not take notes (bahrami and nosratzadeh, 2017). researchers have suggested that note-taking is not only a learner behaviour (bauer and koedinger, 2007) but also a study strategy (karpicke, butler and roediger iii, 2009). therefore, a better understanding of learners' notetaking is vital for both theoretical and practical reasons. while prior studies have been beneficial in understanding the role of note-taking on learners' conceptual understanding, they have mostly been focused on longhand note-taking using pencil and paper. as digital technologies become more prevalent in the classroom, learners increasingly take notes using portable digital devices, such as their laptops. therefore, recent efforts have focused on investigating the effect of the medium (longhand vs. laptop) on learners' note-taking (mueller and oppenheimer, 2014;fiorella and mayer, 2017;luo et al., 2018). for instance, mueller et al. found that the medium of note-taking adopted by learners not only affects the content of notes generated but also their performance on a post-reading test (mueller and oppenheimer, 2014). their findings suggest that laptop note-takers recorded more words than longhand note-takers. however, longhand note-takers achieved higher performance on a post-reading test consisting of conceptual questions. overall, the findings of studies investigating the impact of note-taking medium suggest that laptop note-taking can prompt transcription oriented or verbatim note-taking, which may not always boost learning performance (fiorella and mayer, 2017;luo et al., 2018). a likely reason for the poorer performance associated with verbatim notes is that they allow learners to record or note the material without any in-depth processing (bauer and koedinger, 2007). with advances in multimedia sensing capabilities, researchers have been exploring other modalities beyond the keyboard for digital note-taking. for example, han et al. explored picture note-taking by presenting picremarkable, a picture based note-taking tool which allows semantically related pictures with keywords to be included while taking notes (han, yang and wang, 2014). the findings of this study suggest that picture-based note-taking could support second-language readers to gain a better understanding of the reading material. voice is another modality that has been gaining popularity. when compared to typing using the keyboard, voice can be faster to record and be more expressive (yu, nguyen, prakkamakul and salehi, 2019). moreover, voice notes can also be transcribed to textual notes that, at a later stage, can make the notes review process easier. with the current development of voice note-taking tools and extensions for cloud-based document viewers such as mote 4 and kaizena 5 , learners can easily record voice notes. for example, mote, can assist learners in taking voice notes on digital documents and in labelling the voice recordings. further, the recorded voice can automatically be transcribed to text and later, be shared with peers. although tools supporting voice notes are starting to enter the market, there is a lack of research investigating the impact of voice note-taking on learning. previous research suggests that the medium of note-taking not only can impact the content of the notes but may also affect learners' performance. in line with this, it logically follows that the note-taking modality adopted by learners can also influence their general note-taking behaviours, which, in turn, can potentially affect their learning performance. therefore, in this paper, we aim to compare the two input modalities for note-taking in digital learning: keyboard and voice. we analyse the effects of these note-taking modalities on learners' text comprehension and meta-comprehension. specifically, we aim to answer the following research questions: \u2022 rq1: how does the note-taking modality affect learners' text comprehension? \u2022 rq2: how does the note-taking modality impact the contents of the notes made by learners? \u2022 rq3: can note-taking modality influence learners' meta-comprehension judgement?", "conclusion": "<title>conclusion</title> although voice note-taking is becoming increasingly popular, there is a lack of evidence about how this modality may support learning goals. the present study bridges this gap by providing insights into the effects of voice notetaking on learners' text comprehension, their meta-comprehension judgements, and the contents of their notes. our findings suggest that a change of modality from keyboard to voice may enable learners to make more elaborations and discuss more idea units in their notes. this can assist learners in text comprehension, as reflected in their posttest scores. further, the findings indicate that if the learning goal is to gain basic knowledge of the study content, then both modalities (keyboard vs. voice) perform similarly, but if the goal is to enable learners to gain a conceptual understanding by making inferences, voice note-taking might be more effective than typing notes using keyboard. lastly, the findings suggest that both note-taking modalities have comparable effects on learners' meta-comprehension judgement of text comprehension. overall, our findings suggest that voice modality could be incorporated in digital learning environments for taking notes as it could trigger higher-order learning and enable learners to get a better conceptual understanding of digital texts."}
{"id": 2435, "date": "2020-12-21", "title": "Building Energy Consumption Models Based On Smartphone User's Usage Patterns", "url": "https://arxiv.org/abs/2012.10246v1[cs.HC]", "keywords": ["Android Service", "Deep Neural Networks", "Energy Consumption", "Machine Learning", "Neural Networks", "Recurrent Neural Networks", "User usage pattern"], "abstract": "ror of 158.57mw when the smartphone's average power is 1970.1mw. some studies show that the leading smartphone's workload is the user. based on this fact, we developed an automatic model building methodology that is capable of analyzing the user's usage data and build smart models that can estimate the smartphone's energy consumption based on the user's usage pattern. with the automatic model building methodology, we can adopt strategies to minimize the usage of components that drain the battery.", "rq": ["rq 1: is the user the primary workload for mobile systems?", "rq 2: what the components with the most influence in the smartphone's energy consumption?", "rq 3: how well does our model generalize to any device?", "rq 4: how to assess the accuracy of the model built?"], "relatedWork": "elated works: many researchers conduct studies aiming to model the smartphone's energy consumption using software engineering techniques. the strategy proposed by romansky et al . models the smartphone energy consumption using the system calls inside the application code as inputs to a long short term memory neural network. the authors used 6 android apps in their different versions to collect the system calls and provide them to the neural network to predict smartphone energy consumption. the authors have proven the effectiveness of their method, getting an error of only 4% between the measured energy consumption and their model prediction. another approach used by the authors of the research area of the smartphone's energy consumption model is to develop profiler apps that instrumentalize the studied android apps source code to exercise them and collect battery usage statistics data . using another approach, hindle et al . has proposed the green miner: dedicated testbed hardware that mining software repositories. the green-miner physically measures the energy consumption of mobile devices (android phones) and automates the testing of applications and the reporting of measurements back to developers and researchers. another strategy used to build a smartphone's energy consumption model was proposed by alawnah and sagahyroon , which offered an energy consumption model using the user's usage as inputs to a multilayer perceptron network. the authors obtained a root mean squared error in order of 0.21. during their work, they related the usage of high precision hardware to get the instantaneous power because their model is subject to fluctuations in its precision due to hardware failure. besides energy consumption modeling, some strategies are used for mobile phone energy consumption optimization using usage pattern models. sometimes these models have been developed to identify the smartphone user usage pattern to serve as a subsidy for advertising campaigns . those studies are usually conducted to discover the user-battery interaction. the term was first coined by benerjee et al. . they conducted a systematic user study on battery usage and recharged behavior on both laptop computers and mobile phones. those are the most important findings: 1. batteries are mostly recharged when the battery level is substantial; 2. a considerable portion of recharges are context-driven (in terms of location and time), and those driven by battery levels usually occur when the battery level is high; and 3. there is significant variation among users and systems. to reach those results, they designed, deployed, and evaluated a user-and statistics-driven energy management system, named llama, to exploit the battery power in a user-adaptive and user-friendly fashion to more optimally serve the user. the methodology is based on three strategies: 1. a passive logging tool that periodically records the battery level and charging status; 2. interviewing users to obtain qualitative data regarding users' battery usage, and 3. determining in situ users' motivation for recharging their system. according to tarkoma et al. , many studies on charging behavior have been conducted to date. all of them agree on a few salient points. first, recharging is either triggered by the current battery level or by the context, which is derived from the time and/or location and leads to two distinct user types. tarkoma et al. also discussed the extent to which battery awareness applications change user behavior citing the example of athukorala et al. , who surveyed 1,140 carat users by asking them how the app changed their behavior. the results showed that users who used the app for more than three months were much more likely to stop using applications identified as high consumers by carat. vallina-rodriguez et al. discussed the interdependence caused by the applications and users' behavior and their effect on battery life. the authors' results indicate that simple algorithmic and rule-based scheduling techniques are not the most appropriate for managing the resources because their usage can be affected by contextual factors. another strategy proposed by the researchers in this area uses machine learning and neural networks to identify the context and predict the user activity using classifiers , , . xie et al. use machine learning strategies to identify the context of an e-learning platform usage to adapt the content served to the learners. the developed tool uses sensors like accelerometer, light, and sound to determine the usage context. dai et al. uses machine learning algorithms to predicts the activity performed by a user. to aim this objective, the authors use the cross-user activity transfer technique that uses similar activities performed by other users to augment the machine learning algorithm capacity of predicts the activity performed by a user. bettini et al. built a system, caviar(context-aware actve and incremental activity recognition), which combines semi-supervised learning and semantic context-aware reasoning. the authors purpose the system to predicts the user activity using an incremental strategy, in the same way, that we approach the problem of constructing the smartphone's energy consumption in this research. prior work has created a smartphone's energy consumption model based on users' usage pattern similar to our goal. furthermore, some energy models have been generated using dedicated hardware . other prior works have been assumed that it is possible to interact with the android app source code to identify the system calls with a significant impact on the smartphone's energy consumption . however, our work does not assume that the user has access to the android app source code or that the hardware responsible for measuring the instantaneous power is confident. during this research, we have constructed an automatic model building methodology capable of automatically analyze the user's usage data and build an energy consumption model capable of estimates the smartphone's energy consumption model based on the user's usage pattern. the automatic methodology developed in this work can be used by autonomous energy optimization platforms.", "conclusion": "<title>conclusion and future works</title> the development of smartphone technologies imposes many challenges for researchers. a prominent one is the optimization of energy consumption since the battery is a limited and scarce resource that does not evolve at the same pace as the smartphone's technology. in this work, we developed a methodology to analyze the user behavior automatically and, based on it, build a smartphone energy consumption model that can be used by developers and autonomous optimizers. the main goal of this research is to establish a methodology to create an automatic mechanism to build energy consumption models for smartphones based on the user's usage that can be used by application developers and autonomous optimizers. as future work, we intend to create automatic optimizers that consider the usage context to perform the optimizations based on it. the introduction of intelligence and situational awareness into the recognition process of human-centric event patterns could give a better understanding of human behaviors ."}
{"id": 2437, "date": "2020-12-22", "title": "A Maturity Assessment Framework for Conversational AI Development Platforms", "url": "https://arxiv.org/abs/2012.11976v1[cs.HC]", "keywords": ["conversational AI", "software platforms", "assessment framework"], "abstract": "onversational artificial intelligence (ai) systems have recently sky-rocketed in popularity and are now used in many applications, from car assistants to customer support. the development of conversational ai systems is supported by a large variety of software platforms, all with similar goals, but different focus points and functionalities. a systematic foundation for classifying conversational ai platforms is currently lacking. we propose a framework for assessing the maturity level of conversational ai development platforms. our framework is based on a systematic literature review, in which we extracted common and distinguishing features of various open-source and commercial (or in-house) platforms. inspired by language reference frameworks, we identify different maturity levels that a conversational ai development platform may exhibit in understanding and responding to user inputs. our framework can guide organizations in selecting a conversational ai development platform according to their needs, as well as helping researchers and platform developers improving the maturity of their platforms.", "rq": ["rq 1: what platforms exist for developing conversational ai systems?", "rq 2: what are the features of these platforms?", "rq 3: what are the levels of conversational maturity supported by the identified platforms?"], "relatedWork": "background and related work: with the recent developments in many of the sub fields of conversational ai, including machine learning, dialog management and nlu, many different conversational ai systems have emerged . in industry, this technology has been incorporated into search engines, mobile devices, and personal computers. in search engines such as google and bing, conversational ai is used to create the feeling of having a conversation with the search engine, enhancing the experience. in mobile devices and personal computers, one use of conversational ai is to create virtual assistants. some of the biggest virtual assistants on the market today are apple's siri, google assistant, amazon alexa and microsoft cortana . these assistants also have the capability of acting as chatbots where they keep a turn-based dialog (a dialog where the user and the bot take turns in asking and responding to queries) with the user. there also exist conversational interfaces that only focus on this type-dialogbased conversation such as xiaoice and replika . these dialogs use what is known within conversational ai as intents and entities to understand the user's goal behind the query. in other words, an intent is what the user wants to achieve with the query, and an entity is the key information for answering the intent. recently a number of different platforms have been made available to simplify the creation and integration of conversational interfaces for developers. the most popular ones are: google's di-alogflow (formerly api.ai) 1 , ibm's cloud-based bot service watson conversation 2 , amazon lex 3 and the microsoft bot framework 4 . these platforms come equipped with several different technologies used for nlu, dialog management, response generation and other aspects . since conversational ai is a new field, systematic approaches to overview and categorize it are still in their infancy. patil et al. makes a general comparison of features and functionalities between some of the commercial platforms, giving an overview of what platform one might choose for developing a conversational ai system. there have also been more specific studies conducted which compare the nlu and conversational abilities of these types of platforms. canonico and de russis compare the nlu performance of these platforms have in terms of usability, pre-built intents (a number intents already existing in the nlu tool) context etc. mctear describe the two main conversation models \"oneshot queries\" and \"slot-filling dialogues\". he compares different platforms' ability to handle follow up questions in one-shot query scenarios and their mechanisms for slot-filling (a type of conversation where the bot asks specific questions to fill certain slots to fulfil a user intent). mctear also presents a number of problems that developers may face when creating conversational interfaces with these platforms. one of the main issues is that it might be difficult to know what functionalities a specific platform offers. there is also a difficulty in interpreting what functionalities might be common between platforms since there is no standard terminology. venkatesh et al. describe a number of metrics that can be used to evaluate the overall performance of a conversational agent based on the annual competition alexa prize made for furthering conversational ai. they propose metrics such as conversational user experience, engagement, and conversational depth to measure the conversational abilities of entire conversational ai systems or chatbots . shawar and atwell describe metrics to specifically evaluate chatbot systems, a type of conversational ai interface. they argue that metrics for evaluating the abilities of these systems should be done based on the application and its domain and not solely on a standard. one of the main issues with creating the metrics described above is the understanding of what a good conversation is. clark et al. discuss that people generally describe conversations with conversational interfaces in terms of their performance and perceive them more as a device to be controlled. indicating that people have a previous notion of how these systems will behave coming from a perception that infrastructure to support proper human-to-human dialogs do not exist. the maturity assessment framework presented in this paper takes inspiration from three language proficiency frameworks: common european framework of reference (cefr, ), american council on the teaching of foreign languages (actfl, ), and the interagency language roundtable (ilr, ). the goal of these frameworks is to assess the language competency of an individual for a particular language. all of these frameworks have a similar structure, distinguishing different, successive levels (e.g., in case of cefr, a sixitem scale a1-c2), language-relevant skills (e.g., for cefr, reading, listening, speaking, and writing), and a number of hints for assigning an individual to a level. while the contents of the framework differ, they all share this same basic structure, which we also found useful for inspiring the design of our framework. a number of papers have scientifically investigated these frameworks, studying their validity and the possibility to use them in an automated way .", "conclusion": "<title>conclusion</title> we presented a conversational ai maturity framework for assessing conversational ai development platforms, based on the ability of the produced systems to conduct conversations. by supporting the understanding of how the features of a conversational ai development platform correspond to conversational ability, this framework can help both users with choosing and developers with developing a powerful conversational ai system. our framework is inspired by related frameworks for human language development. comparable to the way in which a human speaker learns a language, the levels of conversational maturity in our framework indicate the ability to conduct and engage in a natural conversation with a user. our framework is based on, and incorporates results from an analysis of the state-of-the-art conversational ai development platforms, which we identified in a literature review. we considered the documentations of these platforms to extract common and unique features, which we grouped into a feature model to provide a highlevel overview of all the different existing features. each feature comes with a description to support the understanding of its use, context, and scope. we related the features to conversational maturity and used them to develop our framework's maturity levels. our results show that the various existing conversational ai development platforms share significant commonalities. in the future, to bridge different terminologies and support users in flexibility choosing a platform according to their current needs, we aim to develop a domain-specific language together with code generators for the various platform. such an infrastructure allows developing a system on a high level, and transforming the specification into an implementation for a concrete platform. it can also support the migration between different platforms when a platform with higher conversational maturity more becomes available."}
{"id": 2454, "date": "2021-01-13", "title": "#StayHome #WithMe: How Do YouTubers Help with COVID-19 Loneliness?", "url": "https://arxiv.org/abs/2101.03706v3[cs.HC]", "keywords": ["YouTube", "video sharing", "parasocial", "social provisions", "disaster", "loneliness"], "abstract": "oneliness threatens public mental wellbeing during covid-19. in response, youtube creators participated in the #stayhome #withme movement (shwm) and made myriad videos for people experiencing loneliness or boredom at home. user-shared videos generate parasocial attachment and virtual connectedness. however, there is limited knowledge of how creators contributed videos during disasters to provide social provisions as disaster-relief. grounded on weiss's loneliness theory, this work analyzed 1488 shwm videos to examine video sharing as a pathway to social provisions. findings suggested that skill and knowledge sharing, entertaining arts, homelife activities, live chatting, and gameplay were the most popular video styles. youtubers utilized parasocial relationships to form a space for staying away from the disaster. shwm youtubers provided friend-like, mentor-like, and family-like provisions through videos in different styles. family-like provisions led to the highest overall viewer engagement. based on the findings, design implications for supporting viewers' mental wellbeing in disasters are discussed.\u2022 human-centered computing \u2192 empirical studies in collaborative and social computing.", "rq": ["rq 1: what are #stayhome #withme videos?", "rq 1:. what #stayhome #withme videos did youtubers make and how they relate to the covid-19 pandemic?", "rq 2:. how did #stayhome #withme videos in different styles and mentioning covid-19 in different degrees affect the social provisions in the video?", "rq 3:. how did videos with different social provisions affect viewer engagement?"], "relatedWork": "2.1 social media and disasters: much research has explored the use of different social media during disasters. houston et al. reviewed prior works and concluded key affordances of social media include signaling and detecting disasters, sending and receiving requests for help, informing conditions, providing mental/behavioral support, etc. . lindsay summarized that social media such as twitter and facebook are primarily used to disseminate and receive disaster information and serve as an emergency management tool . studies examined the unique affordances of different social media in emergencies and disasters. for example, twitter is a platform for sharing short and immediate disaster messages to raise public awareness of the critical situation . facebook users seek official information and organize disaster-supporting communities . reddit users perceive and speculate risks in the long run, or different regions . youtube videos educate the public as well as spread misinformation . disasters are stressful events and can cause mental health problems for both people who are directly affected and the community at large . besides spreading disaster information, social media is also an outlet for expressing emotions and receiving mental health service . therefore studies have looked into technologies to measure public mental health by mining social media data . recent studies suggested that covid social distancing caused loneliness and other mental health challenges to many who stayed at home , especially the young adults . however, the use of video-sharing for supporting mental health during disasters is under-explored . there is limited understanding of how video creators contribute to a social media movement like #stayhome #withme to support disaster mental health and what affordances of the video-sharing platform and community can reduce disaster loneliness.", "conclusion": "<title>conclusion and future work</title> social media plays an increasingly important role in supporting people's mental wellbeing during a difficult time like covid-19. video-sharing platforms like youtube are conducive for providing social connectedness and reducing loneliness during social distancing. this work examines the #stayhome #withme movement as a space for youtubers to help mitigate covid-19 loneliness. the authors identified video styles and obtained a panoramic understanding of youtubers' creation activities and parasocial relationships in shwm. grounded on weiss's theory of loneliness, six social provisions were rated by mturk participants to analyze how videos with different styles and covid-19 mentioning affect the provisions youtubers sought to offer. the authors also explored how different social provisions affect video popularity, viewers' activities, and comment emotion, as indicators of participation in parasocial interactions. from the results, the #stayhome #withme hashtags were primarily used as a space for teaching skills and knowledge, presenting entertaining videos such as artistic presentation and gameplay, and showing homelife activities or chatting with the audience. the videos were less related to the on-going pandemic. the analysis revealed how parasocial relationships supplement social provisions during covid-19. social integration was a dominant provision provided by most of the video styles. how-to videos supported the need for guidance. homelife, chatting, and religious videos offered a sense of attachment and nurturance. the accepted manuscript viewer engagement analysis suggested that family-like provisions were the least offered provisions, but they positively affected viewer engagement and parasocial interactions. based on these findings, the authors suggest that shwm videos sought to de-escalate the mental tension caused by covid-19. youtubers offered friend-like and mentor-like provisions the most, while the family-like provisions are supported the least. youtubers and platform designers should encourage content that offers attachment, nurturance, and alliance during the pandemic to increase parasocial interactions and avoid or mitigate loneliness. moving forward, future studies will extend the findings of the present work to advance the knowledge of supporting disaster mental health through video sharing. as user-generated videos will play an increasing role, new studies and designs are needed to understand the interplay between video sharing and mental wellbeing. follow-up research will extend the findings of this study and develop new design knowledge. for example, one unanswered question in this work is to what degree parasocial interactions can psychologically supplement various social needs during a disaster. the authors do not argue that parasocial relationships with youtubers can or should replace realistic social interactions with families and friends. however, youtubers offered an alternative but growingly popular way to let people stay socially connected during disasters; therefore, it requires a more in-depth investigation. social interactions are easily affected by disasters. youtube provides an option to satisfy social-emotional needs through parasocial interactions. this work's findings offer a seminal idea regarding the use of youtube and youtubers' roles in supporting disaster mental wellbeing. it is necessary to examine youtube viewers' cognitive and behavioral changes after interacting with youtube videos during and after disasters. future work will also investigate new trending video styles such as asmr and live-streams in obtaining social provisions. these efforts will identify new possibilities of applications and services to utilize video sharing to support mental wellbeing in intensive situations. it is essential to explore their options in intervening in mental health issues of the vulnerable populations."}
{"id": 2471, "date": "2021-01-18", "title": "Tip of the Tongue Known-Item Retrieval A Case Study in Movie Identification", "url": "https://arxiv.org/abs/2101.07124v1[cs.IR]", "keywords": [], "abstract": "hile current information retrieval systems are effective for knownitem retrieval where the searcher provides a precise name or identifier for the item being sought, systems tend to be much less effective for cases where the searcher is unable to express a precise name or identifier. we refer to this as tip of the tongue (tot) known-item retrieval, named after the cognitive state of not being able to retrieve an item from memory. using movie search as a case study, we explore the characteristics of questions posed by searchers in tot states in a community question answering website. we analyze how searchers express their information needs during tot states in the movie domain. specifically, what information do searchers remember about the item being sought and how do they convey this information? our results suggest that searchers use a combination of information about: (1) the content of the item sought, (2) the context in which they previously engaged with the item, and (3) previous attempts to find the item using other resources (e.g., search engines). additionally, searchers convey information by sometimes expressing uncertainty (i.e., hedging), opinions, emotions, and by performing relative (vs. absolute) comparisons with attributes of the item. as a result of our analysis, we believe that searchers in tot states may require specialized query understanding methods or document representations. finally, our preliminary retrieval experiments show the impact of each information type presented in information requests on retrieval performance.", "rq": ["rq 1: how does a searcher in a tot state express their need in the search request?", "rq 2: how well does a conventional retrieval system satisfy tot requests?"], "relatedWork": ": our research builds on three areas of prior work. first, our work builds on psychology research on long-term memory, asking what people remember and how they convey memories. similarly, our work builds on prior information retrieval research aimed to support information re-finding in situations where a searcher has lapses in memory. much of this research has been done in the context of personal information management (pim). finally, prior ir research has also studied how information requests aimed at human intermediaries differ from requests aimed at a search system. long-term memory. long-term memory plays an important role in information re-finding. it is generally accepted that human memory is transient. research in psychology has studied how different factors contribute to lapses in long-term memory. for example, research clearly shows that long-term memory degrades with time (i.e., decay theory ) and by an individual engaging with new tasks and information objects (i.e., interference theory ). additionally, memory degrades quicker when an individual did not explicitly aim to remember the item in question (i.e., poor encoding ). in the context of movies, recall may degrade with time and by a searcher engaging with other (perhaps similar) movies. additionally, gaps in memory may occur simply because the searcher did not aim to remember the movie in the long term. psychology research has studied, not only how much is remembered, but also what is remembered. for example, research shows that people tend to forget precise details and remember high-level characteristics or \"gists\" . in the context of movies, a searcher may forget the name of a character, but remember their personality. additionally, models of long-term memory distinguish between declarative memory (i.e., remembering bits of information) versus procedural memory (i.e., remembering skills). furthermore, declarative memory is sub-divided into semantic memory (i.e., memory about inherent characteristics of an information item) versus episodic memory (i.e., memory about previous engagements with the item) . episodic memory can be viewed as \"autobiographical\" and deals with subjective experiences. previous studies about how people recall have demonstrated consistent strategies used by individuals. for example, when presented with the photograph of a famous person, individuals leverage information about the person (e.g. profession, places) in order to recall their name . this is an example of the 'tip of the tongue' phenomenon, 'a state in which one cannot quite recall a familiar word but can recall words of similar form and meaning' . compared to other information seeking tasks, both the information retrieval and cognitive psychology literature indicate that searchers in tot states exhibit more frustration at not knowing the answer and more satisfaction when the answer is revealed. interestingly, psychology research has used movies to study longterm memory in a controlled laboratory setting. as noted in furman et al. , using movies to study long-term memory is appealing because they can simulate \"aspects of real-life experiences by fusing multimodal perception with emotional and cognitive overtones. \" furman et al. conducted a study in which participants watched a 30-minute movie and completed tests to measure long-term memory at different times, ranging from 3 hours to 9 months after watching the movie. as one might expect, test performance and self-reported confidence in the test answers degraded over time. interestingly, however, performance degraded differently for test questions about different aspects of the movie. for example, performance degraded quicker for questions that asked about specific details (e.g., verbatim quotes) than questions that asked about themes and scenes involving social interactions. memory and personal information management (pim). pim research studies how people manage and access their personal information (e.g., files, emails, photos, etc.). memory plays an important role in pim. much pim research has studied the importance of episodic memory (versus only semantic memory) during search and re-finding. in other words, pim studies suggest that systems should support searching and re-finding using contextual cues. for example, a searcher may not remember the contents of an email in order to create an effective keyword query but may remember the day the email was received or events that happened that day. dumais et al. evaluated the \"stuff i've seen\" system and found that \"last modified date\" was the most widely used contextual cue for filtering search results. elsweiler et al. conducted a diary study focused on participants' everyday memory problems and strategies used to overcome these. results confirmed the importance of episodic memory to support information re-findingparticipants often forgot details about the item itself, but remembered contextual details about when the item was last used (e.g., the task they were trying to accomplish when they last engaged with an item). elsweiler et al. evaluated a search system for managing, tagging, and accessing personal photographs. the system allowed searchers to search (and re-find) based on episodic memories. results found that participants often searched based on multiple contextual cues (e.g., time, place, event-type, etc.). hwang et al. evaluated a system to tag bookmarked pages with contextual information. for example, participants could tag bookmarks based on time, location, and the task the participant was working on when the bookmark was made. results found that contextual cues were effective in helping participants re-find bookmarks. additionally, the task associated with a bookmark was the most recalled contextual cue. in the context of life-logging, prior work also suggests that episodic memories (combined with semantic memories) can help searchers find information within their own human digital memory (hdm) repositories . similarly, kelly et al. compared the effectiveness of queries containing only content information (i.e., leveraging semantic memory) versus queries containing both content and context information (i.e., leveraging semantic and episodic memory). queries combining content-related and contextual cues outperformed content-only queries. information requests aimed to humans. wilson proposed that information needs gradually evolve over four stages. first, a visceral need is one that cannot be expressed in wordsthere is a vague sense of unease that cannot be explained. second, a conscious need is one that remains ambiguous (i.e., the searcher does not know what information is needed) but could be potentially resolved by talking to others. third, a formalized need is one that can be communicated to others, but perhaps not to a search system. finally, a compromised need is one that can be formulated using a specific interface or query language (e.g., by choosing specific keywords). in this paper, we study tot information requests posed to human intermediaries. one might argue that these are cases where a searcher does not have the requisite knowledge to transition from a formalized state to an effective compromised state. to build better information retrieval systems, it is important to study not only compromised information needs (e.g., how people formulate keyword queries), but also formalized information needs (e.g., how people convey information needs to a human intermediary). arguello et al. conducted a large-scale user study that compared information requests (for the same information needs) aimed to a search system versus a human intermediary. additionally, they considered information needs associated with specific types of extratopical relevance criteria (e.g., temporal-, geographical-, complexityrelated criteria). through qualitative analysis, the authors compared the search strategies adopted by searchers when conveying extra-topical relevance criteria during requests aimed at a human intermediary versus a search system. in the human intermediary condition, participants reported less difficulty producing their requests but adopted search strategies that deteriorated retrieval performance when the request was issued to a web search engine. for example, in the human intermediary condition, participants were more likely to convey what they did not want. kato et al. also studied how people formulate requests when the information need has a specific extra-topical dimension (e.g., domain knowledge). in this case, requests were aimed to a search system. results found that participants often ignored the extra-topical dimension in their queries or used \"indirect\" strategies that work well with current search systems (e.g., using the query-term 'wikipedia' to get results for a domain novice). queries performed poorly when they explicitly mentioned the extra-topical dimension (e.g., 'simple explanation... '). more closely related to our research, hagen et al. curated a corpus of known-item questions posed to the yahoo! answers q&a site. most questions aimed at (re-)finding a website. however, some questions aimed at (re-)finding a previously experienced item (e.g., movie, book, song, band/musician, etc.). interestingly, a qualitative analysis found that 240 questions (out of 2,755) contained so-called \"false memories\", in which the asker provided incorrect information (e.g., mentioning the wrong actor when trying to recollect a movie). in a recent paper, j\u00f8rgensen and bogers report on qualitative analysis of tot requests posed to the 'tip of my joystick' reddit community, aimed at helping people re-find previously played video games. the coding scheme developed focused on similar phenomena as ours-visual characteristics (e.g., characters), audio characteristics (e.g., soundtrack), metadata characteristics (e.g., release date), comparisons with other video games, and characteristics of the context in which the asker previously engaged with the video game. the authors discuss controlled vocabularies necessary to support tot requests for video games.", "conclusion": "<title>conclusion and future work</title> in this paper, we describe tip of the tongue known-item retrieval, a class of item identification tasks where the searcher has previously experienced or consumed the item but cannot recall an identifier. previous research demonstrates that tot states can be especially frustrating to searchers and, as a result, have led to the creation of community question-answering sites around these needs, covering cultural objects such as movies, music, and books. our qualitative coding of a set of tot requests indicate that searchers employ a variety of information-seeking strategies, including semantic and episodic memories of previous experiences with the item. moreover, searchers leverage more sophisticated constructs such as multi-hop reasoning, self-reflective descriptions of previous search attempts, and expressions of uncertainty. inspite of the sophistication of these techniques, we found that automatic retrieval was largely unaffected by the presence of these operations. we believe that tot requests reflect an important and open area of information retrieval research. we used movie identification as a case study and several of our observations may or may not exist in domains such as music, books, or other media. while specific codes we developed may need to be adapted, we suspect that there are more abstract, general behaviors repeated by searchers across other domains. at that, the range of tactics employed during tot states-perhaps due to frustration-makes this a rich context within which to observe searcher behavior in controlled environments. this would require the adaptation of tot elicitation techniques from the cognitive psychology domain to the information retrieval context . from an algorithmic perspective, supporting document representations that are both comprehensive (i.e., including detailed descriptions and all metadata) and amenable to more elaborate search strategies will go a long way toward satisfying tot needs. as noted in our results, this may require better understanding the distinction between descriptive representations and those biased toward memory-salience. at the same time, the integration of personal information management and life logging techniques will be necessary for responding to contextual information conveyed by searchers."}
{"id": 2473, "date": "2021-01-19", "title": "Work Online, Welfare Calls, and Wine Night: Effects of the COVID-19 Pandemic on Individuals' Technology Use", "url": "https://arxiv.org/abs/2101.07388v1[cs.HC]", "keywords": ["COVID-19", "coronavirus", "computer-supported cooperative work", "education", "online learning", "home computing", "social media"], "abstract": "he covid-19 pandemic has changed the ways many people use computational systems. we conducted an empirical study, using qualitative and quantitative analyses of free-response surveys completed by 62 us residents, to explore how covid-19 affected their computer use across work, education, home life, and social life. nearly all participants experienced an increase in computer usage for themselves or a family member in one or more of the four domains. the increases involved both increasing frequency of existing uses as well as the adoption of new types of use. changes in usage impacted many aspects of people's lives, including relationships, affective experiences, and life trajectories. understanding these changes is important to the future of hci, as the field adapts to covid-19 and potential future pandemics. ccs concepts: \u2022 human-centered computing \u2192 empirical studies in collaborative and social computing; \u2022 social and professional topics;", "rq": ["rq 2: what activities, devices, and platforms were most salient in people's usage across these domains?"], "relatedWork": ": many scholars have studied the ways in which computing has factored into the health-care implications of covid, e.g., . this topic has also been explored in the popular press , and by governmental bodies such as the cdc . various scholars have begun to explore the role of hci in the context of the covid pandemic. perhaps most broadly, yvonne rogers identified many of the abundant ways in which covid is changing how people engage with computers. her reflective piece provided rich descriptions of her own experiences, and the experiences and actions of others around the world. similarly, mikael wiberg identified work, education, and family as three domains of social interaction that were moving online as a result of covid. in this paper, we seek to build on their recognition of the abundant ways that covid is changing people's lives, and to provide deeper insight into these myriad phenomena. in his column in communications of the acm , vint cerf also contemplated the contributions that computing could make to \"post-covid society\". we very much agree, and here explore the ways that people in an industrial civilization have been adopting and adapting existing technologies to fill new needs and wants. going deeper into the specific areas that lie at the juncture of hci and covid that we sought to explore with this paper, we here identify a range of work relevant to this paper's contributions.", "conclusion": "<title>conclusions</title> covid has changed people's lives around the world. it will continue to do so in many regions for months or years to come. beyond covid, other pandemics may become more frequent as well . as people's lives change, their computing use often changes. this study has sought to understand the changes in computing usage that covid caused for one particular population. we sought to explore several domains of participants' lives, to develop a broad sense for the range of effects that unfolded. participants identified an array of changes to their own and their families' computer use, in terms of both the quantity and the nature of the activities undertaken. through analyses of participants' comments, we identified instances where technology was a necessity and a lifeline, and also a source of new opportunities. understanding how people initially adapted to this particular pandemic may be valuable in interpreting future behavior in this domain. as subsequent pandemics or other disruptions bring about similar changes, people's computer usage will continue to evolve. understanding the ways changes in computing have unfolded as a result of covid could help the field of human-computer interaction more effectively contribute to well-being and other desirable social outcomes as future disruptions affect people's lives."}
{"id": 2489, "date": "2021-01-23", "title": "Learning from Home: A Mixed-Methods Analysis of Live Streaming Based Remote Education Experience in Chinese Colleges during the COVID-19 Pandemic", "url": "https://arxiv.org/abs/2010.01662v2[cs.CY]", "keywords": ["LS learning", "live streaming", "distance learning", "COVID-19"], "abstract": "he covid-19 global pandemic and resulted lockdown policies have forced education in nearly every country to switch from a traditional co-located paradigm to a pure online \"distance learning from home\" paradigm. lying in the center of this learning paradigm shift is the emergence and wide adoption of distance communication tools and live streaming platforms for education. here, we present a mixed-methods study on live streaming based education experience during the covid-19 pandemic. we focus our analysis on chinese higher education, carried out semi-structured interviews on 30 students, and 7 instructors from diverse colleges and disciplines, meanwhile launched a large-scale survey covering 6291 students and 1160 instructors in one leading chinese university. our study not only reveals important design guidelines and insights to better support current remote learning experience during the pandemic, but also provides valuable implications towards constructing future collaborative education supporting systems and experience after pandemic.", "rq": ["rq 1: what features do instructors use under ls learning and how are they used?", "rq 3: how does ls education shape collaborative learning experience and influence social relationships?"], "relatedWork": "nd background: we first position our work in the rich literature from the following aspects: formats of education (the activity we study), remote collaboration tools/live streaming platforms (the technology our study focuses on), and the adoption of such technology in activity (agency), where we present an overview of popular ls learning platforms used by chinese colleges during the covid-19 pandemic.", "conclusion": "<title>conclusion</title> in this paper, we study live streaming based education experiences during the covid-19 pandemic through mixed methods. with a focus on chinese higher education, we carried out semi-structured interviews on 30 students and 7 instructors from diverse disciplines, meanwhile launched a large-scale survey covering 6291 students and 1160 instructors, and analyzed user experiences on ls education. our findings suggest ls learning do help student and teachers achieve their education goal to a great extent under remote setting, yet there are several key challenges emerging under the current paradigm, including students' difficulties in paying continuous attention, decreased learning efficacy, and lack of engagement and collaboration. we further demonstrate how various interaction formats enable several novel learning experiences under ls learning, which contribute to variations in instructor-student and studentstudent relationships in both positive and negative ways. based on our findings, we propose important design guidelines and insights to better support current remote learning experiences during the pandemic, and systematically discuss design implications to construct future collaborative education supporting systems and experiences post-pandemic."}
{"id": 2496, "date": "2021-01-27", "title": "Not Now, Ask Later: Users Weaken Their Behavior Change Regimen Over Time, But Expect To Re-Strengthen It Imminently", "url": "https://arxiv.org/abs/2101.11743v1[cs.HC]", "keywords": ["behavior change; distractions and interruptions"], "abstract": "how effectively do we adhere to nudges and interventions that help us control our online browsing habits? if we have a temporary lapse and disable the behavior change system, do we later resume our adherence, or has the dam broken? in this paper, we investigate these questions through log analyses of 8,000+ users on habitlab, a behavior change platform that helps users reduce their time online. we find that, while users typically begin with high-challenge interventions, over time they allow themselves to slip into easier and easier interventions. despite this, many still expect to return to the harder interventions imminently: they repeatedly choose to be asked to change difficulty again on the next visit, declining to have the system save their preference for easy interventions.", "rq": ["rq 1: how do users' intervention difficulty choices change over time?"], "relatedWork": "2.1 self-interruptions and productivity interventions: self-interruptions are a widespread occurrence in the workplace and among students , which are characterized by users interrupting their work with social media , email , and recreational web browsing . the relationship of self-interruptions and social media use with well-being is complicated -there can be benefits , but excessive social media use can also lead to reduced well-being . a number of sociotechnical approaches have emerged to reduce self-interruptions, including deactivating social network accounts , internet addiction bootcamps , workplace site filters , time trackers , as well as various productivity interventions delivered via browser extensions , phone applications , and chatbots . a challenge in the design of these systems is how much control to give users. in the case of workplace site filters, overly restrictive policies can lower productivity and employee satisfaction . however, if productivity interventions are controlled by users, they can easily be uninstalled or bypassed, and rely on the user remaining committed to continue using them . thus, productivity tools need to adapt to users , which they could do by asking users about their intervention preferences and adapting interventions accordingly.", "conclusion": "<title>conclusion</title> attrition is a major problem faced by behavior change systems , and users commonly report mismatches between the difficulty of interventions shown by the system and users' preferred difficulty as a reason for attrition . in this paper we have explored how users' intervention difficulty preferences change over time, and how behavior change systems can adapt to them. using prompts on the habitlab platform, we find that users choose higher intervention difficulty during onboarding, but that their choice of intervention difficulty declines over time. we find that asking users their preferred intervention difficulty at low frequency can both accurately predict the user's preference for intervention difficulty, and can be done at low cost in terms of time and attrition rates. if we allow users to choose both their desired intervention difficulty as well as when they will be prompted next, they overwhelmingly choose to have no intervention this visit, but to be prompted again next visit. however, users continue to request the system to do nothing, but ask again the next visit, and rarely end up later choosing harder interventions. we believe their choice to have no intervention this visit is driven by present-biased decisions that discount future outcomes, while their choice to be prompted again is driven by a wish to avoid cognitive dissonance and a belief that they will soon get back on track towards achieving their behavior change goals. many hci systems aim to empower users by predicting and understanding users' intentions and preferences, and following them. in the case of behavior change systems, empowering users to achieve their goals requires us to understand users' preferences, while taking into consideration that users may be overly optimistic when initially choosing their behavior change regimen, and may succumb to present-biased choices over time."}
{"id": 2498, "date": "2021-01-27", "title": "Powering COVID-19 community Q&A with Curated Side Information", "url": "https://arxiv.org/abs/2101.11556v1[cs.IR]", "keywords": [], "abstract": "ommunity question answering and discussion platforms such as reddit, yahoo! answers or quora provide users the flexibility of asking open ended questions to a large audience, and replies to such questions maybe useful both to the user and the community on certain topics such as health, sports or finance. given the recent events around covid-19, some of these platforms have attracted 2000+ questions from users about several aspects associated with the disease. given the impact of this disease on general public, in this work we investigate ways to improve the ranking of user generated answers on covid-19. we specifically explore the utility of external technical sources of side information (such as cdc guidelines or who faqs) in improving answer ranking on such platforms. we found that ranking user answers based on question-answer similarity is not sufficient, and existing models cannot effectively exploit external (side) information. in this work, we demonstrate the effectiveness of different attention based neural models that can directly exploit side information available in technical documents or verified forums (e.g., research publications on covid-19 or who website). augmented with a temperature mechanism, the attention based neural models can selectively determine the relevance of side information for a given user question, while ranking answers.", "rq": ["rq 3: what kind of queries/questions does the model attend to when ranking relevant/non-relevant answers?"], "relatedWork": ": community question and answering (cq&a) systems is a well researched sub-field both in information retrieval and nlp communities. several systems have been proposed to rank user submitted answers to questions on community platforms such as yahoo! answers, reddit and quora. ranking user submitted answers on community question-answering platforms has been addressed with several approaches. primary method is to determine the relevance of the answer given an input question. text based matching is one of the most common approaches to rank answers. researchers have used several methods to compute similarity between a question and user generated answers to determine relevance. for instance, feature based questionanswer matching is used in with 17 features extracted from unigrams, bigrams and web correlation features using unstructured user search logs to rank answers. it is worth noting that user features and community features when incorporated may still yield further improvements in the performance of these models but this is not the focus of our work. the authors in used questions extracted from yahoo! answers for their experiments. researchers have used different approaches such representation learning, for instance, in authors use lstm to represent questions and answers respectively. convolutional networks have also been used in to rank answers. other approaches such as doc2vec , tree-kernels , adversarial learning , attention or deep belief networks have been used to score question and answer pairs. there have also been studies exploring community, user interaction or question based features to rank answers. while these approaches are relevant, it is not always evident how one can incorporate external information when it is either in free-text or semi-structured format into these systems. we explore some question-answer based matching approaches as baselines in this work and show that for rapidly evolving topics such as covid-19, inclusion of external curated information can boost model performance. the line of work most closely related to ours is incorporation of knowledge bases in q&a systems. existing work , however, approaches different tasks. for instance, authors in focus on finding factual answers to questions using a knowledge base. this does not extend easily to cq&a where neither the questions nor the answers may request or refer to any facts. most recent work is on incorporating medical kb for ranking answers on medical q&a platforms. they propose to learn path based representation of entities (from kb) present in question and answers posted by users. this approach relies on reliable detection of entities first, which may be absent for emerging topics such as covid-19 pandemic. another limitation of this work is that external knowledge may not always be present in a structured format. for example, cdc guidelines are usually simple question-answer pairs posted on the website. this makes it difficult to apply their approach to our problem. the proposed approach in this work incorporates semistructured information directly with help of temperature regulated attention. finally, with the rise of covid-19, researchers across disciplines are actively publishing information and datasets to share understanding of the virus and its impact on people. researchers routinely organize dedicated challenges such as semeval with tasks such as ranking answers on qa forums. one such initiative is trec-covid track which released queries, documents and manual relevance judgements to power search for covid related information. authors in also released covid-19 related qa dataset with 100+ questions and answers pairs extracted from trec covid 6 initiative. these questions/answer pairs are not user generated content, hence, do not reflect real user questions. we also rely on recently released q&a dataset from for our task. we also compile a dataset of 2000+ covid-19 questions with 10k+ answers all submitted by users on yahoo! answers for this work.", "conclusion": "<title>conclusion</title> question answering platforms provide users with effective and easy access to information. these platforms also provide content on rapidly evolving sensitive topics such as disease outbreaks (such as where it is also useful to use external vetted information for ranking answers. existing work only exploits knowledge bases which have some limitations that makes it difficult to use them for community q&a for rapidly evolving topics such as wild-fires or earthquakes. in this work, we tried to evaluate the effectiveness of external (free text or semi-structured) information in improving answer ranking models. we argue that simple question-answer text matching may be insufficient and in presence of external knowledge, but temperature regulated attention models can distill information better which in turn yields higher performance. our proposed model with temperature regulated attention, when evaluated on two public datasets showed significant improvements by augmenting information from two external curated sources of information. in future, we aim to expand these experiments to other categories such as disaster relief and scale the attention mechanism to include multiple external sources in one model."}
{"id": 2514, "date": "2021-02-03", "title": "Problematic Machine Behavior: A Systematic Literature Review of Algorithm Audits", "url": "https://arxiv.org/abs/2102.04256v1[cs.CY]", "keywords": ["algorithm auditing", "literature review", "ethics", "policy", "critical algorithm studies", "algorithmic bias", "algorithmic authority", "algorithmic accountability"], "abstract": "hile algorithm audits are growing rapidly in commonality and public importance, relatively little scholarly work has gone toward synthesizing prior work and strategizing future research in the area. this systematic literature review aims to do just that, following prisma guidelines in a review of over 500 english articles that yielded 62 algorithm audit studies. the studies are synthesized and organized primarily by behavior (discrimination, distortion, exploitation, and misjudgement), with codes also provided for domain (e.g. search, vision, advertising, etc.), organization (e.g. google, facebook, amazon, etc.), and audit method (e.g. sock puppet, direct scrape, crowdsourcing, etc.). the review shows how previous audit studies have exposed public-facing algorithms exhibiting problematic behavior, such as search algorithms culpable of distortion and advertising algorithms culpable of discrimination. based on the studies reviewed, it also suggests some behaviors (e.g. discrimination on the basis of intersectional identities), domains (e.g. advertising algorithms), methods (e.g. code auditing), and organizations (e.g. twitter, tiktok, linkedin) that call for future audit attention. the paper concludes by offering the common ingredients of successful audits, and discussing algorithm auditing in the context of broader research working toward algorithmic justice.", "rq": ["rq 1: what kinds of problematic machine behavior have been diagnosed by previous algorithm audits?", "rq 2: what remains for future algorithm audits to examine the problematic ways that algorithms exercise power in society?"], "relatedWork": ": literature reviews (sometimes referred to as literature surveys ) have been a prominent part of computing research , and a number of reviews are closely related to this work. a 2017 book by cathy o'neil illustrated how various algorithmic systems create disparate impact, and the chapters discuss discrimination in hiring algorithms, loan approval algorithms, labor-scheduling algorithms, and more. sandvig et al. review methods for algorithm auditing, and include some examples of each method. a 2016 review article sought to \"map the debate\" around ethics and algorithms , and a 2018 review article identified a research agenda for developing \"explainable, accountable and intelligible systems. \" while they do overlap with the present work, these studies did not address algorithm auditing as a primary topic. one closely-related literature review examined ethical considerations for data science . the authors identified three challenges related to data (privacy/anonymity, misuse, and accuracy/validity), as well as three challenges related to mathematical modeling (personal/group harm, subjective model design, and model misuse/misinterpretation). since these challenges are pertinent to both data science and algorithmic systems, many algorithm audits center around the same topics, especially personal/group harm. there has also been important related work in developing frameworks and theories for algorithm auditing and accountability. raji et al. introduce a framework intended for internal auditing, which organizations could use when developing algorithms. this framework is exceedingly helpful, although the focus on internal development leads to different audit considerations compared to this review with its focus on public-facing algorithms that have already been deployed. one related literature review by wieringa outlines a theory of \"algorithmic accountability\" through a synthesis of over 200 english articles. the study uses a conceptual framework for accountability to organize the findings, and concludes with a robust definition for algorithmic accountability: \"algorithmic accountability concerns a networked account for a socio-technical algorithmic system, following the various stages of the system's lifecycle. \" building on this review, the current work focuses specifically on audit studies aimed at algorithmic accountability, and synthesizes the types of behavior that require accountability. finally, a 2017 literature review of \"the sharing economy in computing\" overlaps with this work by including some algorithm audits of systems such as uber and taskrabbit. they labeled papers as \"algorithmic auditing\" if they described \"how algorithms can rule the sharing economy sites, \" finding nine papers that met this definition in the sharing economy literature. this review expands the scope beyond just the sharing economy, including audits of search algorithms like google, recommendation algorithms such as those used by spotify, computer vision algorithms such as amazon's \"rekognition, \" and more. still, the literature review presented by dillahunt et al. was instructive for identifying potentially relevant studies. it also posed two clear research questions for slrs in the field of human-computer interaction, which were used in other slrs and also served as a model for this review's research questions. the first question is about what has been done and the second is about what is next to do: \u2022 rq1: what kinds of problematic machine behavior have been diagnosed by previous algorithm audits? \u2022 rq2: what remains for future algorithm audits to examine the problematic ways that algorithms exercise power in society?", "conclusion": "<title>conclusion</title> this systematic literature review focused on audit studies of public-facing algorithmic systems, synthesizing findings from 62 studies and identifying recurring types of problematic machine behavior. the review shows that algorithm audits have diagnosed a range of problematic machine behaviors, such as discrimination in advertising algorithms and distortion in search algorithms. these studies provide empirical evidence that the public harms of algorithmic systems are not theoretical conjectures, rather, they play out in real-world public systems affecting millions of people. the review also suggests that some areas are ripe for future algorithm audits, including addressing discrimination in terms of intersectional identities, further exploring advertising algorithms which are the economic backbone of large technology companies, and employing under-explored methods such as code auditing. some organizations (e.g. twitter, tiktok, linkedin) also deserve further attention. if future audits continue to examine public-facing algorithms, hone in on specific problematic behavior(s), and use compelling baselines, then the field of algorithm auditing can continue holding algorithmic systems accountable by diagnosing harms they pose to the public. acknowledgments i greatly appreciate dr. michelle shumate for guiding this literature review in her class, \"the practice of scholarship, \" and in a subsequent independent study. thanks also to daniel trielli, who helped immensely in synthesizing and coding the papers, and to priyanka nanayakkara, who generously reviewed a draft of this paper and provided insightful feedback."}
{"id": 2518, "date": "2021-02-04", "title": "User Interface Factors of Mobile UX: A Study with an Incident Reporting Application", "url": "https://arxiv.org/abs/2102.02510v1[cs.HC]", "keywords": ["mobile UX", "mobile form design", "map UX", "environmental monitoring"], "abstract": "smartphones are now ubiquitous, yet our understanding of user interface factors that maximize mobile user experience (ux), is still limited. this work presents a controlled experiment, which investigated factors that affect the usability and ux of a mobile incident reporting app. the results indicate that sequence of user interface elements matters while striving to increase ux, and that there is no difference between tab and scrolling as navigation modalities in short forms. these findings can serve as building blocks for empiricallyderived guidelines for mobile incident reporting.", "rq": ["rq 1: what is the influence of different form designs on user experience and usability?", "rq 2: what is the influence of ui component sequences on user experience and usability?"], "relatedWork": "elated work: as indicated in (ricker and roth, 2018), mobile devices enable users to volunteer their local knowledge and experience while situated in place, providing timely and unstructured information about changing geographic conditions. since \"meine umwelt\" is dedicated to the reporting of environmental data, related work on reporting systems is briefly presented in this section. in addition, research on factors of mobile ux is briefly introduced, followed by work on form design on mobile devices, and interactive maps. et al. (2016) focused on the ux dimensions important for incident reporting systems. interviews with participants were used to gain insights into the users' perception of the investigated app. they found users to prefer a selection of reportable items from a menu. this provides an overview of all items and avoids generic forms trying to fit all items at once. moreover, an interactive map was clearly demanded by the users. another requirement found in their interviews was the necessity to provide an identification, to avoid fake reports. pictures and videos of the item should also be included in the report. re-lated to incident reporting are citizen observatories, defined as \"the participation of citizens in monitoring the quality of the environment they live in\" (liu et al., 2014). here, no recent incident or event is present as a motivation for the report. instead, observatories are more focused on ecological data and observations than on incidents in an urban context. the acquired data should be used by the government and if possible made available to the public as data and/or service (liu et al., 2014). citizens' observatories are described as a cheap and easy way for the administration to collect data about the environment.", "conclusion": "<title>conclusion</title> this article has investigated the effect of sequence of ui elements and type of forms within a mobile application for reporting ecological data. a user study has shown significant preferences for the map as a starting element, instead of the map as an ending element. besides, a tab-based, structured design was tested against a scrollable view. results have shown no significant difference between these designs in short forms. with respect to earlier research (harms et al., 2015), it can be concluded, that scrolling does not perform worse for all sizes of form length. in short, the sequence of user interface elements on mobile devices matters, and the type of form design matters, depending on the length of the forms. designers should keep in mind both (besides button placement identified in previous work horbi\u0144ski et al. (2020)) while building their next incident reporting app. future work can replicate this study, for instance, factoring in data about the complexity of the base maps, and collecting qualitative data about what users dis/liked. additionally, future studies can further investigate why perceived user experience and usability are better for some sequences than for others, based on a revised version of the cognitive fit theory, and memory-based theories of ux."}
{"id": 2562, "date": "2021-02-28", "title": "XAlgo: a Design Probe of Explaining Algorithms' Internal States via Question-Answering", "url": "https://arxiv.org/abs/2007.07407v2[cs.HC]", "keywords": ["Explainable AI", "Question Answering", "Algorithm", "Design Probe"], "abstract": "lgorithms often appear as 'black boxes' to non-expert users. while prior work focuses on explainable representations and expert-oriented exploration, we propose and study an interactive approach using question answering to explain deterministic algorithms to nonexpert users who need to understand the algorithms' internal states (e.g., students learning algorithms, operators monitoring robots, admins troubleshooting network routing). we construct xalgo-a formal model that first classifies the type of question based on a taxonomy and generates an answer based on a set of rules that extract information from representations of an algorithm's internal states, e.g., the pseudocode. a design probe based on an algorithm learning scenario with 18 participants (9 for a wizard-of-oz xalgo and 9 as a control group) reports findings and design implications based on what kinds of questions people ask, how well xalgo responds, and what remain as challenges to bridge users' gulf of algorithm understanding.\u2022 human-centered computing \u2192 human computer interaction (hci).", "rq": ["rq 1:. what kinds of questions do users ask xalgo?", "rq 2:. how well can xalgo answer users' algorithm-related questions?"], "relatedWork": ": to inform the design of a question-answering approach for explaining algorithms, we first review two key related bodies of work: explainable ai and question-answering research. we further summarize prior work on understanding software-a similar objective but a different audience (developers); and past research on intelligent tutoring systems-a similar approach (learning) to achieve the understanding of algorithm.", "conclusion": ""}
{"id": 2574, "date": "2021-03-05", "title": "Does Interaction Improve Bayesian Reasoning with Visualization?", "url": "https://arxiv.org/abs/2103.01701v2[cs.HC]", "keywords": ["Data Analysis", "Reasoning", "Problem Solving", "Decision Making", "Interaction Design", "Human-Subjects Quantitative Studies"], "abstract": "nteraction enables users to navigate large amounts of data effectively, supports cognitive processing, and increases data representation methods. however, there have been few attempts to empirically demonstrate whether adding interaction to a static visualization improves its function beyond popular beliefs. in this paper, we address this gap. we use a classic bayesian reasoning task as a testbed for evaluating whether allowing users to interact with a static visualization can improve their reasoning. through two crowdsourced studies, we show that adding interaction to a static bayesian reasoning visualization does not improve participants' accuracy on a bayesian reasoning task. in some cases, it can significantly detract from it. moreover, we demonstrate that underlying visualization design modulates performance and that people with high versus low spatial ability respond differently to different interaction techniques and underlying base visualizations. our work suggests that interaction is not as unambiguously good as we often believe; a well designed static visualization can be as, if not more, effective than an interactive one.\u2022 human-centered computing \u2192 empirical studies in interaction design; empirical studies in visualization.", "rq": ["rq 2: is the effect of interaction modulated by the effectiveness of the underlying static visualization?"], "relatedWork": ": interaction and bayesian reasoning are widely studied areas in visualization, but they are typically studied in isolation from each other. this paper focuses on the intersection of these two areas. by using bayesian reasoning as a test bed for interaction techniques, we add to the body of knowledge on interactivity, and bayesian reasoning visualizations. the following sections discuss related work studying the value add of interaction, bayesian reasoning visualizations, and the intersection of the two.", "conclusion": "<title>conclusion</title> this paper empirically shows how different interaction techniques and visualization designs affect users in solving bayesian reasoning tasks. through two crowdsourced studies, we evaluated five interaction techniques across three different static visualization designs. the results illustrate that the effect of interaction is largely dependent on the design of the underlying static visualization, and implementation of the interaction itself. additionally, we observe that people with different spatial abilities react to interaction differently. these findings suggest that adding interaction to a static bayesian reasoning visualization may not be beneficial, and in some cases can be detrimental. for example, we find adding interaction to certain designs of static bayesian reasoning visualizations can decrease users' accuracy on bayesian inference. similarly, we find when people with high spatial ability use a hover bayesian reasoning visualization, they perform a bayesian reasoning task with significantly worse accuracy than they do with a static visualization. based on these findings we conclude that interaction may not be as unanimously beneficial as it is often believed to be; in some cases a well designed static visualization can be as, if not more, effective."}
{"id": 2603, "date": "2021-03-27", "title": "VisEvol: Visual Analytics to Support Hyperparameter Search through Evolutionary Optimization", "url": "https://arxiv.org/abs/2012.01205v3[cs.LG]", "keywords": ["CCS Concepts \u2022 Human-centered computing \u2192 Visualization", "Visual analytics", "\u2022 Machine learning \u2192 Supervised learning", "Visual Analytics to Support Hyperparameter Search through Evolutionary Optimization"], "abstract": "uring the training phase of machine learning (ml) models, it is usually necessary to configure several hyperparameters. this process is computationally intensive and requires an extensive search to infer the best hyperparameter set for the given problem. the challenge is exacerbated by the fact that most ml models are complex internally, and training involves trial-and-error processes that could remarkably affect the predictive result. moreover, each hyperparameter of an ml algorithm is potentially intertwined with the others, and changing it might result in unforeseeable impacts on the remaining hyperparameters. evolutionary optimization is a promising method to try and address those issues. according to this method, performant models are stored, while the remainder are improved through crossover and mutation processes inspired by genetic algorithms. we present visevol, a visual analytics tool that supports interactive exploration of hyperparameters and intervention in this evolutionary procedure. in summary, our proposed tool helps the user to generate new models through evolution and eventually explore powerful hyperparameter combinations in diverse regions of the extensive hyperparameter space. the outcome is a voting ensemble (with equal rights) that boosts the final predictive performance. the utility and applicability of visevol are demonstrated with two use cases and interviews with ml experts who evaluated the effectiveness of the tool.", "rq": ["rq 2: how to find which particular hyperparameter set is suitable for each model in a majority-voting ensemble of diverse models?", "rq 3: is there any performance improvement from employing several validation metrics that fit better to a specific data set's inherent characteristics?"], "relatedWork": "elated work: visualization tools have been implemented for sequential-based, bandit-based, and population-based approaches , and for more straightforward techniques such as grid and random search . evolutionary optimization, however, has not experienced similar consideration by the infovis and va communities, with the exception of more general visualization approaches such as eavis and interactive evolutionary computation (iec) . to the best of our knowledge, there is no literature describing the use of va in hyperparameter tuning of evolutionary optimization (as defined in section 1) with the improvement of performance based on majority-voting ensembles. in this section, we review prior work on automatic approaches, visual hyperparameter search, and tools with which users may tune ml ensembles. finally, we discuss the differences of such systems when compared to visevol in order to clarify the novelty of our tool. automatic approaches. despite the success of automatic approaches and their advancement through the years, it is important to note that such approaches require extensive computing power and may lack critical features. automatically (or manually) set thresholds may discard different models which could be informative but theoretically seem to perform worse than the rest. moreover, the ranking of models is often based on a single validation metric, leading to the risks discussed in section 1. the aforementioned works that make use of genetic algorithms contain similar mechanisms as in visevol, but without va support for (1) the exploration of the interconnected hyperparameters, and (2) the selection of the proper number of models that should crossover and mutate. visual hyperparameter searching. atmseer implements a multi-granularity visualization for model selection and hyperparameter tuning. it is a visualization tool coupled with a backend framework, called atm , that allows the users to interact with the middle steps of an automl process and control them by adjusting the search space dynamically during execution time. in contrast to visevol, it only supports a single performance measurement, and the output is a single optimized model. one common focus of related work is the hyperparameter search for deep learning models. hypertuner is an interactive va system that enables hyperparameter search by using a multiclass confusion matrix for summarizing the predictions and setting user-defined ranges for multiple validation metrics to filter out and evaluate the hyperparameters. users can intervene in the running procedure to anchor a few hyperparameters and modify others. however, this could be hard to generalize for more than one algorithm at the same time. in our case, we combine the power of diverse algorithms, with one of them being a neural network (nn). hypertendril human-in-the-loop ensemble learning. there are relevant works that involve the human in interpreting, debugging, refining, and comparing ensembles of models . these papers use bagging and boosting techniques for ranking and identifying the best combination of models in different application scenarios. stackgenvis is a va system for composing powerful and diverse stacking ensembles from a pool of pre-trained models. on the one hand, we also enable the user to assess the various models and build his/her own ensemble of models. on the other hand, we support the process of generating new models through genetic algorithms and highlight the necessity for the best and most diverse models in the simplest possible voting ensemble. finally, our approach is model-agnostic and generalizable, since we use both bagging and boosting techniques along with both nns and simpler models . va tools have also been developed to visualize buckets of models , where the best model for a specific problem is automatically chosen from a set of available options. these works feature exploration of the space in search for a final model, but the best model might not be the optimal when compared to a set of models (i.e., multiple hyperparameters) from several algorithms. additionally, the models are already generated before the exploration, and there is no involvement of an optimization method.", "conclusion": "<title>conclusion</title> in this paper, we presented visevol, a va tool with the aim to support hyperparameter search through evolutionary optimization. with the utilization of multiple coordinated views, we allow users to generate new hyperparameter sets and store the already robust hyperparameters in a majority-voting ensemble. exploring the impact of the addition and removal of algorithms and models in a majority-voting ensemble from different perspectives and tracking the crossover and mutation process enables users to be sure how to proceed with the selection of hyperparameters for a single model or complex ensembles that require a combination of the most performant and diverse models. the effectiveness of visevol was examined with use cases using real-world data that demonstrated the advancement of the methods behind achieving performance improvement. our tool's workflow and visual metaphors received positive feedback from three ml experts, who even identified limitations of visevol. these limitations pose future research directions for us."}
{"id": 2613, "date": "2021-03-31", "title": "Showing Academic Performance Predictions during Term Planning: Effects on Students' Decisions, Behaviors, and Preferences", "url": "https://arxiv.org/abs/2104.00148v1[cs.HC]", "keywords": ["Visual learning analytics", "academic performance predictions", "framing effects", "course selection", "course recommendation"], "abstract": "ourse selection is a crucial activity for students as it directly impacts their workload and performance. it is also time-consuming, prone to subjectivity, and often carried out based on incomplete information. this task can, nevertheless, be assisted with computational tools, for instance, by predicting performance based on historical data. we investigate the effects of showing grade predictions to students through an interactive visualization tool. a qualitative study suggests that in the presence of predictions, students may focus too much on maximizing their performance, to the detriment of other factors such as the workload. a follow-up quantitative study explored whether these effects are mitigated by changing how predictions are conveyed. our observations suggest the presence of a framing effect that induces students to put more effort into course selection when faced with more specific predictions. we discuss these and other findings and outline considerations for designing better data-driven course selection tools.\u2022 human-centered computing \u2192 empirical studies in visualization.", "rq": ["rq 1: what are the effects of showing performance predictions to students during term planning?", "rq 2: how do these effects vary when we change the visual representations used to convey the predictions?"], "relatedWork": ": course selection and academic performance prediction are often discussed within the realm of learning analytics (la) . in this section, we first review existing student-oriented visualization tools in the la literature. since icora's recommendations are based on grade predictions, we then survey studies on the effects that exposing students to gpa and historical performance information has on their enrollment decisions and behavior. we conclude this section with the state of the art in visualization design choices and how these affect viewers' interpretation of visual representations. we build upon knowledge from these areas to inform the design of icora and the studies we present in this paper.", "conclusion": "<title>conclusion</title> this paper investigated the effects of performance predictions on students when they plan their upcoming term. to this end, we used icora, an interactive visualization tool that enables the composition of arbitrary sets of courses and provides performance predictions and explanations. a qualitative study of the tool found that in response to performance predictions for both individual course grades and the gpa, students tend to approach course selection as a performance maximization problem, even to the detriment of other factors such as the workload. we also observed little interest in understanding the rationale behind the predictions provided by the tool. in a follow-up quantitative study, we investigated whether the maximization and overreliance effects were affected by the type of visual representation used to convey icora's performance predictions. to this end, we designed a specific to vague spectrum of visual representations for performance predictions. in this second study, we did not found evidence of maximization effects when the gpa is not shown together with the individual course grade predictions. the participants' lack of interest in the explanations, however, persisted. we also found several significant differences in aspects such as the average predicted grade and workload of the selected courses. these differences arose both among visual representations of the same type and between different types. our observations show that framing effects arise when visual structures are used to communicate performance predictions to students. that is, some of the visual representations we studied have the potential to shape the students' decisions and their decision process. furthermore, specific types of visual representations elicit strong preferences and aversions on the students. these observations are of great value to design better data-driven course selection tools. equally importantly, our insights provide new empirical evidence on how different design choices can shape the way people interpret visual representations of data."}
{"id": 2631, "date": "2021-04-10", "title": "", "url": "https://arxiv.org/abs/2104.04842v1[cs.HC]", "keywords": ["Conversational AI Agents", "Interview Chatbot", "Chatbot Debugging", "Chatbot Evaluation Framework", "Chatbot Design Suggestion", "Automatic Chatbot Profiling", "Automatic Chatbot Evaluation"], "abstract": "", "rq": ["rq 2: how did ichatprofile help make chatbot design decisions?"], "relatedWork": "2.1 chatbots for information elicitation: ai-powered conversational user interfaces, also known as ai chatbots or chatbots for short, allow users to communicate with computers in natural language, providing more flexible and personalized user experience . such benefits have encouraged the creation of a wide array of chatbot applications, such as virtual assistants , social companions , and interview chatbots . our work is most relevant to the use of chatbots for information elicitation . researchers have developed various chatbots to elicit information from users through text-based conversations. for example, bohus and rudnicky introduce dialog systems that gather required (c) chat transcripts set in practice with poorly handled conversations information for performing specific tasks (e.g., making travel reservations) . more recently, a number of interview chatbots have been developed to elicit information from a target audience. for example, a chatbot is built to interview students for effective teaming and another chatbot to interview gamers for eliciting their game opinions . williams et al. have developed a chatbot to interview employees for workplace productivity . compared to traditional, static online surveys, these interview chatbots enhance information elicitation by providing interactive feedback and asking follow-up questions . our work is directly related to the efforts of creating interview chatbots. however, existing work focuses on developing interview chatbots for specific information elicitation tasks (e.g., ) or powering interview chatbots with specific skills (e.g., giving them a personality and active listening skills ). while we learn from these efforts, our work reported here has a very different focus: we want to build a tool that can automatically evaluate the performance of an interview chatbot and provide design suggestions for improving the chatbot.", "conclusion": "<title>conclusions</title> we described a computational framework for evaluating interview chatbots and presented ichatprofile, a tool that helps designers to evaluate and improve interview chatbots iteratively. given a set of chat transcripts, it automatically quantifies the performance of a chatbot and generates a chatbot profile. based on the generated chatbot profile, it also offers design suggestions in natural language with evidential conversation examples, which help guide designers to improve the chatbot. to validate the effectiveness of ichatprofile, we designed and conducted a between-subject study that compared the performance of chatbots designed with and without using ichatprofile. based on the transcripts collected from the live chats between 10 chatbots and 1394 users, our results show that ichatprofile helped produce interview chatbots with significantly better performance across almost all dimensions, including response quality, user engagement, and user experience."}
{"id": 2668, "date": "2021-05-02", "title": "Detecting Receptivity for mHealth Interventions in the Natural Environment", "url": "https://arxiv.org/abs/2011.08302v2[cs.HC]", "keywords": ["Receptivity", "Intervention", "Interruption", "Mobile Health", "Engagement"], "abstract": "just-in-time adaptive intervention (jitai) is an emerging technique with great potential to support health behavior by providing the right type and amount of support at the right time. a crucial aspect of jitais is properly timing the delivery of interventions, to ensure that a user is receptive and ready to process and use the support provided. some prior works have explored the association of context and some user-specific traits on receptivity, and have built post-study machine-learning models to detect receptivity. for effective intervention delivery, however, a jitai system needs to make in-the-moment decisions about a user's receptivity. to this end, we conducted a study in which we deployed machine-learning models to detect receptivity in the natural environment, i.e., in free-living conditions. we leveraged prior work regarding receptivity to jitais and deployed a chatbot-based digital coach -ally -that provided physical-activity interventions and motivated participants to achieve their step goals. we extended the original ally app to include two types of machine-learning model that used contextual information about a person to predict when a person is receptive: a static model that was built before the study started and remained constant for all participants and an adaptive model that continuously learned the receptivity of individual participants and updated itself as the study progressed. for comparison, we included a control model that sent intervention messages at random times. the app randomly selected a delivery model for each intervention message. we observed that the machine-learning models led up to a 40% improvement in receptivity as compared to the control model. further, we evaluated the temporal dynamics of the different models and observed that receptivity to messages from the adaptive model increased over the course of the study. ccs concepts: \u2022 human-centered computing \u2192 ubiquitous and mobile computing; \u2022 applied computing \u2192 health care information systems.", "rq": ["rq-3: how do the different models for predicting receptivity perform over time?"], "relatedWork": ": in the domain of ubiquitous computing, researchers have extensively explored a related concept of interruptibility. in the context of smartphone notifications, interruptibility is defined as a person's ability to be interrupted by an incoming notification by taking an action to open or view the notification content . this stream of research has focused on the use of push notifications to attract users' attention, while making the recipients feel less 'interrupted' by the notifications. in this section, we discuss the prior research on interruptibility to smartphone notifications. we also discuss prior work in capturing participant receptivity in mhealth research. most prior 'interruptibility' research has focused on analyzing and understanding user interruptibility and on the association between various contextual factors and interruptibility. researchers have studied factors such as time of day and day of week , location , bluetooth information (as a proxy for social context) , call and sms logs (another proxy for social context) , wi-fi connectivity , and phone battery information . while most of these factors were found to be a predictor of users' interruptibility, some studies have also contradicted those findings. for example, some have found time to be a significant predictor , while others have found the opposite . the same applies for location, where sarker et al. and others found location was an important indicator of interruptibility and mehrotra et al. found otherwise . other research investigated personality traits and mental state as potential predictors for receptivity. happy and energetic participants showed a higher availability to interruptions, compared to stressed study participants . other researchers have shown the significance of personality traits to predict the response delay; in particular, neuroticism and extroversion were found to be significant . many studies have found a significant correlation between physical activity and interruptibility . the type of physical activity was also found to be significant; for example, people driving in a vehicle replied more slowly than people walking outside . further, 'breakpoints' in physical activity, e.g., from walking to standing, were found to be favorable times to trigger notifications . generalizing results, however, is difficult as small sample size and homogeneity of study participants is a common problem in this research area . a few researchers have explored the concept of engagement. in the context of smartphone notifications, engagement usually follows after a person is interrupted and refers to the involvement of an user in a task or app that attracts and holds the user's attention . pielot et al. conducted a study (\ud835\udc5b > 330) in which they delivered eight different types of content and observed participants' engagement and responsiveness . they then built predictive models to classify whether a participant would engage with the notification content, and found that their models led to an improvement of more than 66% over a baseline classifier. related to engagement, dingler et al. built an app aimed at improving users' foreign-language vocabulary through notifications and app usage through out the day . the authors found that several contextual factors relating to phone usage, e.g., number of phone unlocks in the last 5 minutes, time since last unlock, and number of notifications in the last 5 minutes, showed significant correlations to predict users' engagement with the content. some works have even deployed a machine-learning classifier to infer interruptibility. okoshi et al. deployed a breakpoint-detection system to time notifications . based on a study with over 680,000 users, they found that response time to notifications was up to 49% lower if they were delivered during activity breakpoints. pielot et al. deployed a model that allowed them to deliver entertaining content when the participant was likely bored; at such times, they found participants were more likely to engage . in the domain of jitais and mhealth interventions, receptivity is defined as the person's ability to receive, process, and use the support (intervention) provided . to compare with interruptibility and engagement, as highlighted by k\u00fcnzler et al., \"receptivity may be (loosely) conceptualized to encompass the combination of interruptibility (willingness to receive an intervention), engagement (receive the intervention), and the person's subjective perception of the intervention provided (process and use the intervention)\" . there have been a growing number of works exploring receptivity and interruptibility in the domain of mhealth. sarker et al. conducted a study with 30 participants, and identified various contextual and physiological features for their machine-learning model to detect receptivity to ema prompts . the authors drew a parallel between ema and interventions by claiming that interaction with self-report or ema prompts and interaction with interventions would be similar. the authors also provided monetary incentives for ema completion, however, which may have influenced the participants' receptivity. further, mishra et al. investigated contextual breakpoints and how they could be used to detect receptivity to ema . choi et al. conducted a 3-week study with 31 participants in which the participants reported information about their context and cognitive/physical state; the paper explores the association of context and cognitive state with the relevant jit support targeted towards sedentary behavior . the authors identified several key factors relating to receptivity and showed that receptivity to jit interventions is nuanced and context-dependant. in our prior work, we developed a smartphone app to deliver physical-activity interventions and deployed it in a study with 189 participants . we explored how passively collected contextual factors, like location, physical activity, time of day, type of day, phone interaction, and phone battery level, are associated with receptivity to interventions. we also explored the relationship between receptivity and participant-specific characteristics, like age, gender, personality and device type, and receptivity. we further built machine-learning models to detect receptivity and achieved a 77% improvement in f1-score over a biased random model. morrison et al. focused on a mobile stress-management intervention . their system randomly assigned study participants to one of three groups. each group was using a different method for receiving push notifications. one group received the notifications occasionally (not daily), one group received them daily, and one group used a machine-learning model to receive 'intelligent' notifications. however, the authors did not find any difference in how the participants interacted with notifications delivered at opportune times (as determined by their model) vs. those delivered at random times. we argue the negative result was because of the following challenges, and also highlight how we address those challenges in our work. \u2022 based on prior work on interruptibility to generic phone notification, morrison et al. used location labels (home, work, and other), movement from accelerometer, and time variables as the features . while these features might be useful to detect interruptible moments for generic notifications, they might not translate to detecting receptivity to interventions. in fact, our prior work showed that some features like location labels had no significant associations with receptivity to interventions. in comparison, we used more effective features that had shown prior associations with receptivity to interventions . \u2022 morrison et al. built static personalized naive bayes models for each participant based on the data collected during an initial \"learning period. \" since the model was static and did not update after the \"learning period, \" it is possible that their models did not have enough data during to be adequately trained. on the contrary, we used data from a prior study with 148 participants to build our static model, which resulted in a more robust and better-trained model. hence, we argue that our methodology of feature selection and model development could provide better insights towards the effectiveness of machine-learning models for detecting receptivity. in our current work, we build upon the prior research by deploying machine-learning models to detect receptivity in real-life situations. we used the data collected from our previous study to build and deploy two machine-learning models to detect receptivity to physical-activity interventions. we deployed a static model that stayed unchanged through out the study, and an adaptive model that re-trained itself over the course of the study as participants interacted with the notifications. our current work moves beyond \"post-study\" model-evaluations, and evaluates the effectiveness of deploying receptivity-detection models trained using data from a previous study. further, this is the first work to deploy an adaptive model to detect receptivity to jitai and observe how the model performance changes as the study progresses.", "conclusion": ""}
{"id": 2671, "date": "2021-05-05", "title": "Does the Goal Matter? Emotion Recognition Tasks Can Change the Social Value of Facial Mimicry towards Artificial Agents", "url": "https://arxiv.org/abs/2105.02098v1[cs.HC]", "keywords": ["Human-Robot Interaction", "Human-Agent Interaction", "Affective Computing", "Facial Mimicry", "Anthropomorphism", "Uncanny Valley", "Facial Action Coding System"], "abstract": "n this paper, we present a study aimed at understanding whether the embodiment and humanlikeness of an artificial agent can affect people's spontaneous and instructed mimicry of its facial expressions. the study followed a mixed experimental design and revolved around an emotion recognition task. participants were randomly assigned to one level of humanlikeness (between-subject variable: humanlike, characterlike, or morph facial texture of the artificial agents) and observed the facial expressions displayed by a human (control) and three artificial agents differing in embodiment (within-subject variable: video-recorded robot, physical robot, and virtual agent). to study both spontaneous and instructed facial mimicry, we divided the experimental sessions into two phases. in the first phase, we asked participants to observe and recognize the emotions displayed by the agents. in the second phase, we asked them to look at the agents' facial expressions, replicate their dynamics as closely as possible, and then identify the observed emotions. in both cases, we assessed participants' facial expressions with an automated action unit (au) intensity detector. contrary to our hypotheses, our results disclose that the agent that was perceived as the least uncanny, and most anthropomorphic, likable, and co-present, was the one spontaneously mimicked the least. moreover, they show that instructed facial mimicry negatively predicts spontaneous facial mimicry. further exploratory analyses revealed that spontaneous facial mimicry appeared when participants were less certain of the emotion they recognized. hence, we postulate that an emotion recognition goal can flip the social value of facial mimicry as it transforms a likable artificial agent into a distractor. further work is needed to corroborate this hypothesis. nevertheless, our findings shed light on the functioning of human-agent and human-robot mimicry in emotion recognition tasks and help us to unravel the relationship between facial mimicry, liking, and rapport.", "rq": ["rq 1:a to what extent does the humanlikeness of artificial agents influence people's spontaneous facial mimicry?", "rq 1:b to what extent does the embodiment of artificial agents influence people's spontaneous facial mimicry?", "rq 2:a to what extent does the humanlikeness of artificial agents influence people's ability to mimic their facial expressions as accurately as possible when instructed to do so?", "rq 2:b to what extent does the embodiment of artificial agents influence people's ability to mimic their facial expressions as accurately as possible when instructed to do so?"], "relatedWork": "elated work: facial mimicry is the spontaneous imitation of another individual's facial expression without explicit instruction to do so . within the area of facial mimicry research, emotional mimicry refers to the spontaneous mirroring of a facial expression with inherent emotional meaning, for instance, wincing when observing others in pain or frowning at another person's frown. this paper focuses on people's mimicry of the six basic emotions -happiness, sadness, surprise, anger, fear, and disgust -as displayed through the facial expressions of artificial and human agents. within the subsections 2.1, 2.2, and 2.3, we give an account of the different theories on the nature and functioning of spontaneous facial mimicry in human-human interactions (hhi). we then describe the literature on human-agent and human-robot facial mimicry in subsection 2.4, and explain our interest in instructed facial mimicry in subsection 2.5.", "conclusion": "<title>conclusion</title> in the study presented in this paper, we involved participants in an emotion recognition task carried out with artificial agents differing in their embodiment and degree of humanlikeness. in the first phase of the study, we asked participants to observe the artificial agents' facial expressions and attempt to identify the emotions they displayed. in the second phase of the study, instead, we asked participants to observe the agents' facial expressions, mimic them as closely as possible, and then identify them. we used the first part of the study to investigate the frequency of participants' spontaneous facial mimicry, and the second part to investigate the accuracy of their instructed facial mimicry. the aim was to understand whether spontaneous mimicry of artificial agents' facial expressions can be used as a behavioral cue of liking and rapport, and whether instructed facial mimicry could act as a proxy of its spontaneous counterpart. our results suggest that, in an emotion recognition task, the physical instantiation of an artificial agent, together with its likability and anthropomorphism, intrudes rather than promotes people's spontaneous facial mimicry. furthermore, results suggest that instructed facial mimicry negatively predicts spontaneous facial mimicry. since the participants in this study mimicked the facial expressions of the artificial agents more when they were uncertain about the emotion to recognize, one possibility is that, in emotion recognition contexts, facial mimicry serves the purpose of emotion recognition. even though our results did not support our initial hypotheses, they nevertheless show that spontaneous mimicry can be a behavioral cue of liking and rapport, and instructed facial mimicry a proxy of spontaneous facial mimicry."}
{"id": 2704, "date": "2021-05-30", "title": "Strategies and Perceived Risks of Sending Sensitive Documents *", "url": "https://arxiv.org/abs/2105.14619v1[cs.CR]", "keywords": [], "abstract": "people are frequently required to send documents, forms, or other materials containing sensitive data (e.g., personal information, medical records, financial data) to remote parties, sometimes without a formal procedure to do so securely. the specific transmission mechanisms end up relying on the knowledge and preferences of the parties involved. through two online surveys (n = 60 and n = 250), we explore the various methods used to transmit sensitive documents, as well as the perceived risk and satisfaction with those methods. we find that users are more likely to recognize risk to data-at-rest after receipt (but not at the sender, namely, themselves). when not using an online portal provided by the recipient, participants primarily envision transmitting sensitive documents in person or via email, and have little experience using secure, privacy-preserving alternatives. despite recognizing general risks, participants express high privacy satisfaction and convenience with actually experienced situations. these results suggest opportunities to design new solutions to promote securely sending sensitive materials, perhaps as new utilities within standard email workflows. * a version of this paper was presented at the 30th usenix security symposium (sec '21).", "rq": ["rq 1: what methods are used and why?", "rq 1: what methods do people choose when sending sensitive information, and why?", "rq 2: are participants satisfied with their current approaches, particularly in terms of whether they offer sufficient privacy?", "rq 2: are people satisfied?", "rq 3: what risks are people most concerned about when sending sensitive information?", "rq 3: what risks are people most concerned about?"], "relatedWork": "elated work: this paper builds on extensive research on secure communication. in 1999, whitten and tygar's classic paper, why johnny can't encrypt: a usability evaluation of pgp 5.0 , described numerous user-facing issues that make encrypted email impractical for many users, and similar problems persist in pgp 9.0 . follow-up research suggests that usability challenges in encrypted email continue , despite many attempts to automate the process . more recently, secure, end-to-end messaging applications (e.g., signal, whatsapp, telegram) have proliferated as a straightforward and transparent way for users to communicate privately. secure messaging adoption is driven largely by peer influence, rather than its security properties , and users may have misconceptions about the security properties, sometimes believing outside parties can read these encrypted communications, or that methods like sms are more secure . inaccurate mental models of security may contribute to these misconceptions , and we also find that our participants do not strongly grasp secure communication. a particular challenge in secure communication is how to indicate when transmissions are (not) secure. numerous researchers have investigated the effectiveness of different indicators, including website authentication indicators and phishing warnings . making these indicators intelligible and noticeable, without impeding workflows or engendering habituation, remains an open challenge. even after transmission, data may continue to reside on servers, at the sender and/or receiver. cloud storage poses a particular problem as many users have incorrect models of the longevity and location of cloud-based information. clark et al. and khan et al. found that when shown data stored in the cloud, most users find at least one item they wish to delete. users also lack urgency to delete cloud-stored information and express interest in tools designed to do this . this contradicts a common user perception that they have nothing to hide . this problem is only amplified over time, with an increasing number of messaging platforms and other services relying on cloud storage and computing. difficulty protecting information may arise in part because users (and even experts) often have difficulty defining what information is sensitive in the first place . different users may also have different standards for what does or does not fall into the category of sensitive information, as this is highly reliant on context and personal preference . researchers have also investigated how people learn about digital security and privacy, and how they develop associated behaviors. people's mental models for security often focus on direct and visible threats , and people tend to adopt behaviors based on where the behavior was learned, rather than its content . as might be expected, conveniencesecurity tradeoffs also play an important role in adoption of security behaviors . other work suggests that social factors, such as observing others performing a particular security behavior, can motivate users to take more security or privacy precautions . we observe that many of these factorsconvenience, social expectations, and directness of expected threat -also play a role in our participants' choices when sending sensitive information.", "conclusion": "<title>conclusion</title> this paper reports on two surveys of users' experiences sending sensitive information: survey 1 using common scenarios drawn from prior work as prompts (n = 60, 180 total scenario instances) and survey 2 (n = 250) asking more detailed questions based on results from survey 1. we found that users most frequently expect to deliver documents in person or to use email; in reality, they typically use these methods as well as online portals or forms provided by institutional recipients. we also found that participants report high levels of satisfaction with the privacy and convenience of their existing methods, while recognizing that there are possible risks associated with transmitting this information, particularly risks of data leaking after being received at the destination. these results suggest new opportunities for tools and user interventions designed to make secure transmission of documents simpler and more transparent, and supporting retrospective privacy by nudging users to delete no-longer-needed content. table 9: free responses to \"what other methods have you used?\" (survey 2). many participants repeated methods that were provided in the closed-answer question. c survey 1"}
{"id": 2719, "date": "2021-06-04", "title": "The R-U-A-Robot Dataset: Helping Avoid Chatbot Deception by Detecting User Questions About Human or Non-Human Identity", "url": "https://arxiv.org/abs/2106.02692v1[cs.CL]", "keywords": [], "abstract": "humans are increasingly interacting with machines through language, sometimes in contexts where the user may not know they are talking to a machine (like over the phone or a text chatbot). we aim to understand how system designers and researchers might allow their systems to confirm its non-human identity. we collect over 2,500 phrasings related to the intent of \"are you a robot?\". this is paired with over 2,500 adversarially selected utterances where only confirming the system is non-human would be insufficient or disfluent. we compare classifiers to recognize the intent and discuss the precision/recall and model complexity tradeoffs. such classifiers could be integrated into dialog systems to avoid undesired deception. we then explore how both a generative research model (blender) as well as two deployed systems (amazon alexa, google assistant) handle this intent, finding that systems often fail to confirm their nonhuman identity. finally, we try to understand what a good response to the intent would be, and conduct a user study to compare the important aspects when responding to this intent.", "rq": ["rq 1:. how can a user asking \"are you a robot?", "rq 2:. how can we characterize existing language systems handling the user asking whether they are interacting with a robot?", "rq 3:. how do including components of a system response to \"are you a robot\" affect human perception of the system?"], "relatedWork": "elated work: mindless anthropomorphism: humans naturally might perceive machines as human-like. this can be caused by user attempts to understand these systems, especially as machines enter historically human-only domains (nass and moon, 2000;epley et al., 2007;salles et al., 2020). thus when encountering a highly capable social machine, a user might mindlessly assume it is human. dishonest anthropomorphism: the term \"dishonest anthropomorphism\" refers to machines being designed to falsely give off signals of being human in order to exploit ingrained human reactions to appearance and behavior (kaminski et al., 2016;leong and selinger, 2019). for example kaminski et al. (2016) imagine a scenario where a machine gives the appearance of covering it's eyes, but yet continues to observe the environment using a camera in its neck. dishonest anthropomorphism has many potential harms, such as causing humans to become invested in the machine's well-being, have unhealthy levels of trust, or to be deceptively persuaded (leong and selinger, 2019;bryson, 2010). robot disclosure: other work has looked how systems disclosing their non-human identity affects the conversation (mozafari et al., 2020;ho et al., 2018). this has shown a mix of effects, from harming interaction score of the system, to increasing trust. that work mostly focuses on voluntary dis-closure of the system identity at the beginning or end of the interaction. in contrast, we focus on disclosure as the result of user inquiry. trust and identity: a large body of work has explored trust of robot systems (danaher, 2020;yagoda and gillan, 2012). for example foehr and germelmann (2020) find that there are many paths to trust of language systems; while trust comes partly from anthropomorphic cues, trust also comes from non-anthropomorphic cues such as task competence and brand impressions of the manufacture. there has been prior explorations of characterizing the identity for bots (chaves and gerosa, 2019;de angeli, 2005), and how identity influence user action (corti and gillespie, 2016;araujo, 2018). public understanding of systems: prior work suggests one should not assume users have a clear understanding of language systems. a survey of two thousand americans (zhang and dafoe, 2019) indicates some misunderstandings or mistrust on ai-related topics. additionally, people have been unable to distinguish machine written text from human written text (brown et al., 2020;zellers et al., 2019). thus being able to remove uncertainty when asked could be beneficial.", "conclusion": "<title>conclusions and future directions</title> our study shows that existing systems frequently fail at disclosing their non-human identity. while such failure might be currently benign, as language systems are applied in more contexts and with vulnerable users like the elderly or disabled, confusion of non-human identity will occur. we can take steps now to lower negative outcomes. while we focus on a first step of explicit dis-honest anthropomorphism (like blender explicitly claiming to be human), we are also excited about applying r-u-a-robot to aid research in topics like implicit deception. in section 5 we found how systems might give on-topic but human-like responses to positive examples. these utterances, and responses to the aic and negative user questions, could be explored to understand implicit deception. by using the over 6,000 examples we provide (github.com/dngros/r-u-a-robot), designers can allow systems to better avoid deception. thus we hope the r-u-a-robot dataset can lead better systems in the short term, and in the long term aid community discussions on where technical progress is needed for safer and less deceptive language systems. we would like to thank the many people who provided feedback and discussions on this work. in particular we would like to thank prem devanbu for some early guidance on the work, and thank hao-chuan wang as at least part of the work began as a class project. we also thank survey respondents, and the sources of iconography used 9 ."}
{"id": 2720, "date": "2021-06-05", "title": "Empirically Evaluating Creative Arc Negotiation for Improvisational Decision-making", "url": "https://arxiv.org/abs/2106.02921v1[cs.AI]", "keywords": ["human-AI improvisation", "empirical evaluation", "improvisational theatre", "interactive installation"], "abstract": "ction selection from many options with few constraints is crucial for improvisation and co-creativity. our previous work proposed creative arc negotiation to solve this problem, i.e., selecting actions to follow an author-defined 'creative arc' or trajectory over estimates of novelty, unexpectedness, and quality for potential actions. the carnival agent architecture demonstrated this approach for playing the props game from improv theatre in the robot improv circus installation. this article evaluates the creative arc negotiation experience with carnival through two crowdsourced observer studies and one improviser laboratory study. the studies focus on subjects' ability to identify creative arcs in performance and their preference for creative arc negotiation compared to a random selection baseline. our results show empirically that observers successfully identified creative arcs in performances. both groups also preferred creative arc negotiation in agent creativity and logical coherence, while observers enjoyed it more too.", "rq": ["rq 1: can observers and improvisers identify a creative arc when an agent used it for decision-making?"], "relatedWork": ": improvisers demonstrate near real-time collaborative creativity in open-ended and poorly-defined problem domains . a limited number of improvisational agents exist for theatre and storytelling . the three line scene , party quirks , and tilt riders systems are cognitive models of improvisational process, using small amounts of hand-authored expert knowledge to improvise. these systems don't explicitly address the improvisational action selection problem when reasoning over larger amounts of knowledge unlike the use of creative arc negotiation in carnival. more recent improvisational systems such as offer exciting solutions for improvisational action selection using larger data sets and machine learning. in addition to addressing this same problem, creative arc negotiation also enables the system to evaluate both the human's and its own actions in the moment while responding, allowing for more creative responsibility and autonomy. creative arc negotiation can also be considered a form of intrinsic motivation for agents to follow a given creative arc. this is similar to drives for curiosity (seeking out novel or unexpected stimuli) or empowerment maximisation (seeking to maximise influence over future outcomes) . similarly, evolutionary computing has demonstrated agents trained using novelty search and surprise search , where agents are selected for achieving the most novel or unexpected outcomes instead of the highest quality outcome. creative arc negotiation operates at a meta level to generalise these approaches beyond pure maximisation, selecting novelty, unexpectedness, and quality to follow a designer-specified creative arc instead. in principle, one could also add other motivations to the negotiation process, for example, to follow an arc of empowerment. additionally, improvisation is not intended to generate a final product or outcome but on the experiential journey of an ephemeral performance. therefore, motivating the agent to maximise any aspect of the experience would be counterproductive. creative arc negotiation has roots in experience management and other interactive narrative research like fa\u00e7ade and merchant of venice . fa\u00e7ade sequences hand-authored story fragments or 'beats' for the player to follow an arc in dramatic tension. in principle, creative arc negotiation could also emulate dramatic tension search by adding dramatic tension as an added dimension to the negotiation process, while also searching through novelty, unexpectedness, and quality. the merchant of venice research describes a visual programming method for drawing dramatic arcs in order to guide a planning-based interactive narrative experience of the merchant of venice. this is a potentially useful idea that could be incorporated into carnival in the future to enable personalization of creative arcs between players or ease the creative arc authoring process for non-experts.", "conclusion": "<title>conclusion</title> this article describes creative negotiation in the carnival architecture as a solution to the improvisational action selection problem. we also briefly describe the props game in the robot improv circus installation as a domain for studying creative arc negotiation. finally, we contribute three experiments to understand the effect of creative arc negotiation in the robot improv circus on the experience of observers and participating improvisers. the results from the creative arc identification and comparison studies for observers showed that, depending on the specific arc, they could identify trends in the performances that corresponded to the creative arc used by the agent. the experiments also showed their preference for action selection using creative arc negotiation over a random sampling baseline in terms of perceived enjoyment, agent creativity, and logical coherence. observer preferences were even stronger when the human partner's actions were removed from the tasks, and only the agent's actions were evaluated. creative arc identification was not successful in our small-scale laboratory study for participating improvisers, unfortunately, and we discussed why this might be the case. more positively, evidence from the creative arc comparison task showed that, depending on the specific arc, perceptions of agent creativity and logical coherence were significantly higher (enjoyment required more study for conclusive results) for improvised performances with creative arc negotiation compared to our baseline. therefore, creative arc negotiation can be successfully used by improvisational agents for action selection and performances created this way are empirically preferred over our baseline by both observers and participating improvisers."}
{"id": 2741, "date": "2021-06-20", "title": "A Need-finding Study for Understanding Text Entry in Smartphone App Usage", "url": "https://arxiv.org/abs/2105.10127v2[cs.HC]", "keywords": [], "abstract": "ext entry makes up about one-fourth of the smartphone interaction events, and is known to be challenging and difficult. however, there has been little study about the characteristics of text entry in the context of smartphone app usage. in this paper, we present a mixed-method in-situ study conducted in 2016 with 17 active smartphone users to better understand text entry in smartphone app usage. our results show 80% of text was entered into communication apps, with different apps exhibiting distinct usage patterns. we found that structured data such as urls and email addresses are rarely typed but instead are auto-completed or replaced with search, copy-and-paste is rarely used, and sessions of smartphone usage with text entry involve more apps and last longer. we conclude with a discussion about the implications on the development of systems to better support mobile interaction.", "rq": ["rq 2: what kinds of data are entered into smartphones?", "rq 2: what kinds of textual data are entered into smartphones?", "rq 2:. what kinds of data are entered into smartphones?", "rq 4: how are text-entering sessions different from the non-text entering sessions?", "rq 5: how is text transferred among apps within sessions?"], "relatedWork": ": there have been prior studies that tried to understand various aspects of smartphone usage. b\u00f6hmer et al. ran a large-scale logging study of app launches and found that the use of an app on average lasts less than a minute. they also discovered that communication is the most often used app category, with some app categories being used more often at certain times. the livelab project also collected a large dataset of smartphone app usage records. many prior studies (e.g., ) investigated how smartphone usage is triggered by the context and how smartphone interactions can be integrated with the user's activity. karlson et al. looked at smartphone use in the context of task flow, suggesting that interruptions affect mobile productivity and found it common for users to move to a pc to complete a task started on the phone. some studies also focused on characterizing users' information needs: sohn et al. conducted a diary study and discovered that people use diverse and sometimes ingenious ways to obtain information on smartphones. to fully understand smartphone usage, it is not sufficient to only analyze the use of individual apps, as each smartphone app is designed to handle a limited number of domains (usually one), which is not sufficient to support many cross-domain tasks . thus, many researchers have looked at multi-app usage sessions. for instance, for mobile search tasks, carrascal and church reported that users frequently switch among mobile search apps and other apps, and that sessions with mobile searches also tend to have more apps used, have a longer duration; and use some categories of apps more intensively. on the other hand, many smartphone usage sessions can be very short with studies reporting that 40% of sessions are shorter than 15 seconds and 38% contain no app usage but only interactions with the lock screen or launcher (for example, to look at notifications or the time). jesdabodi and maalej proposed the concept of \"usage states\" to categorize usage sessions based on the topic of user's task. many projects (e.g., ) investigated the \"app chain\"-the temporal patterns in app launches or the contextual information of the smartphone usage to predict the next app to be launched. sequences of app screens found in user interaction traces may also be used to represent the user intents of mobile tasks . systems like helper and sugilite proposed using intelligent agents to automate tasks across multiple apps and domains. however, none of the above studies looked at the text entry aspect of smartphone usage, nor is there any dataset for text entry behaviors in app usage available to the community. there were text corpora in some prior projects collected from users' mobile text entry in a single domain (like emails or chat rooms) for the purpose of training and evaluating the performance of text entry methods. but they did not consider text entry behaviors in the context of multiple mobile app interactions, nor did they characterize the text entry behaviors so we can learn what data do users enter or what apps are these data entered into. there are also studies on the usage of a single domain of app with heavy text entry like instant messaging and sms . various systems have been developed to better support mobile text entry. some support easier and more efficient entry and processing of structured data like dates, addresses and urls. fuccella et al. 's work supports mobile text editing with gestures. although there are many solutions proposed, there are few studies about how often those solutions will be relevant, or how prominent the reported problems are, as we do not yet know in which apps do users enter and process structured data, nor do we know how those data are entered and what types of structured data are common. we hope our results reported here can help the community to have a deeper understanding of users' text entry behaviors with respect to app usage and usage sessions, and provide resources for the development of future systems to better support smartphone text entry.", "conclusion": "<title>conclusion and future work</title> we conducted a mixed-method study on understanding user's text entry on smartphones in the context of app usage. our results fill in gaps in prior work, identify characteristics of users' current text entry usage, and shed light on requirements for new systems. we characterize mobile text entry as to what, how, and to which apps the contents are entered, based on actual usage data collected from our participants. we also consider text entry in the context of cross-app sessions and compare text-entering and non-text-entering sessions. in this work, we studied the usage by a sub-population of smartphone users and provide insights on designing novel interactions to better support their usage. future research might investigate text entry behaviors for populations with broader demographics, especially those from diverse socioeconomic backgrounds, people in developing countries , or field workers who have limited access to computers and use smartphone as their primary computing device . per our interviews, our participants seldom use voice input, but a future study should collect voice input data and compare how the usage, scenario and context of voice input differ from those of other text entry methods. it would also be interesting to investigate a broader range of text entry, like text entry across multiple devices. another needed study would be about the relationships between data entry and the user's task flow, and investigate what we can infer about a user's other activities based on their text entry behaviors, and vice versa. finally, the resulting knowledge could guide the design of novel systems and interaction techniques to better support users' tasks on smartphones."}
{"id": 2750, "date": "2021-06-24", "title": "#StayHome Playing LoL -Analyzing Players' Activity and Social Bonds in League of Legends During Covid-19 Lockdowns", "url": "https://arxiv.org/abs/2106.12277v2[cs.HC]", "keywords": ["Social Network Analysis", "Games User Research", "Game Analytics", "Covid-19", "Player Community", "Behavioral Analysis"], "abstract": "humans are social beings. it is therefore not surprising that the social distancing and movement restrictions associated with the covid-19 pandemic had severe consequences for the well-being of large sections of the population, leading to increased loneliness and related mental diseases. many people found emotional shelter in online multiplayer games, which have already proven to be great social incubators. while the positive effect games had on individuals has become evident, we are still unaware of how and if games fostered the fundamental need for connectedness that people sought. in other words: how have the social bonds and interaction patterns of players changed with the advent of the pandemic? for this purpose, we analyzed one year of data from an online multiplayer game (league of legends) to observe the impact of covid-19 on player assiduity and sociality in three different geographical regions (i.e., europe, north america, and south korea). our results show a strong relationship between the development of covid-19 restrictions and player activity, together with more robust and recurrent social bonds, especially for players committed to the game. additionally, players with reinforced social bonds-i.e., people played with similar teammates-were more likely to stay in the game even once the restrictions were lifted.", "rq": ["rq 1: how did player turnout and activity vary across the covid-19 phases?", "rq 2: how did player social structures vary across the covid-19 phases?", "rq 4: how have player networks varied across different geographical regions?", "rq 4:. how have player networks varied across different geographical regions?"], "relatedWork": ": in this section, we discuss evidence of games being great incubators of sociability and connectedness. then we show how player telemetry data has been widely employed to gain knowledge of game status and player experiences. finally, we show how players have dealt with the pandemic through social gaming experiences.", "conclusion": "<title>conclusions</title> social distancing and remote working (and studying) drastically changed people's lives, disrupting their routines and basic social interactions. the #stayathome mantra, which recurred throughout the past year, brought additional impetus and force to the researching of tools that both entertain and connect. games, for example, saw unprecedented growth and in some cases these were also proven to reduce anxiety and produce a sense of well-being in their players. this rise is coherent with recent research showing how multiplayer games foster connectedness and enable real-world friendships. in this study, we expand the analysis focusing on how social interaction patterns and the structure of the player social networks were affected by covid-19 lockdowns. we modeled three different league of legends player networks, each representing a different geographical area throughout a whole year (september 2019-2020). our findings confirmed this activity and player rise already detected in other game genres, as well as the formation of stronger social connections for some players. committed players formed more recurrent and narrower bonds during the lockdown weeks. additionally, new players forming stronger connections during lockdowns were also more likely to be retained in the game when the restrictions were lifted. these findings were similar across the three geographical areas, where small specific differences might also result from political and cultural differences. in conclusion, our findings support the idea that online games can help tackle boredom, loneliness and foster social interactions, even more so in times when real-world connections are limited."}
{"id": 2771, "date": "2021-07-08", "title": "Circadian Rhythms are Not Captured Equal: Exploring Circadian Metrics Extracted by Different Computational Methods from Smartphone Accelerometer and GPS Sensors in Daily Life Tracking", "url": "https://arxiv.org/abs/2107.04135v1[cs.HC]", "keywords": [], "abstract": "ircadian rhythm is the natural biological cycle manifested in human daily routines. a regular and stable rhythm is found to be correlated with good physical and mental health. with the wide adoption of mobile and wearable technology, many types of sensor data, such as gps and actigraphy, provide evidence for researchers to objectively quantify the circadian rhythm of a user and further use these quantified metrics of circadian rhythm to infer the user's health status. researchers in computer science and psychology have investigated circadian rhythm using various mobile and wearable sensors in ecologically valid human sensing studies, but questions remain whether and how different data types produce different circadian rhythm results when simultaneously used to monitor a user. we hypothesize that different sensor data reveal different aspects of the user's daily behavior, thus producing different circadian rhythm patterns. in this paper we focus on two data types: gps and accelerometer data from smartphones. we used smartphone data from 225 college student participants and applied four circadian rhythm characterization methods. we found significant and interesting discrepancies in the rhythmic patterns discovered among sensors, which suggests circadian rhythms discovered from different personal tracking sensors have different levels of sensitivity to device usage and aspects of daily behavior.", "rq": ["rq 1: how does the intradaily temporal distribution of magnitude differ between smartphone accelerometer and gps signals?", "rq 2: how does the level of circadian disruption differ between smartphone accelerometer and gps signals?", "rq 3: how do different cr metrics correlate with one another in both smartphone accelerometer and gps signals?"], "relatedWork": "elated work: as introduced in section 1, the morning-eveningness questionnaire (meq) and the munich chronotype questionnaire (mctq) are typically used to assess the circadian rhythm in participants' sleep and wake schedule. another survey instrument, called the social rhythm metric , quantifies the circadian rhythm in other activities such as social interaction, attending school/work, and having dinner. the commonality between these surveys is their focus on the time in a day when a participant completes a certain number or proportion of a certain type of activity. schoedel et al. sought to passively detect participants' sleep and wake schedule using smartphone usage events such as the action of snoozing, alarm settings, and the first and last time of smartphone usage during a day. the authors also recorded timestamps at which the participants completed 25%, 50%, and 75% of smartphone usage to track its progression throughout the day. we call this approach survey construct automation, because it directly operationalizes survey-solicited activities as sensor-detected events. trigonometric functions naturally allow the modeling of periodicity. researchers have leveraged this to fit cosine curves to sensor signals' temporal distribution over a 24-hour period to characterize the circadian rhythm therein . the method is interchangeably called trigonometric regression, harmonic regression, or cosinor regression, for which multiple days of continuously or equidistantly sampled sensor signals serve as the input data. in the most basic cosinor setup, signal value x at time t is modeled by function x(t) = mesor + amplitude \u2022 cos(2\u03c0/24), in which three parameters of the fitted curve are of primary interest: (1) mesor: short for midline estimating statistic of rhythm, representing the mean value of the curve across cycles of the circadian rhythm; (2) amplitude: one half of the range of the curve within a cycle, and (3) \u03c6 or acrophase: the time in a cycle at which the curve reaches its maximum value. in a transformed version of the cosinor method , researchers aim to better mimic signal distributions that have a flatter or sharper peak or valley area than a normal cosine curve, which is prevalent in human actigraphy data, by plugging the cosinor function as an independent variable into a sigmoid link function such as the logistic function. transformed cosinor methods introduce additional coefficients through the link function but mesor, amplitude, and acrophase are still the key parameters describing the shape. besides the model parameters, another important metric to pay attention to is the goodness-of-fit, often the f-statistic, which indicates the degree to which the cosinor model explains the variance in the signal over the cycles. for sensor signals that are largely sinusoidal in shape, cosinor method has descriptor formula intradaily variability (iv) \u03c3 n i=2 (xi\u2212xi\u22121) 2 /(n\u22121) \u03c3 n i=1 (xi\u2212 x) 2 /n interdaily stability (is) \u03c3 24 h=1 ( xh \u2212 x) 2 /24 \u03c3 n i=1 (xi\u2212 x) xh + 1(h > 20)\u03c3 h\u221220 1 xh ]/5 relative amplitude (ra) m 10\u2212l5 m 10+l5 table 1: five non-parametric descriptors of circadian rhythm. in the formulas, n represents the total number of sampled points. x i is the i-th sampled value of the signal. x is the mean value of all sampled points. xh is the mean value of sampled points within hour h \u2208 {1, . . . , 24} across all days observed. been the gold standard approach to characterize circadian rhythm. however, for many other signals that fail to satisfy such an assumption, a set of metrics extracted by non-parametric methods have become popular . the nonparametric methods also take as input equidistantly sampled (at least hourly) sensor signals but aim to directly quantify notions such as fragmentation within cycle, contrast between rest and activity within cycle, and stability between cycles. table 1 lists five typical non-parametric descriptors of circadian rhythm which can be computed for sensor signals of any shape. of the five metrics, intradaily variability (iv) quantifies fragmentation within a daily cycle. its value increases when there exists a higher amount of switching between low and high activity each day (\"varies more\"). interdaily stability (is), on the other hand, characterizes the extent to which the signal pattern remains similar across different days and takes a greater value when such similarity is high. the other three metrics, m10, l5, and relative amplitude (ra) are based on the periods of time during a day when the signal sees the lowest and highest intensity. m10 is the mean signal value over the 10 consecutive hours during which such value is the highest, whereas l5 indicates the mean signal value over the 5 consecutive hours during which such value is the lowest. relative amplitude quantifies the contrast between m10 and l5: when l5 is very small relative to m10, the ra approaches 1 but becomes zero when the signal's temporal distribution is uniform. fourier analysis, or spectral analysis, is another method to quantify circadian rhythm, specifically the strength of it. using fourier analysis, researchers first obtain the frequency spectrum of a signal, resulting in a periodogram. then, the density of frequency that falls between a specific range can be used as an indicator of rhythmic strength, calculated as the area under the periodogram curve within the range. for circadian rhythm, this range should be a small neighborhood of 24 hours. saeb et al. first used this method on gps location data collected from participants' smartphones. the authors created a lomb-scargle periodogram for each participant's gps coordinates, calculated the amount of energy that fell into the frequency bins within a 24\u00b10.5-hour period, and used this measure as a circadian movement feature for further predictive modeling of depression symptoms. other standalone studies exist that seek to quantify the notion of circadian pattern in unique ways. abdullah et al. used smartphone features such as distance traveled to predict cr scores obtained from the social rhythm metric survey. canzian et al. proposed a \"routine index\" which quantifies the similarity between the geographic distribution of an individual's smartphone-tracked location traces within a period of time during a day and that of the location traces within the same period of time during other days. huckins et al. also focused on the similarity concept and computed \"circadian similarity\" scores which are intra-class correlations between day-to-day variations in smartphone sensing features extracted over the same daily epochs (e.g., morning, afternoon). as opposed to using a trigonometric function to approximate for rest and activity, huang et al. used a hidden markov model to infer latent activity states from participants' accelerometer signal and computed cosinor-like circadian metrics based on the curve generated by latent state probabilities.", "conclusion": "<title>conclusion</title> in this study, we used smartphone tracking data from 225 college student participants with at least five full days of complete data to investigate interrelations between circadian patterns extracted from accelerometer and gps sensors. we used four analytical approaches, namely survey construct automation, transformed cosinor modeling, non-parametric methods, and fourier analysis, to characterize circadian rhythm using both data types. we conceptually categorized cr metrics into three categories, namely temporal distribution, activity span, and circadian disruption. we asked three research questions: rq1 and rq2 compared cr metrics of the temporal distribution category and the circadian disruption category between smartphone accelerometer and gps activity, whereas rq3 examined the inter-relations between different cr metrics within the same sensor. we found that, compared to gps signals, the intradaily distribution of smartphone accelerometer activity follows a pattern that starts earlier in the day; winds down later; reaches half cumulative activity about the same time, which is about two hours earlier than when it reaches maximum activity; conforms less to a sinusoidal wave; and exhibits more intradaily fragmentation. moreover, gps activity exhibited a stronger circadian rhythm and interdaily stability than accelerometer, revealing differences in the daily behavioral aspects that manifest in the two sensor signals. finally, the inter-relations between different cr metrics have their respective peculiarities in accelerometer and gps activity. a notable one is the negative relation between intradaily variability and circadian rhythm strength, which is present in gps but not in accelerometer. our explorations reported in this paper demonstrated the reactivity of passive circadian monitoring and computation to mobile sensor choices (thus daily behavioral aspects) and offered empirical evidence for the inter-relations between a comprehensive set of different circadian rhythm measures."}
{"id": 2782, "date": "2021-07-14", "title": "Effective Interfaces for Student-Driven Revision Sessions for Argumentative Writing", "url": "https://arxiv.org/abs/2107.07018v1[cs.HC]", "keywords": [], "abstract": "e present the design and evaluation of a web-based intelligent writing assistant that helps students recognize their revisions of argumentative essays. to understand how our revision assistant can best support students, we have implemented four versions of our system with differences in the unit span (sentence versus subsentence) of revision analysis and the level of feedback provided (none, binary, or detailed revision purpose categorization). we first discuss the design decisions behind relevant components of the system, then analyze the efficacy of the different versions through a wizard of oz study with university students. our results show that while a simple interface with no revision feedback is easier to use, an interface that provides a detailed categorization of sentence-level revisions is the most helpful based on user survey data, as well as the most effective based on improvement in writing outcomes.\u2022 human-centered computing \u2192 interactive systems and tools; graphical user interfaces; web-based interaction; natural language interfaces; empirical studies in interaction design; empirical studies in hci; \u2022 applied computing \u2192 education; \u2022 computing methodologies \u2192 artificial intelligence.", "rq": ["rq 3: is argrewrite beneficial for student essay improvement?", "rq 4: is there any difference in students\\' revision behavior based on argrewrite condition?"], "relatedWork": ": many of the nlp-based writing assistant tools that were developed over the last few years provide feedback on one writing product at a time, or focus on high-level semantic changes. for example, grammarly provides feedback on grammar mistakes and fluency, ets-writing-mentor provides feedback to reflect on higherlevel essay properties such as coherence, convincingness, etc. other writing assistant tools such as elireview , turnitin are designed for peer feedback, plagiarism detection, etc., rather than focusing on writing analysis and feedback. in contrast to those existing tools, we compare two drafts using the argrewrite revision assistant tool. while a previous version of argrewrite provided feedback based on detailed revision categorization at the sentence-level and was evaluated via a user survey, the current study develops two additional argrewrite interfaces (based on binary revision categorization and sub-sentential revision units) and evaluates all interfaces using both user survey and writing improvement analysis. in terms of revision analysis, work on wikipedia is the most related to the study of academic writing. prior works on wikipedia revision categorization focus on both coarse-level and finegrained revisions. however, because some fine-grained wikipedia categories (e.g., vandalism) are specific to wiki scenarios, writing studies instead use fine-grained revision categories more suitable for student argumentative writing . in both cases (wikipedia or educational), previous studies have focused on investigating the reliability of manually annotating and automatically classifying coarse-level and detailed revision categories, as well as on demonstrating correlations between category frequency and outcome measures. in contrast, our study manipulates whether argrewrite provides feedback using coarse-level (surface versus content) or detailed (e.g., claim, evidence, etc.) revision categorizations of textual changes. previous studies on writing revision research vary as to whether they use the word-level or the sentence-level as the revision span . sentences represent a natural boundary of text and automatic revision extraction at the sentence-level has been shown to be reasonably accurate . however, sentence-level revision categories may not always be appropriate. for example, a sentence revision may contain a few fluency changes at the beginning, with substantial information added at the end. in that case, that sentence contains both surface and content revisions. with that in mind, in addition to the sentence-level revisions that were the focus of the original argrewrite , the current study also explores sub-sentential revisions with detailed revision categorization. the writer's previous revision effort is often studied in collaborative writing to visualize revisions from multiple authors. for example, docuviz tracks the number of revisions in google docs and shows the pattern of revising and developing a collaborative document by multiple authors. unlike collaborative writing, our work focus on multiple revisions by a single author. another research work that studies visualizing multiple revision patterns by a single student also focuses on the amount of revision through an automated revision graph . although our argrewrite tool does show the number of revisions for each revision category, we do not categorize the revisions based on the frequency. instead, the revision categories reflect the purpose of that revision. in our tool, the revision are highlighted in both drafts of the essay. in argument mining, the main goal is to find argument structures and their relations from text. it also focuses on a single text. however, few tools are available for argument mining. one recent work experiments with a text editor to support the student argumentation skills . the tool provides feedback on the argumentation quality of a given text. students using the tool wrote a more convincing argument than students in the control/baseline condition. a tool called argulens helps find issues in issue tracking systems using automatic argument mining . another recent tool for argument mining is called targer , which also visualizes argumentative phrases in a text of a single draft. unlike these argument mining tools, our argrewrite focuses on argumentative revision and compares two drafts of student essays. works on formative feedback usually focus on embedded writing instructions for students to further improve the article . while we provide revision analysis and show it with corresponding highlight colors on our web-based tool, this is not a study about providing formative feedback on student essays, or the quality of feedback. rather, our study focuses on helping students to understand their previous revision effort, or how they addressed the feedback received on the previous draft of an essay. monitoring one's own progress towards a goal is a cognitively complex task called self-regulation . previous studies have shown that self-regulation has a positive impact on students' writing development . in our study, self-regulation occurs both during the reflection of previous revision efforts and during the actual revision process. our argrewite tool does not suggest any future revision automatically. instead, it presents its analysis (but not quality evaluation) of previous revisions so that students can make informed decisions when they further revise the essay. figure 1 shows the essay revision process using the argrewrite tool. experimental participants were recruited through flyers targeting undergraduate and graduate-level students who were either native english speakers or non-native speakers with a certain level of english proficiency (toefl score > 100). in our experiment, there are two rounds of essay revision, draft1 to draft2, and draft2 to draft3. participants wrote their first draft (draft1) of an essay at home based on a given prompt 2 . after a few days of finishing draft1, 2 the prompt is provided in a.1 each participant received expert feedback 3 on their essay argument quality and overall writing structure. based on the feedback, they revised their draft1 and produced draft2. after finishing draft2, participants were randomly assigned to use different conditions of the argrewrite in a lab environment. they did not receive any feedback on their draft2. instead, they are shown the argrewrite interface on a computer highlighting their previous revision from draft1 to draft2. participants were asked to use the tool to revise their draft2 and create a final and generally improved version of the essay, draft3.", "conclusion": "<title>conclusion</title> in this paper, we presented a tool that helps students to make further revisions on their argumentative writings. we developed four versions of the interface for the tool and presented a comparative study to determine to what extent might the explicit representations of revision purpose categories help students to improve their essay. our analysis shows that detailed revision categorization at the sentence-level is the most helpful compared to conditions that do not provide detailed feedback. detailed sub-sentential revision categorization also seemed promising, but more research and development is warranted. in particular, determining the most useful and intuitive level of granularity and detail in writing feedback is an open research question. in the future, we plan to further explore the sub-sentential revision purpose taxonomy to support effective automated writing assistant systems."}
{"id": 2786, "date": "2021-07-18", "title": "\"I Packed My Bag and in It I Put...\": A Taxonomy of Inventory Systems for Virtual Reality Games", "url": "https://arxiv.org/abs/2107.08434v1[cs.HC]", "keywords": ["virtual reality", "inventory", "taxonomy", "game design"], "abstract": "n a journey, a backpack is a perfect place to store and organize the necessary provisions and tools. similarly, carrying and managing items is a central part of most digital games, providing significant prospects for the player experience. even though vr games are gradually becoming more mature, most of them still avoid this essential feature. some of the reasons for this deficit are the additional requirements and challenges that vr imposes on developers to achieve a compelling user experience. we structure the ample design space of vr inventories by analyzing popular vr games and developing a structural taxonomy. we combine our insights with feedback from game developers to identify the essential building blocks and design choices. finally, we propose meaningful design implications and demonstrate the practical use of our work in action.", "rq": ["rq 1: how important are inventory systems for vr games?", "rq 2: how difficult is the design and development process?", "rq 3: are the available resources a sufficient aid?", "rq 4: what are the unique requirements and challenges when implementing inventories for virtual scenarios?"], "relatedWork": ". related work: despite being one of the most common elements in games, only two closely related works address inventories in vr: wegner et al. compare two concepts for their suitability in serious games, and cmentowski et al. present different inventory designs and establish an early taxonomy. considering the sparse pool of closely related work, we briefly introduce the most relevant work dealing with vr menus in general. for a detailed overview of menus and interactions in virtual environments, we point to the work by dachselt et al. , kim et al. , and bowman et al. . unfortunately, the established insights are only partially applicable since inventories differ from most of the researched interfaces. unlike other menus, such as game settings, inventories should blend into the active gameplay and support a specific set of interactions. in one of the earliest works on virtual menus, jacoby et al. present seven interaction aspects: invocation, location, reference frame, cursor, highlighting, selection, and removal. these terms partially overlap with the design characteristics placement, selection, representation, and structure given by bowman et al. . we have arranged these terms into three basic categories: \u2022 layout: representation, structure \u2022 placement: location, reference frame \u2022 interaction: invocation, removal, highlighting, selection a. layout menus in virtual environments come in various shapes and appearances, depending on the use case. often, menus closely match the scenario's visual appearance, which ensures a consistent experience and benefits the overall game experience . other designs preserve a neutral and abstract style, making them familiar and easily recognizable as archetypes of their kind , . apart from designing the menu itself, research has focused on the menu items' layout and geometry. over time, many prominent approaches have been proposed, such as the tulip menu or the command and control cube . many publications have covered the differences between various layouts regarding efficiency and intuitiveness . as these approaches mainly have emphasized the fast selection of few distinct menu options, the results are not applicable to inventories aiming to easily manage dozens of items.", "conclusion": "<title>vii. conclusion</title> developers of vr inventories can select from various designs for each component and thus must consider the framing determined by the respective game. our work introduced this timely topic by structuring the research area in multiple steps. after filtering the applicable, related work, we conducted semistructured interviews with developers to assess the community's needs. then, we analyzed the inventories of 18 vr games and decomposed the interfaces' structure. our taxonomy covers the vast design space of vr inventories, ranging from simple 2d solutions to diegetic interfaces. while these building blocks share common aspects with non-vr inventories, they also account for vr-related peculiarities, such as spatial interactions. structuring the design process into requirements and building blocks provides a guideline and facilitates decision-making. we emphasize that our work is not limited to real-world inventories but also applies to storage concepts beyond those known from our daily lives. in the final part, we designed three inventories for specific use cases to demonstrate our contribution. the application section also unveils our open questions: developers usually consider game-and user-related requirements first. these assumptions provide an idea of the critical aspects required for the next implementation steps. however, how these considerations lead to specific design decisions favorable for the intended use case remains unclear. next, developers must assemble a complete set of design choices. this selection bears further challenges in the form of detrimental effects between individual design elements. these problems illustrate the need to evaluate the interplay between requirements and design choices and the mutual effects between building blocks further. we assume that such future work will complement our structural approach and help developers and researchers."}
{"id": 2820, "date": "2021-08-02", "title": "Examining the Social Context of Alcohol Drinking in Young Adults with Smartphone Sensing", "url": "https://arxiv.org/abs/2107.06302v3[cs.SI]", "keywords": ["passive sensing", "smartphone sensing", "nightlife", "alcohol", "drinking", "social context", "young adults", "mobile sensing", "self-reports", "interaction sensing", "continuous sensing"], "abstract": "ccording to prior work, the type of relationship between a person consuming alcohol and others in the surrounding (friends, family, spouse, etc.), and the number of those people (alone, with one person, with a group) are related to many aspects of alcohol consumption, such as the drinking amount, location, motives, and mood. even though the social context is recognized as an important aspect that influences the drinking behavior of young adults in alcohol research, relatively little work has been conducted in smartphone sensing research on this topic. in this study, we analyze the weekend nightlife drinking behavior of 241 young adults in a european country, using a dataset consisting of self-reports and passive smartphone sensing data over a period of three months. using multiple statistical analyses, we show that features from modalities such as accelerometer, location, application usage, bluetooth, and proximity could be informative about different social contexts of drinking. we define and evaluate seven social context inference tasks using smartphone sensing data, obtaining accuracies of the range 75%-86% in four two-class and three three-class inferences. further, we discuss the possibility of identifying the sex composition of a group of friends using smartphone sensor data with accuracies over 70%. the results are encouraging towards supporting future interventions on alcohol consumption that incorporate users' social context more meaningfully and reducing the need for user self-reports when creating drink logs for self-tracking tools and public health studies. ccs concepts: \u2022 human-centered computing \u2192 empirical studies in hci; empirical studies in ubiquitous and mobile computing; smartphones; mobile phones; mobile devices; empirical studies in collaborative and social computing; \u2022 computer systems organization \u2192 sensors and actuators; \u2022 applied computing \u2192 consumer health; health informatics; sociology; psychology.", "rq": ["rq 1: what social contexts around drinking events can be observed by analyzing self-reports and smartphone sensing data corresponding to weekend drinking episodes of a group of young adults?", "rq 2: can young adults\\' social context of drinking be inferred using sensing data?", "rq 3: are social context inference models robust to different group sizes?"], "relatedWork": "background and related work 2.1 the social context of drinking alcohol: while there are numerous definitions for the term social context in different disciplines, in this paper, we borrow the concept commonly used in alcohol research , which refers to either one or both of the following aspects: (1) type of relationship: the relationship between an individual and the people in the individual's environment with whom she or he is engaging, and (2) number of people: the number of people belonging to each type of relationship, with whom the individual is engaging. by combining the two aspects, a holistic understanding of the social context of drinking of an individual can be attained. the consumption of alcohol is associated with different contextual characteristics. these characteristics include the type of setting (e.g., drinking location), its physical attributes (e.g., light, temperature, furniture), its social attributes (e.g., type, size, and sex-composition of the drinking group, on-going activities), and the user's attitudes and cognition . applied to real-life situations, this conception underlines the changing nature of the drinking context, in the sense that the variety of situations during which alcohol might be consumed is rather large. for instance, across three consecutive days, the same person might drink in a restaurant during a date with a romantic partner, join a large party at a night club with many attendees, and finally, join a quiet family dinner at home. among all contextual characteristics, the composition of the social context is a central element of any drinking occasion, since the consumption of alcohol is predominantly a social activity for non-problematic drinkers . among adolescents and young adults, previous literature has shown that amounts of alcohol consumed on any specific drinking occasion vary depending on the type and number of people present . the type of relationship that received the most attention so far is the presence of friends, in terms of number and of sex composition. converging evidence shows that the likelihood of drinking and drinking amounts are positively associated with the size of the drinking group . unfortunately, the group size is generally used as a continuous variable, preventing the identification of a threshold at which the odds of drinking in general or drinking heavily increase. evidence regarding the sex composition of the group, however, provided mixed results, with some studies indicating that more alcohol is consumed in mixed-sex groups while others suggesting that this might rather be the case in same-sex groups . the influence of the presence of the partner (e.g. boyfriend or girlfriend) within a larger drinking group has not been investigated, but evidence suggests that alcohol is less likely to be consumed and in lower amounts in a couple situation (i.e., the presence of the partner only) . it should be noted that these studies only suggest correlational links between the contextual characteristics and drinking behaviors and should not be interpreted as causal relationships. the presence or absence of members of the family also play an important role in shaping adolescents and young adults' drinking behaviors. in particular, the presence of parents and their attitude towards drinking are often described as being either limiting or facilitating factors, but evidence in this respect is inconclusive. for instance, the absence of parental supervision was found to be associated to an increased risk for drinking at outdoor locations and young adults' home suggesting that their presence might decrease this risk. however, another study shows that parents' knowledge about the happening of a party is negatively associated with the presence of alcohol, but there was no relationship between whether a parent was present at the time of the party and the presence of alcohol . lastly, parents might also facilitate the use of alcohol by supplying it, especially to underage drinkers . to sum up, evidence on the impact of the presence or absence of parents on young people's drinking appears mixed as this might be related to their attitude towards drinking, with some parents being more tolerant or strict than others . lastly, it should be noted that the presence of siblings has rarely been investigated, but unless they have a supervision role in the absence of parents, their role within the drinking group might be similar to one of friends. . crane et al. conducted a randomized controlled trial using the app called \"drink less\", to provide interventions. this app relied on user self-reports, and they concluded that the app helped reduce alcohol consumption. moreover, davies et al. conducted a randomized controlled trial with an app called \"drinks meter\", that provided personalized feedback regarding drinking. this app also used self-reports to provide feedback. similarly, many mobile health applications in alcohol research that provide users with interventions or feedback, primarily used self-reports .", "conclusion": "<title>conclusion</title> in this study, we examined the weekend drinking behavior of 241 young adults in switzerland using self-reports and passive smartphone sensing data. our work emphasized the importance of understanding the social context of drinking, to obtain a holistic view regarding the alcohol consumption behavior. with multiple statistical analyses, we show that features from modalities such as accelerometer, location, bluetooth, and application usage could be informative about social contexts of drinking. in addition, we define and evaluate seven inference tasks obtaining accuracies of the range 75%-86% in two-class and three-class tasks, showing the feasibility of using smartphone sensing to detect social contexts of drinking occasions. we believe these findings could be useful for ubicomp and alcohol epidemiology researchers towards in implementing future mobile health systems with interventions and feedback mechanisms."}
{"id": 2828, "date": "2021-08-05", "title": "LookAtChat: Visualizing Eye Contacts for Remote Small-Group Conversations", "url": "https://arxiv.org/abs/2107.06265v3[cs.HC]", "keywords": ["eye contact", "video conferencing", "video-mediated communication", "gaze interaction"], "abstract": "fig. 1. we present lookatchat, an online group chat system that takes advantage of eye-tracking technology available with ordinary webcams to visualize eye contacts in group chats. lookatchat implements and evaluates both 2d directional and 3d perspective layout to inform users with spatial cues. to convey eye contacts in a), b) directional layout renders arrows between video streams, while out-glowing the video window of users who are looking at you. c) perspective layout transforms video streams to gaze targets, while slightly shaking the video window of users who are looking at you. as a proof-of-concept, lookatchat explores the potential of using gaze information during online video chat. video conferences play a vital role in our daily lives. however, many nonverbal cues are missing, including gaze and spatial information. we introduce lookatchat, a web-based video conferencing system, which empowers remote users to identify eye contact and spatial relationships in small-group conversations. leveraging real-time eye-tracking technology available with ordinary webcams, lookatchat tracks each user's gaze direction, identifies who is looking at whom, and provides corresponding spatial cues. informed by formative interviews with 5 participants who regularly use videoconferencing software, we explored the design space of eye contact visualization in both 2d and 3d layouts. we further conducted an exploratory user study (n=20) to evaluate lookatchat in three conditions: baseline layout, 2d directional layout, and 3d perspective layout. our findings demonstrate how lookatchat engages participants in small-group conversations, how gaze and spatial information improve conversation quality, and the potential benefits and challenges to incorporating eye contact visualization into existing videoconferencing systems. ccs concepts: \u2022 human-centered computing \u2192 collaborative interaction.", "rq": ["rq 1: how do people perceive eye contact without visualization in conventional videoconferencing?", "rq 2: can visualization of eye contact improve communication efficiency?", "rq 4: what forms of eye contact visualization may be preferred by users?"], "relatedWork": ": to understand how gaze information is integrated into video conferences and to justify our design decisions, we review prior art on multi-user experience in distributed collaboration and gaze tracking technologies for videoconferencing. many researchers have contributed to investigating future workspaces such as improving individual productivity like holodoc , reconstructing multi-user experiences like \"the office of the future\" , and cross-device interaction . furthermore, remote conferencing shows its potential for geologically dispersed users and is efficient for group discussion . in scenarios requiring certain levels of trust and judgement with non-verbal communication, non-verbal cues are highly important for effective communication . gaze support and feeling of face-to-face play a central role in those scenarios. with the increasing development of gaze tracking devices and technology, gaze-assisted interaction are becoming popular in the fields of text entry , video captions , and video conferences.", "conclusion": "<title>conclusion and future work</title> in this paper, we introduce lookatchat, a web-based video conferencing system which supports visualizing eye contacts for small-group conversations. motivated by missing gaze information in conventional video conferences, we investigate the demands of gaze information by conducting five formative interviews. we further explore the design space of visualizing eye contacts with video streams of small groups and propose 11 layouts by brainstorming in focused groups. as a proof-of-concept, we develop and open source lookatchat which supports eye contact visualization for small-group conversations. we conduct a remote user study of 20 participants to examine the benefits and limitations of the interfaces, as well as the potential impacts of user engagement and experience on the conversation. the quantitative results indicate that lookatchat with directional layout and perspective layout provided notably more bidirectional sensation, feelings of direct conversation, social experience, and engagement than the baseline layout. more participants prefer the 2d directional layout to the 3d perspective layout because it is simpler and easier to understand. we plan to explore several future directions for improving lookatchat. first, we plan to implement more layouts from our design space exploration stage and establish an open-source community to develop more layouts to the system. second, we intend to integrate privacy protection filters for users to select whether or not to share their own gaze information. third, more advanced real-time neural models may be leveraged to improve the tracking accuracy in lookatchat and balance the trade off between accuracy and real-time performance. as an initial step toward visualizing eye contacts in conventional video conferencing interfaces with commonly accessible hardware requirements, we believe our work may inspire more designs to convey nonverbal cues for remote conversations. such features may eventually be integrated with video conferencing software to increase social engagement and improve conversation experience."}
{"id": 2869, "date": "2021-08-23", "title": "The \"Shut the f**k up\" Phenomenon: Characterizing Incivility in Open Source Code Review Discussions", "url": "https://arxiv.org/abs/2108.09905v1[cs.SE]", "keywords": ["incivility", "civility", "communication", "code review", "open source", "online communities"], "abstract": "ode review is an important quality assurance activity for software development. code review discussions among developers and maintainers can be heated and sometimes involve personal attacks and unnecessary disrespectful comments, demonstrating, therefore, incivility. although incivility in public discussions has received increasing attention from researchers in different domains, the knowledge about the characteristics, causes, and consequences of uncivil communication is still very limited in the context of software development, and more specifically, code review. to address this gap in the literature, we leverage the mature social construct of incivility as a lens to understand confrontational conflicts in open source code review discussions. for that, we conducted a qualitative analysis on 1,545 emails from the linux kernel mailing list (lkml) that were associated with rejected changes. we found that more than half (66.66%) of the non-technical emails included uncivil features. particularly, frustration, name calling, and impatience are the most frequent features in uncivil emails. we also found that there are civil alternatives to address arguments, while uncivil comments can potentially be made by any people when discussing any topic. finally, we identified various causes and consequences of such uncivil communication. our work serves as the first study about the phenomenon of in(civility) in open source software development, paving the road for a new field of research about collaboration and communication in the context of software engineering activities. ccs concepts: \u2022 human-centered computing \u2192 empirical studies in collaborative and social computing; \u2022 software and its engineering \u2192 open source model.", "rq": ["rq 2: how much incivility exists in code review discussions of rejected patches?", "rq 3: how is incivility correlated with the occurrence of arguments, the individual contributors, and the discussion topics?", "rq 4: what are the discoursal causes of incivility?", "rq 5: what are the discoursal consequences of incivility?"], "relatedWork": "background & related work: in this section, we provide background information and discuss related work in the areas of (1) the modern code review process in general, (2) the code review process of the linux kernel development, (3) the social construct of incivility, and (4) previous studies focused on negative communication in open source software development.", "conclusion": "<title>conclusion & future work</title> incivility is an important issue that can potentially affect many open source contributors in various ways. to the best of our knowledge, this is the first study of an in-depth characterization of incivility in open source code review discussions, providing evidence, descriptions, and explanations of incivility in this dynamic context. by analyzing the code review discussions of the linux kernel mailing list, we encountered tbdfs not previously found in any other study, proposed a definition of incivility based on the uncivil tbdfs, assessed the frequency of incivility, analyzed the correlation with the common assumptions of the cause of incivility (i.e., arguments, contributors, and topics), and assessed the discoursal causes and consequences of developers' and maintainers' uncivil interactions. as a result, we found that incivility is common in code review discussions of rejected patches of the linux kernel. we also found that frustration, name calling, and impatience are the most frequent features in uncivil emails. besides that, our results indicate that there are civil alternatives to address arguments, and that uncivil comments can potentially be made by any people when discussing any topic. finally, we found the main causes and consequences of uncivil communication for both developers and maintainers. previous work have found that interpersonal conflicts and toxicity are rare on google's code review discussions and on github projects with \"too heated\" conversations , but they have negative consequences when they occur. based on this evidence, we decided to first characterize incivility by analyzing the linux community, which has been criticized for using harsh language, giving frequent rejections, and negative feedback . because software development is essentially a communication-intense activity, incivility can arise in any community and development stage. however, the results found in this study may not be generalized to other communities or other software development activities. hence, we suggest that future research investigate the potential generalizability of our findings in other open source and industrial projects. additionally, not all causes and consequences of incivility are visible in public code review discussions. an in-depth investigation of the community members' experience and perception of incivility would be helpful to address this problem. we believe that the findings of this work will pave the way for further studies in software development that aim to analyze incivility and promote civil communication. more specifically, the causes and consequences of incivility found in this study are crucial for devising strategies to handle incivility during code review. even though many approaches exist to prevent incivility, such as the code of conduct , these approaches do not treat the root of the problem. for"}
{"id": 2888, "date": "2021-09-03", "title": "Effects of interactivity and presentation on review-based explanations for recommendations", "url": "https://arxiv.org/abs/2105.11794v2[cs.HC]", "keywords": ["Recommender systems", "explanations", "user study", "user characteristics"], "abstract": "ser reviews have become an important source for recommending and explaining products or services. particularly, providing explanations based on user reviews may improve users' perception of a recommender system (rs). however, little is known about how reviewbased explanations can be effectively and efficiently presented to users of rs. we investigate the potential of interactive explanations in reviewbased rs in the domain of hotels, and propose an explanation scheme inspired by dialog models and formal argument structures. additionally, we also address the combined effect of interactivity and different presentation styles (i.e. using only text, a bar chart or a table), as well as the influence that different user characteristics might have on users' perception of the system and its explanations. to such effect, we implemented a review-based rs using a matrix factorization explanatory method, and conducted a user study. our results show that providing more interactive explanations in review-based rs has a significant positive influence on the perception of explanation quality, effectiveness and trust in the system by users, and that user characteristics such as rational decisionmaking style and social awareness also have a significant influence on this perception.", "rq": ["rq 1: how do users perceive review-based explanations with different degrees of interactivity, in terms of explanation quality, and of the transparency, efficiency and trust in the system?", "rq 2: how do different presentation styles influence users' perception of review-based explanations with different degrees of interactivity?", "rq 3: how do individual differences in decision-making styles, social awareness or visualization familiarity moderate the perception of review-based explanations with different degrees of interactivity and presentation styles?"], "relatedWork": "elated work: review-based explanatory methods leverage user generated content, rich in detailed evaluations on item features, which cannot be deduced from the general ratings, thus enabling the generation of more detailed explanations, compared to collaborative filtering (e.g. \"your neighbors' ratings for this movie\" ) and content-based approaches (e.g. ). review-based methods allow to provide: 1) verbal summaries of reviews, using abstractive summarization from natural language generation (nlg) techniques , 2) a selection of helpful reviews (or excerpts) that might be relevant to the user, detected using deep learning techniques and attention mechanisms , 3) a statistical view of the pros and cons of item features, usually using topic modelling or aspect-based sentiment analysis , information that is integrated to rs algorithms like matrix or tensor factorization ) to generate both recommendations and aspect-based explanations. our evaluation is based on the third approach, and is particularly related to the model proposed by , since it facilitates getting statistical information on users' opinions, which has been proven to be useful for users , and can be provided in explanations with different presentation styles (strictly verbal or visual). yet, the optimal way of presenting such information, either in a textual (short summaries) or a graphical form (e.g., different types of bar charts) remains unclear. in addition to information display factors, a second factor could also influence users' perception of the explanations: the possibility of interacting with the system, to better understand the rationale for its predictions. interactive explanations have been already addressed in the field of explainable artificial intelligence (xai) (although to a much lesser extent compared to static explanations ). here, the dominant trend has been to provide mechanisms to check the influence that specific features, points or data segments may have on the final predictions of a machine learning (ml) algorithm, as in the work of . however, despite the progress of xai interactive approaches, their impact and possibilities in explainable rs remain largely unexplored, as well as the empirical validation of their effects on users. more specifically, the dominant ml interactive approach differs from ours in at least two ways: 1) we use non-discrete and non-categorical sources of information, subjective in nature and unstructured, which, however, can be used to generate both textual and visual structured arguments 2) such approach is designed to meet the needs of domain experts, i.e. users with prior knowledge of artificial intelligence, while we aim to target the general public. therefore, we explore in this paper an interactive explanation approach that facilitates the exploration of arguments that support claims made by the system (why an item is recommended). to this end, we adopted the definition of interactivity stated by steuer : \"extent to which users can participate in modifying the form and content of mediated environment in real time\", and characterized the degree of interactivity of proposed explanations through the liu and shrum dimensions of interactivity : active control and two-way communication. the first is characterized by voluntary actions that can influence the user experience, while the second refers to the ability of two parties to communicate to one another. active control is reflected in our proposal by the possibility to use hyperlinks and buttons, that allow users to access explanatory information at different levels of detail at will, while two-way communication is represented by the ability to indicate the system (through pre-defined questions) which are their most relevant features, so the presentation of the explanatory content (answers) is adjusted accordingly. in order to formulate and test an interactive flow for review-based explanations, we set our focus on argumentative models that may enable the two-way communication desideratum. in contrast to static approaches to explanation, dialog models have been formulated conceptually , allowing arguments over initial claims in explanations, within the scope of an interactive exchange of statements. despite the potential benefit of using these models to increase users' understanding of intelligent systems , their practical implementation in rs (and in xai in general) still lacks sufficient empirical validation . this dialogical approach contrasts with other argumentative -though staticexplanation approaches based on static schemes of argumentation (e.g. ), where little can be done to indicate to the system that the explanation has not been fully understood or accepted, and that additional information is still required. consequently, we formulated a scheme of interactive explanations in review-based rs, combining elements from dialogue models and static argument schemes (section 3), and conducted a user study to test the effect of the proposed interactive approach. effects of interactivity have been studied widely in fields like online shopping and advertising , and more specifically in the evaluation of critique-based rs, where users are able to specify preferences for the system to recalculate recommendations, which has been found to be beneficial for user experience . despite the intuitive advantages that interactivity can bring, interactivity does not always translate into a more positive attitude towards the system, since it also depends on the context and the task performed . nevertheless, it has also been shown that higher active control is beneficial in environments involving information needs, and a clear goal in mind , which is actually our case (i.e. deciding which hotel to book). furthermore, we hypothesized (in line with ) that a number of user characteristics may moderate the effect of interactive functionalities, on the perception of explanations. particularly, we aimed to test the moderating effect of decision-making styles and social awareness. in regard to the former, research has shown that it is determined significantly by preferences and abilities to process available information . particularly, we believe that users with a predominant rational decision making style would better perceive explanations with a higher degree of interactivity, than explanations with less possibility of interaction, given their tendency to thoroughly explore information when making decisions . on the other hand, more intuitive users may not find the interactive explanations very satisfactory, given their tendency to make decisions through a quicker process , so that a first explanatory view would be sufficient, and it would not be necessary to navigate in depth the arguments that the system can offer. as for social awareness, and in line with results reported by , we hypothesize that users with a higher social awareness may perceive explanations with higher interactivity more positively, given their tendency to take into account the opinions of others, and to adjust their own using those of others, while choosing between various alternatives , which has been proved to be beneficial during decision making , and is facilitated by our approach. finally, in regard to presentation styles, visual arguments (a combination of visual and verbal information) may have a greater \"rhetorical power potential\" than verbal arguments, due (among others) to their greater immediacy (possibility of quick processing) . this could especially benefit users with a predominantly intuitive decision-making style, due to their usually quick manner of making decisions, based mostly on first impressions . however, users with lower visual abilities might benefit less from a presentation based on images or graphics . consequently, we believe that when exposed to graphic-based explanation formats, higher interactive explanations may be beneficial to users with lower visual familiarity, as they could access additional information to better understand the explanations provided.", "conclusion": "<title>conclusions and future work</title> in this paper, we have presented a scheme for explanations as interactive argumentation in review-based rs, inspired by dialogue explanation models and formal argument schemes, that allows users to navigate from aggregated accounts of other users' opinions to detailed extracts of individual reviews, in order to facilitate a better understanding of the claims made by the rs. we tested an implementation of the proposed scheme in the hotels domain, and found that more interactive explanations contributed to a more positive perception of effectiveness and trust in the system. we also found that individual differences in terms of user characteristics (e.g. decision-making style, social awareness and visualization familiarity) may lead to differences in the perception of the proposed implementation. while our proposal suggests a first step towards an effective implementation of interactive explanations for review-based rs, some important improvements can still be considered, to increase users' perception of transparency, as pointed out in the previous section. here, the provision of links with predefined why, how or what questions, while practical, could be improved, for example, with the possibility for the user to ask more flexible questions, even in natural language. thus, as future work, we plan to leverage advances of conversational agents (i.e. chatbots), natural language processing and natural language generation techniques, such as question answering and automatic summarization, to enhance the implementation proposed in this paper. it is important to note that our scheme entails an explanatory dialogue on a single-item level. however, we plan in the future to investigate the effect of contrastive dialogue-based explanations of the type \"why p rather than not-p?\". in this respect, we believe that this type of explanation can be leveraged to enable users further possibilities to influence the recommendation process itself, e.g. requesting for a more refined set of recommendations that better suit their preferences, based on an explanatory contrast between the different options. the above might result in greater satisfaction with the overall system, as has been proven with interactive rs in the past, but this time from the explanations as such."}
{"id": 2905, "date": "2021-09-13", "title": "Developers Who Vlog: Dismantling Stereotypes through Community and Identity", "url": "https://arxiv.org/abs/2109.06302v1[cs.SE]", "keywords": ["vlogs", "YouTube; stereotypes", "developer life"], "abstract": "evelopers are more than \"nerds behind computers all day\", they lead a normal life, and not all take the traditional path to learn programming. however, the public still sees software development as a profession for \"math wizards\". to learn more about this special type of knowledge worker from their first-person perspective, we conducted three studies to learn how developers describe a day in their life through vlogs on youtube and how these vlogs were received by the broader community. we first interviewed 16 developers who vlogged to identify their motivations for creating this content and their intention behind what they chose to portray. second, we analyzed 130 vlogs (video blogs) to understand the range of the content conveyed through videos. third, we analyzed 1176 comments from the 130 vlogs to understand the impact the vlogs have on the audience. we found that developers were motivated to promote and build a diverse community, by sharing different aspects of life that define their identity, and by creating awareness about learning and career opportunities in computing. they used vlogs to share a variety of how software developers work and live-showcasing often unseen experiences, including intimate moments from their personal life. from our comment analysis, we found that the vlogs were valuable to the audience to find information and seek advice. commenters sought opportunities to connect with others over shared triumphs and trials they faced that were also shown in the vlogs. as a central theme, we found that developers use vlogs to challenge the misconceptions and stereotypes around their identity, work-life, and well-being. these social stigmas are obstacles to an inclusive and accepting community and can deter people from choosing software development as a career. we also discuss the implications of using vlogs to support developers, researchers, and beyond. ccs concepts: \u2022 social and professional topics \u2192 computing profession; \u2022 human-centered computing \u2192 empirical studies in collaborative and social computing; \u2022 software and its engineering \u2192 collaboration in software development;", "rq": ["rq 1: what are developer motivations and intentions for creating 'day in the life' vlogs?", "rq 2: what content do developers share?", "rq 3: what kind of interaction happens around these videos?"], "relatedWork": ": youtube is a video platform that hosts more than 26 billion videos covering topics from entertainment to education. the people involved in creating these videos, the viewers and their interaction with the content, and the range of content available makes youtube an interesting subject for researchers. in the past decade, researchers have studied the structure and working of youtube's different components like recommendation algorithms, views and comment, with the intention of improving the features through automation and ml . others have studied youtube from the social lens, how youtube can generate open, authentic communities with participatory culture and the effect on these communities in different directions like benefits and challenges of using youtube for education , effect of social networking among youth , impact on propagating healthcare information etc. however, the impact of youtube videos on the software engineering community has largely been explored based on technical videos curated for educations purposes. online videos have been helpful for learning new technical content. for example, technical content being available as interactive lessons through moocs have been helpful with teaching technical content in large course settings . however, moocs often leave out the applied experience of what it means to us what was learned in practice. more specifically, how it will be in practice or if it will at all. in fact the low completion rates of moocs demonstrate that they are transferring into increased labor market value . however, these online videos are missing the practicality of what is being shared, creating a lack of confidence among viewers regarding the applicability.", "conclusion": "<title>conclusion</title> through vlogs, developers showcase themselves as more than nerds who work behind computers all day. they share technical knowledge and professional experiences as well as rare moments of their personal lives that resonate with their viewers and inform them at the same time. we found that vlogs were a means to help developers breakdown the misconceptions and pessimistic perspectives to a career in software development. through vlogs, developers advocate for a diverse community of developers from different educational backgrounds and professional journeys. from the comments we found that these vlogs provided a community of support where people bonded over shared experiences breaking the mold of what a software developer can be. we discuss the types of perspectives developers share to address stereotypes around their identity, work, and personal life. we also outline est practices and implications for content creators, video sharing platforms, and research. in studying mechanisms where software developers control the narrative of their profession, we learn more about how technical workers use online platforms to challenge stereotypes and inspire a diverse generation of knowledge workers."}
{"id": 2919, "date": "2021-09-20", "title": "NudgeCred: Supporting News Credibility Assessment on Social Media Through Nudges", "url": "https://arxiv.org/abs/2108.01536v2[cs.HC]", "keywords": ["Social Media", "Twitter", "Nudge", "News", "Credibility", "Misinformation", "Fake News", "Intervention", "Heuristic", "Bandwagon"], "abstract": "struggling to curb misinformation, social media platforms are experimenting with design interventions to enhance consumption of credible news on their platforms. some of these interventions, such as the use of warning messages, are examples of nudges-a choice-preserving technique to steer behavior. despite their application, we do not know whether nudges could steer people into making conscious news credibility judgments online and if they do, under what constraints. to answer, we combine nudge techniques with heuristic based information processing to design nudgecred-a browser extension for twitter. nudgecred directs users' attention to two design cues: authority of a source and other users' collective opinion on a report by activating three design nudges-reliable, questionable, and unreliable, each denoting particular levels of credibility for news tweets. in a controlled experiment, we found that nudgecred significantly helped users (n=430) distinguish news tweets' credibility, unrestricted by three behavioral confounds-political ideology, political cynicism, and media skepticism. a five-day field deployment with twelve participants revealed that nudgecred improved their recognition of news items and attention towards all of our nudges, particularly towards questionable. among other considerations, participants proposed that designers should incorporate heuristics that users' would trust. our work informs nudge-based system design approaches for online media. ccs concepts: \u2022 human-centered computing \u2192 human computer interaction (hci); empirical studies in hci ; user studies;", "rq": ["rq 1:. can heuristic-based design nudges on an online social news feed help users distinguish between reliable, questionable, and unreliable information?"], "relatedWork": "s 2.1 designing for information credibility: at present, social media platforms are taking three approaches to combat misinformation-removing misinformation, reducing their reach, and raising awareness . the first line of action falls under the practices of crowdsourced (in-house and community-driven) and technology-assisted moderation by enforcing established community guidelines . the second approach involves reviews from fact-checking services followed by downranking and the application of warning/correction labels . the third approach largely focuses on contextualizing misleading content through design interventions, such as providing source transparency , prioritizing content from trusted authorities , and showing related news stories from various sources . some of these interventions also target particular issues (e.g., voting ) or particular interactions (e.g., message forwarding ). while contextualizing with additional information has its benefits, producing unsorted information only adds to the confusion . in this regard, we simplify design cues to aid users in distinguishing news coming from mainstream and non-mainstream news sources. aside from these platform-led efforts, researchers have also taken up the challenge of designing tools to aid in assessing information credibility. these works span several approaches, including fact-checking systems, interventions, media literacy programs and games . there are multiple scholarly efforts for computationally assessing content credibility . there are some scholarly works on establishing appropriate credibility signals for online content, as well as on designing guides for labeling manipulated media . some works examine particular crowd-led credibility labeling, including ratings by partisan crowds and the relationship between ratings from crowds and experts . compared to actively seeking labels from the crowd, our work uses both authoritative sources of information as well as passive crowd interaction with content for labelling content credibility in nudgecred. this combination helps us overcome the scale issue regarding recruiting quality crowd workers for active labelling. scholars have employed multiple types of messages as interventions against misinformation, including theory-centered messages , warning messages , corrective messages , and opposing argument messages . studies examined the efficacy of interventions in various genres of news, including public health and politics . some research examined the effectiveness of interventions across countries . others examined effects for interventions across time by offering real-time correction versus delayed retraction . real-time correction tools utilize various strategies, including mining databases of well-known fact-checking websites (such as, snopes and politifact) or crowdsourcing fact-checking. paynter and colleagues looked into how to strategize corrections by combining several existing techniques (e.g., salience of a graphical element in a warning); they call this approach \"optimized debunking\" . some suggest that while corrections can be effective, they can also backfire by inadvertently provoking users into attitude-consistent misperceptions . however, others were unable to replicate such backfiring effects . warnings about information credibility have been more successful than corrections and are not prone to the same backfiring effect . while there are various methods (e.g., warnings, reminders, and default options ) to operationalize nudges, we utilize warnings in nudgecred.", "conclusion": "<title>conclusion</title> in this study, we provide evidence that a nudge-based design that directs users' attention to specific social cues on the news can affect their credibility judgments. we used three nudges: reliable, applied to mainstream news tweets without questions in replies; questionable, applied to mainstream news tweets with questions in replies; and unreliable, applied to non-mainstream news tweets. our experiment suggests that users who saw tweets with reliable nudge as more credible, and tweets with questionable and unreliable nudges as less credible compared to the control users. moreover, our nudges were not affected by users' political preferences, political cynicism, and media skepticism. through interviews, we found evidence of how nudges can impact users' news consumption and how the current design can be improved. this research proposes further exploration of nudge-based system design approaches for online platforms."}
{"id": 2945, "date": "2021-10-04", "title": "Human-Imitating Metrics for Training and Evaluating Privacy Preserving Emotion Recognition Models Using Sociolinguistic Knowledge", "url": "https://arxiv.org/abs/2104.08792v2[cs.CL]", "keywords": [], "abstract": "privacy preservation is a crucial component of any real-world application. but, in applications relying on machine learning backends, privacy is challenging because models often capture more than what the model was initially trained for, resulting in the potential leakage of sensitive information. in this paper, we propose an automatic and quantifiable metric that allows us to evaluate humans' perception of a model's ability to preserve privacy with respect to sensitive variables. in this paper, we focus on saliency-based explanations, explanations that highlight regions of the input text, to infer internal workings of a black box model. we use the degree with which differences in interpretation of general vs privacy preserving models correlate with sociolinguistic biases to inform metric design. we show how certain commonly-used methods that seek to preserve privacy do not align with human perception of privacy preservation leading to distrust about model's claims. we demonstrate the versatility of our proposed metric by validating its utility for measuring cross corpus generalization for both privacy and emotion. finally, we conduct crowdsourcing experiments to evaluate the inclination of the evaluators to choose a particular model for a given purpose when model explanations are provided, and show a positive relationship with the proposed metric. to the best of our knowledge, we take the first step in proposing automatic and quantifiable metrics that best align with human perception of model's ability for privacy preservation, allowing for cost-effective model development.", "rq": ["rq 3: how can we quantify this difference to obtain a metric that is a proxy for human judgement of the goodness of privacy preservation -one that encodes both the model's ability to avoid private variable leakage and a person's belief that the model preserves privacy?", "rq 4: is the proposed metric versatile for quantifying human trust in other tasks beyond privacy preservation?"], "relatedWork": "elated work: model interpretability is a critical component of machine learning systems that are designed to interact with humans. models that are interpretable have the ability to explain why they are making decisions, or in the context of privacy, why users should have faith that they are preserving users' sensitive information. we divide our related work section into three parts: 1) privacy preservation or debiasing, 2) interpretability methods, and 3) human trustworthiness.", "conclusion": "<title>conclusion</title> we study how interpretation mechanisms can be used to evaluate privacy preserving models. and how they can be used to inform metric design that correlates with humans' perception of model's ability for a given task. we analyse patterns in interpretation differences that are introduced due to an additional constraint of privacy preservation. and look at how this difference can be directionally correlated with known sociological indicators of gender to inform our metric design. we conduct crowdsourcing studies to validate that this metric is representative of humans' perception of model's ability for privacy preservation. finally, we show how the same metric design concept can be used for measuring generalization capability for both emotion recognition performance and privacy preservation in cross-corpus settings."}
{"id": 2972, "date": "2021-10-13", "title": "Alexa, in you, I trust! Fairness and Interpretability Issues in E-commerce Search through Smart Speakers", "url": "https://arxiv.org/abs/1801.03604", "keywords": ["e-commerce", "search", "interpretabity", "explanation", "fairness"], "abstract": "n traditional (desktop) e-commerce search, a customer issues a specific query and the system returns a ranked list of products in order of relevance to the query. an increasingly popular alternative in e-commerce search is to issue a voice-query to a smart speaker (e.g., amazon echo) powered by a voice assistant (va, e.g., alexa). in this situation, the va usually spells out the details of only one product, an explanation citing the reason for its selection, and a default action of adding the product to the customer's cart. this reduced autonomy of the customer in the choice of a product during voice-search makes it necessary for a va to be far more responsible and trustworthy in its explanation and default action. in this paper, we ask whether the explanation presented for a product selection by the alexa va installed on an amazon echo device is consistent with human understanding as well as with the observations on other traditional mediums (e.g., desktop ecommerce search). through a user survey, we find that in 81% cases the interpretation of 'a top result' by the users is different from that of alexa. while investigating for the fairness of the default action, we observe that over a set of as many as 1000 queries, in \u224868% cases, there exist one or more products which are more relevant (as per amazon's own desktop search results) than the product chosen by alexa. finally, we conducted a survey over 30 queries for which the alexa-selected product was different from the top desktop search result, and observed that in \u224873% cases, the participants preferred the top desktop search result as opposed to the product chosen by alexa. our results raise several concerns and necessitates more discussions around the related fairness and interpretability issues of vas for e-commerce search. 1\u2022 human-centered computing \u2192 collaborative and social computing design and evaluation methods.", "rq": ["rq-1: how do users interpret the explanations given in the audio response by vas?"], "relatedWork": "s: intelligent voice assistants: several prior works have showed the impact of the voice and information quality of vas having positive effect on consumer trust and further willingness to use these systems . security and privacy risks associated with vas have also been investigated , calling for better diagnostic testings to ensure more trustworthy vas. several cognitive biases (e.g., priming and anchoring biases) during the interaction of vas and customers have also been studied in prior works . while these prior works discuss about some important aspects, none of them investigates the understanding of humans about the framing of different responses by vas (which we do in this work). bias and unfairness in information access systems: a rich vein of studies have focused on issues related to fairness of information access algorithms, ranging from individual fairness to group fairness . cognitive biases due to nudges from information access system have been investigated in multiple studies as well . the current work is a suitable amalgamation of studying interpretation (from cognitive viewpoint) and fairness issues (from the perspectives of producers, and customers ) due to responses provided by alexa systems upon different e-commerce search queries.", "conclusion": ""}
{"id": 2985, "date": "2021-10-13", "title": "An Exploration of Reddit's Advice Communities", "url": "https://arxiv.org/abs/2008.09094", "keywords": [], "abstract": "dvice forums are a crowdsourced way to reinforce cultural norms and moral behavior. sites like reddit contain massive amounts of natural language human interaction, with rules and norms unique to each individual subreddit community. to explore this data, we created a dataset with top 1000 posts from each of two such forums, r/amitheasshole and r/relationships, and extracted natural language features including sentiment, similarity, word frequency, and demographics using both algorithmic and manual methods. further, we developed a method to extract demographic information from the subreddits, examined how the post authors' self-disclosures reflect the unique communities in which their posts are shared, and discussed how the authors' language use choices might be related to broader social patterns. we observed some differences between the subreddits in terms of word frequency, demographics disclosure, and gendered language. in general, both subreddits had more female posters than male, and posters tended to use more words about their opposite gender than the same. gender-diverse posters were uncommon. implications for future research include a more careful, inclusive focus on identity and disclosure and how that interacts with advice-seeking behavior in online communities.", "rq": ["rq 1: what natural language features can we extract from unstructured reddit posts?", "rq 2: how do online communities with specific and similar interests compare in terms of their natural language features, such as sentiment scores and high frequency words?", "rq 3: is there any correlation between a post\\'s natural language features and its engagement metrics?"], "relatedWork": "background and related works: the value of social media sites as an information resource is well established. on a surface level, various social media sites including facebook, twitter, reddit, and numerous others appear relatively similar. however, each site contains information flows that dictate the depth, truthfulness, and originality of interactions. cinelli et al. (2021) explored the frequency of echo chambers across different social media platforms, finding that facebook and twitter are more prone to siloed information exchanges. choi et al. (2016) compared social media sites to learn their individual qualities as resources for analysis. they measured frequency of posting, presence of external links, and uniqueness of word usage. these types of analysis provide a framework for selecting the appropriate social media site for a given research question. among the major social media platforms, reddit is a particularly rich resource. while reddit communication remains entirely digital, nevard (2018) suggested that reddit is a public sphere that extends beyond the boundaries of the reddit environment and influences individuals as they interact with society at large. yadav et al. (2021) highlighted the absence of marketing schemes on reddit, as individual users can report spam. this feature of reddit ensures the genuineness of the individuals by reducing incentives for profit and discouraging misaligned motivations. another key feature of reddit is the presence of metadata provided by the author of the posts. this often appears in a shorthand format that can be extracted using natural language processing tools (haworth et al., 2021) . collisson et al. (2018) highlighted this feature, and concluded that reddit \"seems to be an ideal source of real-world, dyadic data from people seeking and offering relationship advice\" (collission et al., 2018, p. 302). reddit is built upon a vast and diverse ecosystem of subreddits. the benefits of reddit as a data source are common across many of these subreddits, and it is common for researchers to draw on individual subreddits to collect social media data that fits the criteria for their work. for example, collisson et al. (2018) specifically examined the subreddit called r/relationships where posters seek individualized relationship advice. the subreddit r/amitheasshole is an immensely valuable expression of human morality and ethics that proves useful across multiple domains of study, including gender, psychology, ethics and morality, human computer interaction, and sociology. o'brien (2020) created a public dataset of r/amitheasshole posts to support such explorations. studies examining gender differences on reddit endeavor to profile the experiences and behaviors of different gender groups across the site. this type of profiling could lead to improved understanding of gender dynamics transferable to a broad range of social interactions. thelwall & stuart (2019) found gender differences in participation rates across different subreddits. flesch (2019) established the practice of collecting gender information from posters' self-declaration, and confirmed the value of extracting linguistic features from the reddit corpora to understand gender differences as they relate to different discussion themes. while these works capture gender participation within the reddit ecosystem, li et al. (2019) replicated established gender theories in anonymous digital communities. their results showed a connection between emotional disclosures and assumptions of female identity. the anonymity present on reddit creates a unique space where posters are often willing to disclose personal experiences more candidly than normal. this creates a vast collection of personal accounts that psychologists can use to research the human mind using unobtrusive methods. curiskis et al. (2007) studied data processing techniques to improve the usability of such data, because a careful analysis of linguistic features can reveal significant insight into the cognition and emotion of both posters and commenters . jaerch et al. (2015) investigated the relationship between user reputation and engagement on the site. the possibility of transferring results across subreddits is a persistent theme in the literature. most notably, botzer et al. (2021) classified the moral judgements of r/amitheasshole, then applied that knowledge to numerous other subreddits. their results revealed characteristics of individual posters whose behavior is deemed to have a negative morale valence. botzer et al.'s (2021) work is relevant from a psychological perspective, but also as an example of the value of reddit for designing artificial intelligence. the r/amitheasshole subreddit asks participants to tag the original posts as a judgement of the original poster's behavior. in addition to botzer et al. (2021) , zhou et al. (2021) and lourie et al. (2021) utilized r/amitheasshole for the development of machine learning systems that classify or generate ethical decisions.", "conclusion": "<title>conclusions and future work</title> in this work, we developed a methodology to extract demographic information from a social media site where user demographics are neither always shared, nor presented in a structured format. we investigated what natural language features could be extracted from unstructured reddit post text, compared two advice-oriented subreddits in terms of those features, and looked for correlations between language features and engagement metrics. the features we extracted included sentiment, similarity, word frequency, and in-text demographics. we examined how the post authors' self-disclosures reflect the unique communities in which their posts are shared and how the authors' language use choices might be related to broader social patterns. we found some differences between r/amitheasshole and r/relationships, especially in terms of word frequency, demographics disclosure, and gendered language, but nothing significant in terms of sentiment or overall similarity. a more in-depth analysis of parts-of-speech tagging seems like the best path forward in terms of text analysis. we obtained the most common verbs and nouns found in the top 1000 posts of each of the r/relationships and r/amitheasshole subreddit communities, which could be a practical tool to help the scholarly community identify and compare high frequency words in other advice forums in future studies. our observations on the differences in aggression and interiority of different subreddits could inspire future studies to explore how posters' perceived locus of control and relational depth influences their query formulation. while these topics fall outside the scope of this study, future researchers could examine additional online advice communities, improve demographics extraction methods, and perform more detailed parts of speech tagging and token analyses of posts' text to look for patterns. this study is limited in that it relies on a one-time scraping of \"top\" reddit posts that may be biased in favor of higher engagement. it does not attempt to account for time or over-sample for certain areas of interest that are unbalanced, like flair and gender diversity. we did not collect comments or user metadata, so it cannot address a broader look at interactions and networks on reddit. work could take these into account, apply more robust processes to extract demographic information from posts, and identify coding methods for key words and phrases for deeper analysis. we would also love to explore the relationship type between the original poster (op) and subject without relying on assumptions about the gender binary. the scope could be broadened to include other relationship-and behavior-centric forums to explore how different communities create and share information about ethical decision-making and human behavior. another aspect to explore is the \"memeification\" of the posts in these forums, that is, how posts in some subreddits are captured and shared on other social media networks, which may further reflect cultural values and acceptable behaviors."}
{"id": 3003, "date": "2021-10-13", "title": "Do Bots Modify the Workflow of GitHub Teams?", "url": "", "keywords": [], "abstract": "he ever-increasing complexity of modern software engineering projects makes the usage of automated assistants imperative. bots can be used to complete repetitive tasks during development and testing, as well as promoting communication between team members through issue reporting and documentation. although the ultimate aim of these automated assistants is to speed taskwork completion, their inclusion into github repositories may affect teamwork as well. this paper studies the question of how bots modify the team workflow. we examined the event sequences of repositories with bots and without bots using a contrast motif discovery method to detect subsequences that are more prevalent in one set of event sequences vs. the other. our study reveals that teams with bots are more likely to intersperse comments throughout their coding activities, while not actually being more prolific commenters.", "rq": ["rq 2: how do bots affect the team contrast motifs?"], "relatedWork": ". related work a. bots: storey et al. provided a framework to examine the impact of bots on software development teams by categorizing bot roles and their effectiveness in helping developers meet their goals . the authors urged the research community to study the impact of bots, positive or negative. since then, research on the impact of automation has grown significantly. a study on arxiv:2103.09319v1 16 mar 2021 a sample of popular repositories before and after bot adoption found no significant difference in metrics such as time to pull request before and after bot adoption . however, a more recent paper found that the adoption of code review bots increases the number of merged pull request and decreases communication among developers . in addition to considering the effectiveness of bots towards improving taskwork, some authors have examined social interactions between bots and humans. liu et al. found that the stale bot, which helps maintainers triage abandoned issues and pull requests by marking them after a period of inactivity, can create a negative experience for contributors , . this illustrates the importance of research on human-bot interaction towards providing insights on best practices for the development of effective software bots , , . desiderata for automation include improving social interactions, better management of the workflow, and increasing the awareness of the developers about bot capabilities. dey et al. created a bot classifier, biman, for detecting bots in the world of code dataset; their technique focuses on commit activity. here we propose a simpler classifier that is well suited for event data extracted from ghtorrent ; unlike biman, it does not require tracking file modifications.", "conclusion": "<title>v. conclusion and future work</title> this paper studies the following question: how do bots modify the workflow of software engineering teams? for this study, we constructed a bot detection classifier to discover github bots and to identify the repositories that use them. to compare human-bot teams with human only ones, we applied our contrast motif discovery technique to the two groups of sequences. rq1 was answered affirmatively; both human-only and human-bot teams possess contrast motifs that are found predominantly in only one of the groups. our analysis of the contrast motifs indicates that in humanbot teams, issue comments are scattered throughout the event sequences while in human-only teams the contrast motifs are simpler and issue comments tend to be clustered together (rq2). the continuous communication that we observe in human-bot teams could occur due to a lack of situation awareness caused by introduction of automation. we plan to measure and compare the performance of human-bot and human-only teams to understand the impact of automation and communication differences on the outcome of the teams. we hypothesize that teams with bots are more likely to intersperse comments throughout their coding activities, while not actually being more prolific commenters. note that the type of bot obviously affects the workflow. in this study, we aggregated sequences generated by teams using many types of automation. it may be beneficial to do a narrower study examining the effects of a single type of bot. kozlowski et al.'s normative model of team development defines four continuous and overlapping phases: team formation, task compilation, role compilation, and team compilation . in future work, we will extract contrast motifs from different phases of team development in order to compare and contrast the processes in these phases across team types. vi. data availability our dataset is publicly available at: https://osf.io/de6y7/"}
{"id": 3009, "date": "2021-10-13", "title": "Oppenlaender, Jonas, Crowdsourcing creative Work", "url": "", "keywords": ["creative work", "creativity", "creativity support tools", "crowdsourcing"], "abstract": "reative work is launched on paid crowdsourcing platforms, yet we lack an in-depth understanding of how the two key stakeholders of crowdsourcing platforms (crowd workers and requesters) perceive and experience creative work. creativity is a human characteristic that is difficult to automate by machines, and supplying requesters with crowdsourced human insights and complex creative work is, therefore, a timely topic for research. according to value-sensitive design, the integration of human insight into complex socio-technical systems will need to consider the perspectives of the two key stakeholders. this article-based doctoral thesis explores the stakeholder perspectives and experiences of crowdsourced creative work on two of the leading crowdsourcing platforms. the thesis has two parts. in the first part, we explore creative work from the perspective of the crowd worker. in the second part, we explore and study the requester's perspective in different contexts and several case studies. the research is exploratory and we contribute empirical insights using survey-based and artefact-based approaches common in the field of human-computer interaction (hci). in the former approach, we explore the key issues that may limit creative work on paid crowdsourcing platforms. in the latter approach, we create computational artefacts to elicit authentic experiences from both crowd workers and requesters of crowdsourced creative work. the thesis contributes a classification of crowd workers into five archetypal profiles, based on the crowd workers' demographics, disposition, and preferences for creative work. we propose a three-part classification of creative work on crowdsourcing platforms: creative tasks, creativity tests, and creativity judgements (also referred to as creative feedback). the thesis further investigates the emerging research topic of how requesters can be supported in interpreting and evaluating complex creative work. last, we discuss the design implications for research and practice and contribute a vision of creative work on future crowdsourcing platforms with the aim of empowering crowd workers and fostering an ecosystem around tailored platforms for creative microwork.", "rq": ["rq 1:. how do crowd workers perceive creative work on the crowdsourcing platform?", "rq 2:. how do requesters perceive and experience creative work?", "rq 3:. how can we support requesters in evaluating crowdsourced creative work?"], "relatedWork": "1.2 prior work on the perspective of the crowd worker: much of the research on crowdsourcing is conducted with primarily the requester's benefits in mind (martin et al., 2014) and with a focus on incremental improvements in work and data quality (vakharia & lease, 2015). the requester-centred focus of academia largely fails to consider the subjective perspective and work reality of the crowd workers as one of the main stakeholder groups on online crowdsourcing platforms. it is, therefore, not unfounded to ask what crowd workers think about non-routine cognitive work, such as creative work. however, qualitative studies focusing entirely on the perspective of the crowd worker are rare in the literature. first, one line of inquiry to better understand the perspective of the crowd workers is content analysis. crowd workers can be considered as networked individuals who emphatically share their feelings and concerns in communities online (gray, suri, ali, & kulkarni, 2016;yin, gray, suri, & vaughan, 2016). crowd workers, therefore, leave traces on online message boards, such as turker nation3. the content on these online fora can be linguistically analysed. for instance, nouri, wachsmuth, and engels (2020) mined different online forums for problems reported by crowd workers. inter alia, the authors reported on problems in the evaluation of tasks (e.g., unfair rejections) related to the prevalent power dynamics between the requesters and crowd workers on paid 3https://www.reddit.com/r/turkernation/ crowdsourcing platforms. martin et al. (2014) analysed the content of turker nation. among other findings, the authors reported on the crowd workers' view of mturk and the relationship between crowd workers and requesters. second, the subjective experience of crowd workers can be elicited in online surveys. kittur et al. (2013), for instance, collected the perspective of a sample of crowd workers on mturk for their article on the future of crowd work. the \"bill of rights\" (irani & silberman, 2013) and the work by whiting et al. (2017) with prior findings \"that the work experiences of crowdworkers were affected by stressful deadlines and complex requirements in tasks\" and \"dehumanizing crowdwork conditions\" (y. wang, papangelis, lykourentzou, et al., 2020). y. wang, papangelis, saker, et al. (2020) also investigated the experiences of crowd workers in china. the authors found significant differences in the work context, motivation, engagement, and preferences between individual crowd workers and crowd workers in so-called crowd farms. last, the voice of the crowd worker can be collected via tool-supported means. turkopticon by irani and silberman (2013) is an example of a worker-centred collective system that allows crowd workers to rate and review hits and requesters. the tool collects the subjective work experiences of crowd workers. reviews are, however, often shaped by the work reality on the microtask platform (e.g., abusive requesters, unfairly rejected work, or underpayment), and rarely mention creative work.", "conclusion": ""}
{"id": 3051, "date": "2021-10-13", "title": "A Mixed-Methods Analysis of the Algorithm-Mediated Labor of Online Food Deliverers in China", "url": "https://arxiv.org/abs/2107.13509", "keywords": ["labor", "on-demand labor", "gig economy", "algorithm mediation", "algorithmic management"], "abstract": "n recent years, china has witnessed the proliferation and success of the online food delivery industry, an emerging type of the gig economy. online food deliverers who deliver the food from restaurants to customers play a critical role in enabling this industry. mediated by algorithms and coupled with interactions with multiple stakeholders, this emerging kind of labor has been taken by millions of people. in this paper, we present a mixed-methods analysis to investigate this labor of online food deliverers and uncover how the mediation of algorithms shapes it. combining large-scale quantitative data-driven investigations of 100,000 deliverers' behavioral data with in-depth qualitative interviews with 15 online food deliverers, we demonstrate their working activities, identify how algorithms mediate their delivery procedures, and reveal how they perceive their relationships with different stakeholders as a result of their algorithm-mediated labor. our findings provide important implications for enabling better experiences and more humanized labor of deliverers as well as workers in gig economies of similar kinds. ccs concepts: \u2022 human-centered computing \u2192 empirical studies in hci; empirical studies in collaborative and social computing.", "rq": ["rq 0: how is labor like for online food deliverers and what factors are associated with their labor?", "rq 1: how do algorithms mediate the labor of online food deliverers?", "rq 2: how do online food deliverers perceive their relationships with related stakeholders and how are they shaped by the mediation of algorithms?"], "relatedWork": "nd background: in this section, we first introduce labor and the gig economy in cscw, which our work situates as our context. we then review papers concerning algorithm mediation and algorithm management at work, which constitute our major aspects to delve into in this paper. we further discuss previous works on delivery work, highlight the research gaps and illustrate our contributions. we end this section by providing a background of online food deliverers in china, which we take as the case for study.", "conclusion": "<title>conclusion</title> in this paper, we seek to understand the labor in a burgeoning branch of the gig economyonline food delivery platforms in china. combining large-scale data-driven investigations and in-depth interviews, we seek to uncover the labor of online food deliverers whose endeavors are highly mediated by algorithms. our results show the labor of online food deliverers is highly time-dependent, can be influenced by deliverer-related characteristics, and is vastly coupled with and mediated by algorithms, which helps deliverers better accommodate their work but also catalyzes new contextual obstacles. the algorithm-mediated labor also brings novel interaction experiences and cultivates deliverers' nuanced relationships with different stakeholders. based on our discoveries, we further discuss how our work provides novel implications for enabling more human-centric labor of deliverers and even benefit workers in similar gig economy based platforms."}
{"id": 3053, "date": "2021-10-13", "title": "Beyond Virtual Bazaar: How Social Commerce Promotes Inclusivity for the Traditionally Underserved Community in Chinese Developing Regions", "url": "", "keywords": ["social commerce", "inclusive", "underserved", "bazaar", "HCI4D"], "abstract": "he disadvantaged population is often underserved and marginalized in technology engagement: prior works show they are generally more reluctant and experience more barriers in adopting and engaging with mainstream technology. here, we contribute to the hci4d and ictd literature through a novel \"counter\" case study on chinese social commerce (e.g., pinduoduo), which 1) first prospers among the traditionally underserved community from developing regions ahead of the more technologically advantaged communities, and 2) has been heavily engaged by this community. through 12 in-depth interviews with social commerce users from the traditionally underserved community in chinese developing regions, we demonstrate how social commerce, acting as a \"virtual bazaar\", brings online the traditional offline socioeconomic lives the community has lived for ages, fits into the community's social, cultural, and economic context, and thus effectively promotes technology inclusivity. our work provides novel insights and implications for building inclusive technology for the \"next billion\" population.\u2022 human-centered computing \u2192 empirical studies in hci.", "rq": ["rq 1: how does the traditionally underserved community 4 in chinese developing regions engage in social commerce?", "rq 2: how do characteristics of social commerce situate with the traditionally underserved community in chinese developing regions and promote inclusivity?"], "relatedWork": "nd background: in this section, we position our work in the literature of bazaar economy (theoretical basis of the analyses), hci4d (the line of literature we make primary contributions to), and social commerce (our focal subject). we end this section by illustrating the background of the traditionally underserved community in chinese developing regions, which we situate our study in.", "conclusion": "<title>conclusion</title> in this paper, we present an in-depth analysis of the \"counter\" case on chinese social commerce, which successfully engages the traditionally underserved community in chinese developing regions and achieves a great success. we investigate how social commerce enables this high level of inclusivity by qualitatively investigating these people's adoption, product purchases, economic transactions, and social interactions on social commerce. we identify that social commerce acts as and beyond bazaars that the community is familiar with for ages. we illustrate how social commerce adapts to the characteristics of the traditionally underserved community, which facilitates their willingness of engagement and provides satisfying services for them. based on these, we discuss how our findings can implicate future research and design and contribute to more inclusive hci systems."}
{"id": 3064, "date": "2021-10-13", "title": "Meeting Effectiveness and Inclusiveness in Remote Collaboration", "url": "", "keywords": ["Computer-mediated communication", "meeting effectiveness", "meeting inclusiveness", "statistical modeling", "machine learning"], "abstract": "primary goal of remote collaboration tools is to provide effective and inclusive meetings for all participants. to study meeting effectiveness and meeting inclusiveness, we irst conducted a largescale email survey (n=4,425; after iltering n=3,290) at a large technology company (pre-covid-19); using this data we derived a multivariate model of meeting effectiveness and show how it correlates with meeting inclusiveness, participation, and feeling comfortable to contribute. we believe this is the irst such model of meeting effectiveness and inclusiveness. the large size of the data provided the opportunity to analyze correlations that are speci ic to sub-populations such as the impact of video. the model shows the following factors are correlated with inclusiveness, effectiveness, participation, and feeling comfortable to contribute in meetings: sending a pre-meeting communication, sending a post-meeting summary, including a meeting agenda, attendee location, remote-only meeting, audio/video quality and reliability, video usage, and meeting size. the model and survey results give a quantitative understanding of how and where to improve meeting effectiveness and inclusiveness and what the potential returns are. motivated by the email survey results, we implemented a post-meeting survey into a leading computer-mediated communication (cmc) system to directly measure meeting effectiveness and inclusiveness (during covid-19). using initial results based on internal lighting we created a similar model of effectiveness and inclusiveness, with many of the same indings as the email survey. this shows a method of measuring and understanding these metrics which are both practical and useful in a commercial cmc system. by improving meeting effectiveness, companies can save signi icant time and money. improving meeting inclusiveness is hypothesized to improve meeting effectiveness, but also improves the working environment and employee retention at organizations. \uf020 ccs concepts: \u2022 human centered computing \u2192 computer supported cooperative work; empirical studies in collaborative and social computing", "rq": ["rq 1: how much does inclusiveness impact meeting effectiveness?", "rq 2: what makes meetings more or less effective and inclusive?", "rq 3: how is the cmc system impacting meeting effectiveness and inclusiveness?", "rq 4: how can we practically measure meeting effectiveness and inclusiveness in a cmc system?"], "relatedWork": ": meetings have been extensively studied in the academic literature (a recent review is given in ). one method to understand what drives meeting effectiveness is to first create a survey for meeting participants that include parameters considered to be related to effectiveness, and then to analyze the survey to see if the hypotheses are correct. this process is called a meeting design characteristics study. a meeting design characteristics study by leach et al. shows that the agenda, quality of facilities, and ending on time were found to be correlated to perceived effectiveness (n=958 survey). attendee involvement served as a key mediator variable in the observed relationships. another meeting design characteristics study with even more factors is given by cohen et al. for meeting quality (n=367 survey). this study shows the top significant factors for meeting effectiveness are meeting space size, starting promptness, lighting quality, and organization type. allen et al. show that meeting satisfaction predicted employee empowerment, and information availability partially mediated this effect. geimer et al. asked meeting attendees how to improve meeting effectiveness. the results suggest that employees are often invited to meetings of little relevance and many organizers fail to apply fundamental meeting design practices. agendas have been shown to be correlated to meeting quality and meeting effectiveness . similarly, post-meeting summaries (minutes) have been shown to be pacm on human-computer interaction, vol. 5, no. cscw1, article 173, publication date: april 2021. correlated to meeting quality and meeting effectiveness . allen et al. links premeeting discussions with meeting effectiveness. meeting size has been shown in and to be negatively correlated to meeting effectiveness. odermatt et al. showed uncivil meeting behaviors to be negatively correlated to meeting satisfaction and effectiveness. while there has been significant research in better understanding meeting effectiveness, there is no common consensus on how to measure meeting effectiveness. for example, garcia et al. measure meeting effectiveness by the percent of agenda tasks that are completed. standaert et al. provides 19 business meeting objectives and used a survey with a 5-point scale (1: not at all effective to 5: very effective) on how different meeting modalities achieved the business meeting objectives for each of the 19 business meeting objectives. nixon et al. measure meeting effectiveness by two items, goal attainment and decision satisfaction. rogelberg et al. measure meeting effectiveness for meetings in a typical week using a 6 question survey (5-point scale) which include: \"achieving your own work goals\", \"achieving colleagues' work goals\", \"achieving your department-sectionunit's goals\", \"providing you with an opportunity to acquire useful information\", \"providing you with an opportunity to meet, socialize, or network with people\" and \"promoting commitment to what was said and done in the meeting.\" leach et al. measure meeting effectiveness for meetings in a typical week with a 3 question survey (5-point scale): \"achieving your own work goals\", \"achieving your colleagues' goals\" and \"achieving your department's / section's / unit's goals.\" the number of studies that show significant value in video conferencing over audio conferencing is remarkably sparse and mixed. veinott et al. showed that video helps non-native speakers better negotiate than audio-only conferencing. however, habash showed that video added little or no additional benefit over audio-only conferencing for group perception and satisfaction in distributed meetings. instead of measuring a task metric or satisfaction, daly-jones et al. showed that video does improve conversational fluency and interpersonal awareness over audio-only meetings. sellen showed when remote participants join an audio or video conference with a conference room, the conference room participants produced more interruptions and fewer formal handovers of the floor than the remote participants. video did not improve the interruption or handover rate for remote participants compared to audio-only. standaert et al. showed that telepresence systems improved meeting effectiveness over audio and video conferencing systems. tang et al. showed that usage of a video conferencing system drops significantly when the video feature was removed, and analysis showed the video was used to help mediate their interaction and convey visual communication. while there are many studies showing gender bias in speaking and interruption rates , both show that gender is not correlated to meeting effectiveness. triana et al. showed women felt more included when cmc was used before face-to-face meetings compared to doing face-to-face meetings and then cmc meetings; the order of communication media influenced the perceived inclusiveness, which influenced their participation. guo et al. showed that traditional face-to-face meetings outperformed videoconferencing teams when both teams had the same team-building experience. however, a dialogue-based framework can be used to help virtual teams to perform as effectively as traditional face-to-face teams. davidson reviews studies on how trust and member inclusion are communication factors to foster collaboration in teams, though not meetings specifically. there are many guides on how to have inclusive meetings, e.g., , though remarkably no research that we are aware of that actually measure inclusiveness. we are not aware of previous studies on measuring meeting inclusiveness, but inclusiveness has been extensively studied for organizations. ashikali et al. used a large scale (n=10,976) employee survey to build a structural equation model that shows how transformation leadership and diversity management correlate to an inclusive culture of an organization. a six-question survey is used to measure the inclusive culture of an organization. in (chapter 1) ferdman defines a similar set of six experiences of inclusion for organizations. pearce and randel defined a three question survey on measuring team inclusion. rice et al. conducted studies to further show how organizational inclusiveness relates to supervisory inclusiveness, and how that relates to citizenship behavior and affective commitment. in (chapter 17) lukensmeyer et al. provide a list of important characteristics of a meeting that is truly inclusive which we discuss in more detail in section 3.1.2. to our knowledge, there are no previous studies of meeting effectiveness that include meeting inclusiveness, av quality and reliability, remote/local participants, comfortableness in participating, or pre-meeting written communication. in addition to the structural aspects of meetings, which we address in this paper, there has been significant work done on remote collaboration and the non-structural aspects of collaboration. olson provides a summary of recommendations for effective remote collaboration and best practices for remote meetings. woolley studied the collective intelligence of groups and showed that groups with more equal distribution of turn-taking and groups with more equal distributions of gender had a higher collective intelligence. lykourentzou studied how personalities affect crowd-sourced teams and found that teams without a surplus of leader-type personalities exhibited less conflict and their members reported higher levels of satisfaction and acceptance. kulkarni study massive online classes and found that the more geographically diverse the discussion groups, the better the performance of the students. kiesler and sproull studied electronic mail systems and showed how it increased the flow of information in organizations, and in particular reducing social contexts such as location, distance, time, organizational hierarchy, age, and gender. further discussion of these non-structural aspects is given in section 5.", "conclusion": "<title>conclusions</title> in this study, we conducted email and in-client surveys and created multivariate models of the relationships of meeting effectiveness, inclusiveness, comfortableness to contribute, and participation. the model and survey results can be used to answer the research questions given in section 1. the high-level results show that there is significant room for improvement for meetings to be more effective, inclusive, and where everyone feels comfortable participating. some specific guidance for developers of cmc systems is given below: \uf0b7 cmc systems should include surveys to measure meeting effectiveness and inclusiveness, which can be used to build models as shown in this paper to better understand how the cmc system relates to effectiveness and inclusiveness. in addition, the survey can be used in ab tests to measure improvements in the cmc system to improve these metrics. \uf0b7 video usage is correlated with more inclusive meetings. cmc systems should encourage video usage by making them the default modality, nudging users to use video, and reducing barriers to video usage such as reducing bandwidth, ensuring video doesn't degrade audio quality, and reducing fatigue due to poor quality video . \uf0b7 remote participation needs to be significantly improved, especially to help remote participants interrupt and get the speaking floor. \uf0b7 cmc systems need tools to promote including agendas and premeeting readings in meeting invitations, as well as tools to create automatic meeting summaries. \uf0b7 to improve larger meeting participation, cmc systems should not join auto-muted but create reliable/robust noise suppression technology so muting is not needed. \uf0b7 audio/video quality and reliability are critical for effective and inclusive meetings, so cmc systems need to continue improving it until it is shown that the quality and reliability no longer impact effectiveness and inclusiveness. one confound to this study is the company surveyed may not be similar to many other companies or organizations. this can be addressed by running the survey across many different companies and generate one or more multivariate models. there may be different graph structures for different organizations, or possibly just a few general graphs that cover nearly all companies and organizations. as a future area of research, we can use the survey for conducting ab tests to improve meeting effectiveness and inclusiveness by adding new features to our cmc system. the meeting effectiveness model allows for even more understanding of these metrics and will allow us to prioritize which parts of the cmc system to improve to increase meeting effectiveness and inclusiveness, and give feedback to the cmc system user on how to improve the effectiveness and inclusiveness of their own meetings or their organization's meetings. in order to better predict meeting effectiveness and inclusiveness with our model, we plan to increase the input features in the in-client survey model so it is more complete, starting with missing significant features in table 1. in addition, meeting participant attributes need to be included in our model, not just the structural attributes of the meeting. this includes personality attributions of the participants (e.g., is there a surplus of leadertype personalities in the meeting ), geographic location , as well as gender and racial information. based on we expect to see gender bias in meeting participation rates. we are not aware of previous research on racial bias in meeting participation rates, but it would not be surprising to find that these also exist. additional research needs to be done to measure the survey biases such as non-response bias, survey exposure fatigue, telemetry loss bias, and the impact to the survey being anonymous or not. these are all important areas that are required for integrating the survey into a cmc system. this study relies on a short survey that directly measures concepts such as inclusiveness and effectiveness. an alternative approach is to conduct the study with a larger survey with multiple questions targeting such concepts. then inclusiveness and effectiveness and their relations can be inferred using confirmatory factor analysis (cfa) and structural equation models (sem) . this approach needs implementing a prior hypothesis about key contributors to effectiveness and inclusiveness and requires a larger survey which can cause a lower response rate and high non-response bias. it also is not applicable for the in-client survey that enables continuous monitoring of these metrics as key performance indicators of an organization due to the high cognitive load of filling out a large survey at the end of a meeting. however this approach can be used to help further validate the short direct survey method. improving meeting effectiveness and inclusiveness has significant financial benefits to organizations, as well as making their workplace a better environment to collaborate and retain employees. our hope is this research improves the understanding of how to do this, and that future meetings get closer to the goal that all meetings achieve their business goals and that everyone feels included in their meetings."}
{"id": 3071, "date": "2021-10-13", "title": "Humans are not Boltzmann Distributions: Challenges and Opportunities for Modelling Human Feedback and Interaction in Reinforcement Learning", "url": "https://arxiv.org/abs/2009.13649", "keywords": [], "abstract": "einforcement learning (rl) commonly assumes access to well-specified reward functions, which many practical applications do not provide. instead, recently, more work has explored learning what to do from interacting with humans. so far, most of these approaches model humans as being (nosily) rational and, in particular, giving unbiased feedback. we argue that these models are too simplistic and that rl researchers need to develop more realistic human models to design and evaluate their algorithms. in particular, we argue that human models have to be personal, contextual, and dynamic. this paper calls for research from different disciplines to address key questions about how humans provide feedback to ais and how we can build more robust human-in-the-loop rl systems.", "rq": ["rq 1: how do personality factors influence how humans interact with ai systems?", "rq 2: are there measurable personality factors with a clear impact on the human feedback and interaction dynamic to allow for personalization?", "rq 3: how can we quantify prior knowledge and semantic understanding to model interaction dynamics?", "rq 6: how do contextual factors influence individual personality factors, and can they be modeled independently?", "rq 8: can we measure and predict changes in these factors during interaction sequences?", "rq 9: how do personal and contextual factors adapt to changes in the interaction?"], "relatedWork": "elated work: research on human-centered machine learning has borrowed many methods from social science and the humanities to assess human feedback and interaction. however, most of the assumptions made about the reasoning processes, interaction and communication dynamics, as well as the integration of such feedback into learning models has remained unchallenged, lacking effective human-centered evaluations . in this section, we provide a brief overview of types of human-ai interaction, with a specific focus on rl.", "conclusion": "<title>conclusion</title> we reviewed research on human feedback in rl from a human-centered perspective. we argued that current human models used in rl are too simple and that we need better human models if we want to design systems that can learn from humans robustly in the real world. we argued that we need personal, contextual, and dynamic models to design robust rl systems that learn from humans. we hope to start an interdisciplinary discussion around these topics with the goal of building better human models and designing interaction protocols that can work outside of simulations."}
{"id": 3086, "date": "2021-10-13", "title": "What Makes a Good Commit Message?", "url": "https://arxiv.org/abs/1904.08398", "keywords": ["Commit-based software development", "open collaboration", "commit message quality"], "abstract": "key issue in collaborative software development is communication among developers. one modality of communication is a commit message, in which developers describe the changes they make in a repository. as such, commit messages serve as an \"audit trail\" by which developers can understand how the source code of a project has changed-and why. hence, the quality of commit messages affects the effectiveness of communication among developers. commit messages are often of poor quality as developers lack time and motivation to craft a good message. several automatic approaches have been proposed to generate commit messages. however, these are based on uncurated datasets including considerable proportions of poorly phrased commit messages. in this multi-method study, we first define what constitutes a \"good\" commit message, and then establish what proportion of commit messages lack information using a sample of almost 1,600 messages from five highly active open source projects. we find that an average of circa 44% of messages could be improved, suggesting the use of uncurated datasets may be a major threat when commit message generators are trained with such data. we also observe that prior work has not considered semantics of commit messages, and there is surprisingly little guidance available for writing good commit messages. to that end, we develop a taxonomy based on recurring patterns in commit messages' expressions. finally, we investigate whether \"good\" commit messages can be automatically identified; such automation could prompt developers to write better commit messages.", "rq": ["rq 1: to what extent do poorly composed commit messages exist?"], "relatedWork": ": commit messages constitute an important modality in collaborative software development for sharing knowledge among developers and in establishing an audit trail of the evolution of a software project. we discuss prior literature that has focused on understanding and utilizing commit messages and how to automatically generate commit messages. commit messages are a key resource when addressing several software engineering challenges. one stream of research has focused on classifying code changes into different types by utilizing commit messages manually or automatically to assist maintenance . for example, mockus and votta identified three types of commits: adaptive, corrective, and perfective, consistent with swanson's typology of maintenance activities . based on the proposed commit types, numerous classification models have been proposed, and commit messages play an important role . a second stream of research has focused on the measurement of quality of code changes by analyzing commit messages. for example, agrawal et al. studied the evolution of commit quality in five projects by measuring (among others) the number of unique commit messages, and found that the quality of commits declined over time. santos et al. studied the relationship between \"unusual messages\" and code quality in commits, and found that unusual messages correlate with build failures, suggesting that these messages serve as a warning sign. while it is clear that commit messages play an important role in communication among developers, developers may lack time or motivation to craft good commit messages that clearly communicate what is being committed. to address this, several scholars have proposed automatic approaches to automatically generate messages. some of them are rule-based or use predefined templates . for instance, buse and weimer used symbolic execution to generate path predicates between versions of code changes, then populated pre-defined templates and applied summarization transformations to generate commit messages for code changes. two important limitations of these commit messages generated based on templates are (1) a lack of flexibility, and (2) they cannot convey the intent of committing changes, which only exists in a developer's mind until it is written. recent studies rely on advanced techniques, such as information retrieval and deep learning to generate commit messages automatically. these tend to rely on reusing messages of similar code changes. for example, huang et al. calculated syntax, semantic, pre-syntax, and pre-semantic similarities of changed code fragments between two versions to find similar code changes and reuse their messages. while specific models vary in their techniques, a common feature is that they take prior commit messages as a key input. for these information retrieval and deep learning based tools, the quality of the manually written commit message is difficult to guarantee , which may threaten the effectiveness of these tools. a few studies investigated the content of commit messages but mainly focused on specific aspects. for example, alomar et al. explored how developers document their refactoring activities in commit messages, and found that developers tend to explicitly mention the improvement of certain quality attributes and code smells . chahal and saini constructed a model that can judge the quality of commit messages by calculating 11 syntactical measures. text content in other oss development activities has been studied, such as what/how to document when submitting patches and what information is needed in a bug report . the results of our study on the distribution and expression categories of good commit messages and their relationship with maintenance activities can complement prior understanding of what is a good commit message and how to write one. moreover, we propose a good-message identification tool that can be used to prompt developers to write better commit messages and build high-quality datasets for the task of automatically generating commit messages.", "conclusion": "<title>conclusion</title> commit messages play an important role in collaborating software development and evolution. nonetheless, the considerable proportions of low-quality messages in oss projects reflect the difficulties that developers face when writing commit messages, and threaten the effectiveness of existing automatic commit message generation tools. our study explored the distribution and expression patterns of these well-written messages, linked message expression categories to different maintenance activities, and construct several automatic identification models of good commit messages. our study findings can help developers write good commit messages and assist researchers to construct high-quality datasets before generating messages automatically."}
{"id": 3107, "date": "2021-10-13", "title": "3D Virtual Reality vs. 2D Desktop Registration User Interface Comparison", "url": "", "keywords": ["\u2022 Supplementary text \u2022 Tables S1 to S2"], "abstract": "orking with organs and extracted tissue blocks is an essential task in many medical surgery and anatomy environments. in order to prepare specimens from human donors for further analysis, wet-bench workers must properly dissect human tissue and collect metadata for downstream analysis, including information about the spatial origin of tissue. the registration user interface (rui) was developed to allow stakeholders in the human biomolecular atlas program (hubmap) to register tissue blocks-i.e., to record the size, position, and orientation of human tissue data with regard to reference organs. the rui has been used by tissue mapping centers across the hubmap consortium to register a total of 45 kidney, spleen, and colon tissue blocks, with planned support for 17 organs in the near future. in this paper, we compare three setups for registering one 3d tissue block object to another 3d reference organ (target) object. the first setup is a 2d desktop implementation featuring a traditional screen, mouse, and keyboard interface. the remaining setups are both virtual reality (vr) versions of the rui: vr tabletop, where users sit at a physical desk which is replicated in virtual space; vr standup, where users stand upright while performing their tasks. all three setups were implemented using the unity game engine. we then ran a user study for these three setups involving 42 human subjects completing 14 increasingly difficult and then 30 identical tasks in sequence and reporting position accuracy, rotation accuracy, completion time, and satisfaction. all study materials were made available in support of future study replication, alongside videos documenting our setups. we found that while vr tabletop and vr standup users are about three times as fast and about a third more accurate in terms of rotation than 2d desktop users (for the sequence of 30 identical tasks), there are no significant differences between the three setups for position accuracy when normalized by the height of the virtual kidney across setups. when extrapolating from the 2d desktop setup with a 113-mm-tall kidney, the absolute performance values for the 2d desktop version (22.6 seconds per task, 5.88 degrees rotation, and 1.32 mm position accuracy after 8.3 tasks in the series of 30 identical tasks) confirm that the 2d desktop interface is well-suited for allowing users in hubmap to register tissue blocks at a speed and accuracy that meets the needs of experts performing tissue dissection. in addition, the 2d desktop setup is cheaper, easier to learn, and more practical for wet-bench environments than the vr setups.", "rq": ["rq 4: what is the maximum performance level that a user can reasonably achieve, and how many practice tasks are required before performance levels out?"], "relatedWork": "issue registration procedure and prior work: developing a human reference atlas at single-cell resolution requires recording the size, position, and rotation of tissue extracted from living or post-mortem patients-before the tissue is processed for spatially explicit analysis. fig 1a shows a photo of a typical setup: a kidney was butterflied and placed on a dissecting board to capture its size and shape, as well as the size, position, and rotation of a tissue block (outlined in pink) extracted from it. commonly, a computer is close to the dissection work area so data can be entered and uploaded. the documentation of extraction sites is non-trivial as different donors might have organs of different sizes and the number and shape of anatomical structures (e.g., the number of renal pyramids per kidney) might differ across individuals. it is common to use exemplary organs derived from an individual donor's data as a reference. an example is the male left kidney derived from the visible human (vh) dataset published by the national library of medicine (nlm). this 3d model is about 100 mm high (see green y-axis), 60 mm wide (red x-axis), and 40 mm deep (blue z-axis)-see fig 1 , b and c. different procedures exist to capture relevant information; resulting data is submitted to diverse clinical record-keeping systems with different metadata schemas. different organs-e.g., lung , breast , thymus , and pancreas -have rather different needs and are subject to many standard operating procedures (sops) and checklists . a closer look at these sops and checklists developed for different organs by different authors reveals the lack of common procedures and documentation standards. more importantly for hubmap, existing data captures only partial or inconsistent spatial information (i.e., the level of detail at which this information is captured varies across protocols).", "conclusion": "<title>conclusions</title> the were defined by seven experts for the large intestine (five), the heart (53), the left and right kidneys (one each), and the spleen (three) and these extraction sites can be associated with hundreds of tissue blocks that share these locations. going forward, we envision two types of user studies exploring 3d manipulation further. first, we plan to run studies in a more \"in the wild\" setting . this would allow us to consider variables that are hard to test in a lab setting with mostly novice users, and result in more accurate data about user performance and satisfaction in a true production setting. this would likely be a more focused study with a smaller sample of subject matter experts at their place of work (i.e., a wet lab or adjacent data processing facility), and would enable us to evaluate the performance of the 2d desktop rui in a realistic usage scenario. second, it would be valuable to test how interventions could help users improve their performance during the experiment (e.g., between the ramp-up and plateau phases). specifically, we aim to run a study with a \"reflective\" phase where the user sees a visualization of their own performance data from previous tasks before completing a second set of tasks. our goal is to use the human ability to recognize patterns and trends visually to test if different types of interactive data visualizations can help users formulate strategies to improve their performance in terms of position accuracy, rotation accuracy, and completion time. given the detailed telemetry data collected from rui users (especially those in vr), a natural next step would be to add an intervention where users can see their own movement as well as the position and rotation of the tissue and target blocks over time, thus enabling them to detect problems and strategize more efficient solutions for future tasks. we deposited video demos and study materials for this experiment on github (https://github.com/cns-iu/rui-tissueregistration)."}
{"id": 3146, "date": "2021-10-25", "title": "Actions Speak Louder than Listening: Evaluating Music Style Transfer based on Editing Experience", "url": "https://arxiv.org/abs/2110.12855v1[cs.SD]", "keywords": ["Human-centered computing", "neural networks", "music generation", "style transfer", "artificial intelligence"], "abstract": "he subjective evaluation of music generation techniques has been mostly done with questionnaire-based listening tests while ignoring the perspectives from music composition, arrangement, and soundtrack editing. in this paper, we propose an editing test to evaluate users' editing experience of music generation models in a systematic way. to do this, we design a new music style transfer model combining the non-chronological inference architecture, autoregressive models and the transformer, which serves as an improvement from the baseline model on the same style transfer task. then, we compare the performance of the two models with a conventional listening test and the proposed editing test, in which the quality of generated samples is assessed by the amount of effort (e.g., the number of required keyboard and mouse actions) spent by users to polish a music clip. results on two target styles indicate that the improvement over the baseline model can be reflected by the editing test quantitatively. also, the editing test provides profound insights which are not accessible from usual listening tests. the major contribution of this paper is the systematic presentation of the editing test and the corresponding insights, while the proposed music style transfer model based on state-of-the-art neural networks represents another contribution.\u2022 applied computing \u2192 sound and music computing; \u2022 humancentered computing \u2192 empirical studies in hci.", "rq": ["rq 1: can the loading metrics reflect users' experience of editing?", "rq 2: can the loading metrics effectively measure improvement of users' experience?", "rq 4: what is the relationship between users' listening and editing experience?"], "relatedWork": ": music style transfer has been referred to as the style transfer between various semantic domains, such as timbre and instrument transfer in audio , performance rendering from symbolic to audio , and composition style transfer to modify the harmonic, rhythmic or structural attributes of music at the score level , the latest one will be the main focus of this paper. recently, deep learning models have been used in fitting the style of a specific music corpus. neural networks have been widely investigated in symbolic music style imitation, including bachprop , bachbot , coconet , and recent works based on transformer autoencoder and supervised style transfer with synthetic data . quantitative evaluation for music generation is still an open problem . recent studies on music generation typically evaluate their work by combining objective evaluation and user study. objective approaches mostly take the prediction accuracy or loglikelihood (ll) , or the rhythmic, harmonic, structural similarity between the generated results and the training data . subjective approaches or user studies are mostly questionnaire-based listening tests, which list listening samples together with designed questions for the users to evaluate the quality of the listening examples. in other words, such subjective tests focus on listeners' response regarding how good the generated music sounds, in terms of either the scaled rating (e.g., five-point likert scale) or preference (i.e., ab test) comparing several models, and the quality is usually assessed by the 'number of wins' among these models . on the other hand, quantitative user studies from music editors' view are rarely seen. related studies are mostly non-quantitative expert interviews . in a recent study which evaluates the quality of automatic music transcription method for ethnomusicologists , the correlation between the transcription time and user-reported transcription effort is reported, and the results indicate the potential to perform quantitative editing tests for music generation. the evaluation of the melody note detection software tony might be the only one which studied the number of editing actions and editing time as an evaluation criterion. however, its scenario is different from music generation since the music transcription task has a unique ground truth.", "conclusion": ""}
{"id": 3190, "date": "2021-11-26", "title": "Who, What, Why and How? Towards the Monetary Incentive in Crowd Collaboration: A Case Study of Github's Sponsor Mechanism", "url": "https://arxiv.org/abs/2111.13323v1[cs.HC]", "keywords": ["CCS CONCEPTS \u2022 Computer systems organization \u2192 Embedded systems", "Redundancy", "Robotics", "\u2022 Networks \u2192 Network reliability sponsor, donation, GitHub, open source, financial support"], "abstract": "hile many forms of financial support are currently available, there are still many complaints about inadequate financing from software maintainers. in may 2019, github, the world's most active social coding platform, launched the sponsor mechanism as a step toward more deeply integrating open source development and financial support. this paper collects data on 8,028 maintainers, 13,555 sponsors, and 22,515 sponsorships and conducts a comprehensive analysis. we explore the relationship between the sponsor mechanism and developers along four dimensions using a combination of qualitative and quantitative analysis, examining why developers participate, how the mechanism affects developer activity, who obtains more sponsorships, and what mechanism flaws developers have encountered in the process of using it. we find a long-tail effect in the act of sponsorship, with most maintainers' expectations remaining unmet, and sponsorship has only a shortterm, slightly positive impact on development activity but is not sustainable. while sponsors participate in this mechanism mainly as a means of thanking the developers of oss that they use, in practice, the social status of developers is the primary influence on the number of sponsorships. we find that both the sponsor mechanism and open source donations have certain shortcomings and need further improvements to attract more participants.", "rq": ["rq 1: why do individuals participate or not in the sponsor mechanism?", "rq 2: how effective is sponsorship in motivating developer oss activity?", "rq 4: what are the shortcomings of the sponsor mechanism?"], "relatedWork": ": open innovation in science (ois) is a concept, which unifies the two domains of open and collaborative practices in science, i.e., open science (os) and open innovation (oi) . for os, the three pillars are accessibility, transparency, and inclusivity, among which the inclusivity (e.g., citizen science) is directly related to the knowledge production process. for oi, various forms of collaborative practice exist, including crowdsourcing, oss development, etc. regarding these open initiatives, the motivation and incentives of participation has always been the focus of continuous research . although there are different views on the relationship between citizen science, crowdsourcing, and oss development, we follow the relationships described above and present the related work on participation motivation and monetary incentives of the three parts separately.", "conclusion": "<title>conclusion and future work</title> this paper took github's sponsor mechanism as a case study and used a mixed qualitative and quantitative analysis method to investigate four dimensions of the mechanism. regarding why developers participate in the sponsor mechanism, we found that it is mainly related to the use of oss. regarding the mechanism's effectiveness, we found that the sponsor system has only a short-term effect on development activities but that in the long term, there is a slight decrease. we studied who obtains more sponsorships and found that the social status of the maintainer in the community correlates most strongly with this outcome (the more followers, the more sponsorships a developer acquires). regarding the drawbacks of the mechanism, we found that in addition to the shortcomings in its use, participants felt that the sponsor mechanism should better attract and support corporate sponsors. some people thought that the open source donation method needed to be improved to attract more developers to participate. overall, we have explored the correlation between donation behavior and developers in open source communities using the github sponsor mechanism. in future work, we will further explore the following aspects:"}
{"id": 3225, "date": "2021-12-21", "title": "CHAT2CODE: TOWARDS CONVERSATIONAL CONCRETE SYNTAX FOR MODEL SPECIFICATION AND CODE GENERATION, THE CASE OF SMART CONTRACTS A PREPRINT", "url": "https://arxiv.org/abs/2112.11101v1[cs.SE]", "keywords": ["Model-driven Engineering", "Automatic Code Generation", "Chatbots", "Smart Contracts", "Blockchain", "Natural Language Processing"], "abstract": "he revolutionary potential of automatic code generation tools based on model-driven engineering (mde) frameworks has yet to be realized. beyond their ability to help software professionals write more accurate, reusable code, they could make programming accessible for a whole new class of non-technical users. however, non-technical users have been slow to embrace these tools. this may be because their concrete syntax is often patterned after the operations of textual or graphical interfaces. the interfaces are common, but users would need more extensive, precise and detailed knowledge of them than they can be assumed to have, to use them as concrete syntax. conversational interfaces (chatbots) offer a much more accessible way for non-technical users to generate code. in this paper, we discuss the basic challenge of integrating conversational agents within model-driven engineering (mde) frameworks, then turn to look at a specific application: the auto-generation of smart contract code in multiple languages by non-technical users, based on conversational syntax. we demonstrate how this can be done, and evaluate our approach by conducting user experience survey to assess the usability and functionality of the chatbot framework.", "rq": ["rq 1:. what is the overall experience of the participants based on their background?", "rq 2:. what are some current limitations and challenges with the chatbot?", "rq 3:. what are the possible improvements to improve the adaptability of the chatbot?"], "relatedWork": "elated work: this section presents the related work of using chatbot with mde whether it was to generate conceptual models, query models, or developing chatbots. furthermore, we present the related work of auto-generating smart contract artifacts from chatbots or nlp. p\u00e9rez-soler et al. p\u00e9rez-soler et al. investigated the usage of nl with dsl and introduced an approach to automate the generation of chatbot interface from models in p\u00e9rez-soler et al. . this work was evaluated using a real case study of the existing modelling framework. in another work, p\u00e9rez-soler et al. p\u00e9rez-soler et al. proposed the use of chatbots (conversational syntax) to query existing conceptual models. p\u00e9rez-soler et al. p\u00e9rez-soler et al. used the xatkit framework to integrate chatbots with emf-based meta models. conga p\u00e9rez-soler et al. , an mde approach, was proposed to automatically develop chatbots and generate their codes in two platforms dialogflow and rasa. conga also provides a recommendation tool to recommend the best chatbot platform to use based on the system specification. ed-douibi et al. ed-douibi et al. proposed an mde approach to generate chatbots for open data web apis queries. in this work, the xatkit framework was used to generate chatbots that support both direct and guided queries. table 5 summarizes the related work and compares it with our approach. in general, there are few works done in the field of chatbot and mde. most of the discussed related work focuses on generating, querying models, or developing chatbots, while in our approach, we focused on querying and creating instances from models. furthermore, we applied our approach to auto-generating codes from chatbots, in particular smart contract artifacts. there is also related research work in the field of using nlp to domain modeling such as in saini et al. , ibrahim and ahmad , robeer et al. . however, these works focus on analysing text (description) instead of interactive conversation as in our case.", "conclusion": "<title>conclusion</title> in this paper, we investigated the use of chatbots as the concrete syntax for modeling frameworks, illustrate requirements, specify design, and auto-generate codes. we proposed an approach for auto-generating platform-independent codes, in particular smart contract codes, from conversational syntax. moreover, we showcased our methodology with smart contract development and implemented a chatbot framework, icontractbot, for modeling and developing smart contracts. furthermore, we evaluated the chatbot framework in terms of its usability, and functionality based on the user experience study. the results showed that the overall user satisfaction depends on the participant's background. however, 79% of the participants in all groups had an above-average overall experience in using the framework. marcel robeer, garm lucassen, jan martijn em van der werf, fabiano dalpiaz, and"}
{"id": 3226, "date": "2021-12-22", "title": "Design guidelines for narrative maps in sensemaking tasks", "url": "https://arxiv.org/abs/2112.12205v1[cs.HC]", "keywords": ["Narrative Visualization", "Narrative Maps", "Sensemaking", "Text Analytics"], "abstract": "arrative sensemaking is a fundamental process to understand sequential information. narrative maps are a visual representation framework that can aid analysts in their narrative sensemaking process. narrative maps allow analysts to understand the big picture of a narrative, uncover new relationships between events, and model the connection between storylines. we seek to understand how analysts create and use narrative maps in order to obtain design guidelines for an interactive visualization tool for narrative maps that can aid analysts in narrative sensemaking. we perform two experiments with a data set of news articles. the insights extracted from our studies can be used to design narrative maps, extraction algorithms, and visual analytics tools to support the narrative sensemaking process. the contributions of this paper are three-fold: (1) an analysis of how analysts construct narrative maps; (2) a user evaluation of specific narrative map features; and (3) design guidelines for narrative maps. our findings suggest ways for designing narrative maps and extraction algorithms, as well as providing insights towards useful interactions. we discuss these insights and design guidelines and reflect on the potential challenges involved. as key highlights, we find that narrative maps should avoid redundant connections that can be inferred by using the transitive property of event connections, reducing the overall complexity of the map. moreover, narrative maps should use multiple types of cognitive connections between events such as topical and causal connections, as this emulates the strategies that analysts use in the narrative sensemaking process.", "rq": ["rq 1: how do analysts manually construct narrative maps?", "rq 2: how do map size and transitivity affect the utility or effectiveness of the map?"], "relatedWork": "elated work: first, we note that this work is an extended version of a short paper in a visualization conference 21 . the original version included partial results and a more superficial analysis of our results for rq1, focusing on connections types, construction strategies, and graph and layout properties. this extended version includes new insights on rq1, such as event selection and additional features and suggestions proposed by the analysts. furthermore, this version includes rq2, which did not exist in the original publication. finally, this version also includes a series of design guidelines for narrative maps and an in-depth discussion of our results. in the rest of this section, we discuss the existing literature in the field of narrative visualization. in particular, we give a brief introduction to the intersection of narratives and visualization. then, we discuss narrative extraction and representation methods. finally, we discuss works that model cognitive strategies in the sensemaking process.", "conclusion": "<title>conclusions</title> we studied how analysts construct narrative maps and the characteristics of these maps. in particular, our user study detected 7 types of cognitive connections. in particular, we have shown the importance of topical and causal relationships in the construction of narrative maps, as these were the most common high-level connections in the usergenerated maps. in terms of strategies, we found three major ways to construct maps. each one of these strategies can be the basis of a new extraction algorithm. furthermore, in terms of the structure of the map, we saw an even distribution between tree-like maps and dag-like maps. regarding layout, we found that most users preferred a vertical top-down layout (i.e., scrollytelling), with the main story shown first. we also evaluated the effect of map size and transitivity, finding that users preferred long maps without transitive connections. all these results led to a series of design guidelines for narrative maps. these guidelines can be used in the design of new extraction algorithms and interactive visualization tools. future work will deal with the implementation of such algorithms and tools, as well as their evaluation based on the insights gathered in this work. future work could explore how strategies differ when applied to different domains, data set sizes, and analyst experience. in particular, it would be useful to consider how previous analyst training (e.g., experience with structured analytic techniques) could influence the construction strategies or the narrative map structures. finally, as mentioned before, the overarching goal of our study was to improve the design of narrative maps 10 . thus, by extracting these design guidelines and understanding the narrative sensemaking process, we have provided the basis for future improvements of the narrative map model. thus, future work should focus on using these findings to improve narrative maps and the associated extraction algorithms."}
{"id": 3227, "date": "2021-12-22", "title": "Lux: Always-on Visualization Recommendations for Exploratory Dataframe Workflows", "url": "https://arxiv.org/abs/2105.00121v2[cs.DB]", "keywords": [], "abstract": "xploratory data science largely happens in computational notebooks with dataframe apis, such as pandas, that support flexible means to transform, clean, and analyze data. yet, visually exploring data in dataframes remains tedious, requiring substantial programming effort for visualization and mental effort to determine what analysis to perform next. we propose lux, an always-on framework for accelerating visual insight discovery in dataframe workflows. when users print a dataframe in their notebooks, lux recommends visualizations to provide a quick overview of the patterns and trends and suggests promising analysis directions. lux features a highlevel language for generating visualizations on demand to encourage rapid visual experimentation with data. we demonstrate that through the use of a careful design and three system optimizations, lux adds no more than two seconds of overhead on top of pandas for over 98% of datasets in the uci repository. we evaluate lux in terms of usability via a controlled first-use study and interviews with early adopters, finding that lux helps fulfill the needs of data scientists for visualization support within their dataframe workflows. lux has already been embraced by data science practitioners, with over 3.1k stars on github.", "rq": ["rq 1: what is the overall performance of lux?", "rq 2: what is the effect of the number of columns on lux's performance?", "rq 3: how does the approximation-based prune condition affect the quality of the recommendations relative to no approximation?"], "relatedWork": ": lux draws from work on visualization recommendation systems, visualization specification, and visual dataframe tools. visualization recommendation (visrec). to visualize data, data scientists need to subselect the aspects of data, and then define a mapping from data to graphical encodings. interactive interfaces, such as tableau and powerbi , offer easy-to-use interfaces for visualization construction. some systems offer suggestions on other possible visualizations for users to browse through, as visualization recommendations. visrec systems can either suggest interesting portions of the data to visualize based on statistical properties or better ways to visualize attributes that users have selected . similarly, there has been research on recommending interesting attributes or filters to avoid manual data exploration during olap 81]. while interactive gui-based tools have gained adoption among business analysts, they are not as widely used by data scientists with programming expertise, due to their lack of customizability and integration with the rest of the data science workflow. lux draws on recommendation principles from this literature and explores how visualization recommendations can support a dataframe workflow. moreover, figure 5 outlines a novel, multi-tiered framework that lux employs to support flexible visual and programmatic interactions with a dataframe, overcoming the limitation in expressiveness of existing gui-based visrec tools. visualization specification (visspec). visspec frameworks codify visualization design principles and best practices to simplify the task of creating a visualization . these frameworks encompass a range of abstractions depending on the degree to which users are required to specify low-level details associated with the visualization definition. for example, imperative visualization libraries, such as plotly , d3 , and matplotlib , require users to manually compute the data associated with the graphical elements (e.g., position or size of marks) before defining the visualization characteristics. declarative visualization languages, such as altair and vega-lite , enable rapid specification of visualizations by applying smart defaults to synthesize low-level visualization details, so that users are not required to specify common chart components, such as axes, ticks, and labels. lux is built on top of these imperative and declarative frameworks and synthesizes visualization code to enable users to customize as needed. partial specification languages, such as draco and com-passql , commonly employed in visrec systems, support reasoning based on a partial specification provided by the user and design constraints encoded in the system. a partial specification can be thought of as a \"query\", with the system automatically ranking a set of perceptually-effective visualizations that match the query. as we will see in section 5, the intent language in lux is more convenient to specify than these existing languages in that it only requires users to specify data aspects of interest (or omit them entirely), instead of having to worry about visualization encodings. lux is also more versatile in that it supports functionalities beyond visualization creation for steering the recommendations generated. that said, as a promising direction for future work, lux could make use of draco's sophisticated reasoning around visualization design to improve which visualizations are displayed, going beyond the rule-based heuristics in its current implementation. compared to imperative, declarative, and partial visspec frameworks, figure 6 illustrates how lux's intent language further reduces the specification burden on users, allowing them to provide lightweight intent as opposed to writing long code fragments for visualization; we will elaborate on this in section 5. visual data exploration with dataframes. of late, dataframes have become the de-facto framework for interactive data science. the comprehensive, incremental set of operators make it easy to do sophisticated data transformation, while also allowing validation after each step. however, exploring dataframes is challenging, requiring substantial programming and analytical know-how. many visualization tools have been developed for dataframes . these tools generate summaries, covering analyses spanning missing values, outliers, attribute-level visualizations, and associated statistics. in addition, bamboolib , pandas-profiling , dataprep , sweetviz , and pandasgui offer a gui for constructing visualizations and data transformations. unlike these existing tools, lux lowers the barrier to visualizing dataframes by adopting an always-on approach so that dataframe visualizations are always recommended to users at all times, instead of relying on users to explicitly call external commands to plot or profile as needed.", "conclusion": "<title>conclusion</title> we propose lux, an always-on visualization framework for exploratory dataframe workflows. lux is a lightweight wrapper that reduces the barrier of visualizing data, enabling seamless exploration and visual discovery in-situ. to provide better visualization recommendations, we make use of user-provided intent and history, as well as structural information and metadata. we extend and evaluate various optimization strategies that minimize the overhead of lux, including approximate query processing, lazy computation, and caching and reuse. lux's adoption over the last year and success of user evaluation points to its importance for dataframe workflows-steering users towards valuable insights as they ponder what to do next with their data."}
{"id": 3231, "date": "2021-12-23", "title": "Human-AI Collaboration for UX Evaluation: Effects of Explanations and Synchronization", "url": "https://arxiv.org/abs/2112.12387v1[cs.HC]", "keywords": ["human-AI collaboration", "user experience (UX)", "AI-assisted UX evaluation", "explainable AI", "intelligent user interface design", "synchronization", "explanations", "think-aloud usability test"], "abstract": "nalyzing usability test videos is arduous. although recent research showed the promise of ai in assisting with such tasks, it remains largely unknown how ai should be designed to facilitate effective collaboration between user experience (ux) evaluators and ai. inspired by the concepts of agency and work context in human and ai collaboration literature, we studied two corresponding design factors for ai-assisted ux evaluation: explanations and synchronization. explanations allow ai to further inform humans how it identifies ux problems from a usability test session; synchronization refers to the two ways humans and ai collaborate: synchronously and asynchronously. we iteratively designed a tool-ai assistant-with four versions of uis corresponding to the two levels of explanations (with/without) and synchronization (sync/async). by adopting a hybrid wizard-of-oz approach to simulating an ai with reasonable performance, we conducted a mixed-method study with 24 ux evaluators identifying ux problems from usability test videos using ai assistant. our quantitative and qualitative results show that ai with explanations, regardless of being presented synchronously or asynchronously, provided better support for ux evaluators' analysis and was perceived more positively; when without explanations, synchronous ai better improved ux evaluators' performance and engagement compared to the asynchronous ai. lastly, we present the design implications for ai-assisted ux evaluation and facilitating more effective human-ai collaboration. ccs concepts: \u2022 human-centered computing \u2192 usability testing; empirical studies in hci.", "rq": ["rq 1: how would the explanations of ai affect ux evaluators' performance and perception in analyzing usability test videos?", "rq 2: how would the synchronization of ai affect ux evaluators' performance and perception in analyzing usability test videos?", "rq 3: what are ux evaluators' preferences that can inform the design of ai tools assisting ux evaluation?"], "relatedWork": "background and related work 2.1 ai for usability problems detection: analyzing usability test video to identify problems that participants encountered is a common task for ux evaluators. they need to attend to multiple behavioral signals of the participant from both visual and audio channels of the test video. more importantly, they need to leverage their domain expertise to determine whether there is indeed a usability problem or whether it is just typical efforts (e.g., trial-and-error) that the participant had to make when using the product. to help ux evaluators better analyze usability test videos, recent research began to develop ai methods to predict the overall ux of interfaces or detect specific usability problems . for example, grigera et al. proposed a rule-based classifier to detect a predefined set of usability smells-the hints of bad designs that could cause usability problems-by analyzing users' interaction logs . similar rule-based classification approaches have been used to detect usability smells in mobile websites and in virtual reality applications . jeong et al. proposed a graph-based ai method to model and measure the similarity of users' interactions with a mobile application to detect potential usability problems . although such automatic methods show the promise of detecting simple usability problems for specific user interfaces based on structured data (e.g., interaction logs) and empirical rules, detecting usability problems directly from a usability test video, which is a primary task of ux practitioners, is still challenging to be fully automated as it requires an understanding of the functions and designs of the test product, the test tasks, and the test subject's behaviors. to address the limitation of fully automated methods, researchers began to investigate human-ai collaboration tools to support ux evaluators rather than replacing them. one representative work is vista, a visual analytical tool that integrates visualization and machine learning (ml) to detect and highlight segments of a usability test video containing potential usability problems . such human-ai collaboration was shown to help ux evaluators identify more problems than they worked alone . as a first step to experiment human-ai collaboration for usability test video analysis, vista was limited in two ways. first, the collaboration between the ai and the ux evaluator was asynchronous. the evaluator was shown with the ai's predictions before they started their analysis, which might have affected the evaluator's independent analysis. alternatively, the ai's predictions could be shown synchronously, creating a perception that the evaluator and the ai are analyzing a usability test video simultaneously, which might allow the evaluator to perform more independent analysis while still being able to access the second perspective from the ai. fan, et al. the second limitation, based on their study participants' feedback, was that vista remained an \"opaque box\" and did not allow an understanding of how the ai worked. although vista visualizes the input features to show what went into the ai's analysis, it was deemed insufficient without having access to the meaning of these input features or the rationales on which the judgments were based. thus, it is necessary to explore explanations that could answer the why question in identifying usability problems in a video, such as what design principles or usability heuristics were violated . our work seeks to understand how synchronization (i.e., synchronous and asynchronous collaboration) and explanations (i.e., with and without) would affect ux evaluators' collaboration with the ai in the context of usability test video analysis. to overcome the technical limitations of ai in detecting ux problems, we opt for a hybrid wizard-of-oz (woz) approach in order to focus on evaluating different ways to present the ai's suggestions with a controlled experiment. our approach simulates a reliably performing ai system but is grounded in the technical feasibility of ml technologies. specifically, we assume the system works with a supervised ml classifier, which takes a segment of a usability test video as input and predicts whether the test subject encounters a problem in that video segment. the design of our woz ai's functionalities, including the ai explanations, will be discussed in section 3.3.2.", "conclusion": "<title>conclusion</title> we have studied how two factors of human-ai collaboration-explanations and synchronization-would affect the performance and perception of ux evaluators in the context of analyzing usability test videos. we iteratively designed fan, et al. a tool-ai assistant-with four versions of uis corresponding to the two levels of explanations (with/without) and synchronization (sync/async). we conducted a mixed-methods study with 24 ux evaluators identifying ux problems from usability test videos with ai assistant. our quantitative results show that both explanations and synchronization have positive effects on ux evaluators' performance (e.g., the number of identified ux problems) and engagement (e.g., time spent analyzing the video). specifically, ai with explanations, regardless of being presented synchronously or asynchronously, helped to improve ux evaluators' performance of and engagement in their analysis, as well as perception of the tool (e.g., understanding and satisfaction), compared to the baseline ai (i.e., asynchronous ai without explanations); when without explanations, synchronous ai improved ux evaluators' performance and engagement more than the asynchronous baseline ai. our qualitative results further reveal the ways how explanations and synchronization helped ux evaluators. specifically, explanations helped them better understand how the ai works, increased their trust in ai, and provided them with additional utility for ux evaluation tasks; and synchronization helped them better perform independent analysis, feel less overwhelmed by the ai's suggestions, and create a stronger sense of \"social presence\"-the feeling of working together with a \"colleague. \" based on our findings, we have shown ways to improve the design of explanations and synchronization aspects of human-ai collaboration, such as matching the ai's agency with the type of support it can provide (i.e., ai's capability), balancing between human agency and ai agency, and supporting the adaptability and customizability by allowing ux practitioners to guide the ai, such as by offering their expertise. finally, we have presented the design implications for ai agency and timing of human-ai collaboration in general and for ai-assisted tools for ux evaluation."}
{"id": 3278, "date": "2022-01-19", "title": "Unintended Bias in Language Model-driven Conversational Recommendation", "url": "https://arxiv.org/abs/2201.06224v2[cs.IR]", "keywords": ["Conversational Recommendation Systems", "BERT", "Contextual Language Models", "Bias and Discrimination"], "abstract": "onversational recommendation systems (crss) have recently started to leverage pretrained language models (lm) such as bert for their ability to semantically interpret a wide range of preference statement variations. however, pretrained lms are well-known to be prone to intrinsic biases in their training data, which may be exacerbated by biases embedded in domain-specific language data (e.g., user reviews) used to fine-tune lms for crss. we study a recently introduced lm-driven recommendation backbone (termed lmrec) of a crs to investigate how unintended bias -i.e., language variations such as name references or indirect indicators of sexual orientation or location that should not affect recommendations -manifests in significantly shifted price and category distributions of restaurant recommendations. the alarming results we observe strongly indicate that lmrec has learned to reinforce harmful stereotypes through its recommendations. for example, offhand mention of names associated with the black community significantly lowers the price distribution of recommended restaurants, while offhand mentions of common male-associated names lead to an increase in recommended alcohol-serving establishments. these and many related results presented in this work raise a red flag that advances in the language handling capability of lm-driven crss do not come without significant challenges related to mitigating unintended bias in future deployed crs assistants with a potential reach of hundreds of millions of end users.", "rq": ["rq 1: how well can lmrec recommend for language input?", "rq 2: what ways may unintentional racial bias appear?", "rq 3: what ways may unintentional gender bias appear?", "rq 5: what ways may unintentional sexual orientation bias appear?", "rq 6: what ways may unintentional location and religion bias appear?"], "relatedWork": ": this section briefly summarizes how fairness/bias issues have been analyzed in two requisite elements of language model-driven recommender systems: recommendation systems and language models. recent work on how language models can be leveraged in conversational recommender systems is also covered though we note a conspicuous lack of work on bias in lm-driven crss.", "conclusion": "<title>conclusion and future work</title> given the potential that pretrained lms offer for crss, we present quantitative and qualitative analysis to identify and measure unintended biases in lmrec. astonishingly, we observed that the model exhibits various unintended biases without involving any preferential statements nor recorded preferential history of the user, but simply due to an offhand mention of a name or relationship that in principle should not change the recommendations. our work has identified and raised a red flag for lm-driven crss and we consider this study a first step to understand and eventually mitigate unintended biases of future lm-driven crss."}
{"id": 3301, "date": "2022-02-02", "title": "Recommendations for Visualization Recommendations: Exploring Preferences and Priorities in Public Health", "url": "https://arxiv.org/abs/2202.01335v1[cs.HC]", "keywords": ["Visualization recommendation systems", "algorithmic trust", "automation", "recommendation source"], "abstract": "he promise of visualization recommendation systems is that analysts will be automatically provided with relevant and high-quality visualizations that will reduce the work of manual exploration or chart creation. however, little research to date has focused on what analysts value in the design of visualization recommendations. we interviewed 18 analysts in the public health sector and explored how they made sense of a popular in-domain dataset 1 in service of generating visualizations to recommend to others. we also explored how they interacted with a corpus of both automaticallyand manually-generated visualization recommendations, with the goal of uncovering how the design values of these analysts are reflected in current visualization recommendation systems. we find that analysts champion simple charts with clear takeaways that are nonetheless connected with existing semantic information or domain hypotheses. we conclude by recommending that visualization recommendation designers explore ways of integrating context and expectation into their systems.\u2022 human-centered computing \u2192 visualization design and evaluation methods; visualization systems and tools; user studies.", "rq": ["rq 1: what characteristics of a visualization design do analysts prioritize when recommending them to colleagues?", "rq 2: what do analysts prioritize when evaluating visualization recommendations from other sources?", "rq 3: how do the recommendations made by analysts align with those created from other sources in terms of visual form or analytical purpose?"], "relatedWork": ": our research questions and experimental design are informed by assumptions and goals behind the design of existing visualization recommendation systems, as well as by prior studies that involve participants expressing their preferences amongst visualizations from heterogeneous sources or creating novel and heterogeneous visualizations themselves. we therefore highlight three topics of related research: visualization recommendation systems, assessment of those systems (and visualizations in general), and visualization construction for novice users.", "conclusion": "<title>conclusion</title> this work explored the preferences and priorities of in-domain analysts when creating and evaluating visualization recommendations for their target audience. we base our findings off semi-structured interviews with 18 analysts in the public health sector, observing behaviors, attitudes, and perceptions they had for various components throughout the visualizations in the experiment. our findings highlight that these users overwhelmingly value simplicity, relevancy, and analytic interest both when creating their own visualization designs and when evaluating other visualization recommendations. participants either demonstrated an understanding of a visualization and the potential story or insight stemming from it, or were able to formulate targeted questions to any uncertainties with the attributes in the visualization. furthermore, certain data attributes (demographic and health outcomes) were frequently paired in visualization designs, indicating natural priors and biases in semantic knowledge in the dataset. lastly, we find that participants more likely engage with visualizations showing seemingly \"positive\" results with perceptively clearer patterns or trends. based on our findings, we suggest various design possibilities for visualization recommendation designers that could better aid in data exploration workflows."}
{"id": 3318, "date": "2022-02-10", "title": "Assessing the Fairness of AI Systems: AI Practitioners' Processes, Challenges, and Needs for Support", "url": "https://arxiv.org/abs/2112.05675v2[cs.AI]", "keywords": ["AI", "machine learning", "fairness", "software development practices"], "abstract": "various tools and practices have been developed to support practitioners in identifying, assessing, and mitigating fairness-related harms caused by ai systems. however, prior research has highlighted gaps between the intended design of these tools and practices and their use within particular contexts, including gaps caused by the role that organizational factors play in shaping fairness work. in this paper, we investigate these gaps for one such practice: disaggregated evaluations of ai systems, intended to uncover performance disparities between demographic groups. by conducting semi-structured interviews and structured workshops with thirty-three ai practitioners from ten teams at three technology companies, we identify practitioners' processes, challenges, and needs for support when designing disaggregated evaluations. we find that practitioners face challenges when choosing performance metrics, identifying the most relevant direct stakeholders and demographic groups on which to focus, and collecting datasets with which to conduct disaggregated evaluations. more generally, we identify impacts on fairness work stemming from a lack of engagement with direct stakeholders or domain experts, business imperatives that prioritize customers over marginalized groups, and the drive to deploy ai systems at scale. ccs concepts: \u2022 human-centered computing \u2192 empirical studies in collaborative and social computing; collaborative and social computing design and evaluation methods; \u2022 computing methodologies \u2192 artificial intelligence.", "rq": ["rq 1: what are practitioners' existing processes and challenges when designing disaggregated evaluations of their ai systems?", "rq 2: what organizational support do practitioners need when designing disaggregated evaluations, and how do they communicate those needs to their leadership?", "rq 3: how are practitioners' processes, challenges, and needs for support impacted by their organizational contexts?"], "relatedWork": ": 2.1 assessing the fairness of ai systems disaggregated evaluations are often designed and conducted by third parties that are external to the teams responsible for developing the ai systems to be evaluated. 3 although there are good reasons for third parties to design and conduct disaggregated evaluations, including increased credibility (as there may be fewer reasons to believe that decisions were made so as to cast the ai systems in question in a more favorable light), there are also drawbacks to relying solely on this approach . for example, third parties may not have access to detailed knowledge about ai systems' inner workings, perhaps due to trade secrecy laws , and may therefore overlook crucial components or features that might cause fairness-related harms . in addition, unless third parties are given pre-deployment access, they can only conduct disaggregated evaluations of ai systems that have already been deployed and potentially even caused fairness-related harms -or what morley et al. referred to as a gap between diagnostic and prescriptive approaches . to address this, raji et al. proposed the smactr framework for internal auditing to close the \"ai accountability gap\" , with prompts and artifacts targeted at different stages of the ai development lifecycle. this framework is designed to promote internal auditing practices that might align evaluations of ai systems with organizations' principles and values. however, it is intended to be used by auditors that are internal to the organizations responsible for developing the ai systems in question, but external to the teams tasked with system development. this raises the question of how practitioners can use disaggregated evaluations to uncover performance disparities before system deployment, particularly given that incentives to ship ai products and services quickly may be at odds with the slow and careful work that is needed to design and conduct such evaluations .", "conclusion": "<title>conclusion</title> as researchers and practitioners develop new tools and practices for identifying, assessing, and mitigating fairness-related harms caused by ai systems, it is critical to understand how these tools and practices are actually used. in this paper, we focus on one such practice: disaggregated evaluations of ai systems, intended to uncover performance disparities between demographic groups. via semi-structured interviews and structured workshops with ai practitioners at multiple companies, we identify impacts on fairness work stemming from a lack of engagement with direct stakeholders or domain experts, business imperatives that prioritize customers over marginalized groups, and the drive to deploy ai systems at scale. specifically, we find that practitioners face challenges when choosing performance metrics, identifying the most relevant direct stakeholders and demographic groups on which to focus, and collecting datasets with which to conduct disaggregated evaluations. these findings suggest the need for processes for engaging with direct stakeholders and domain experts prior to deployment to new geographic contexts, as well as counterbalances to business imperatives that can lead to pressures to deploy ai systems before assessing their fairness in contextually appropriate ways."}
